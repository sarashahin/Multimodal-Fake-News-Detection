{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpb30k10_Jlw"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQKZiTd_yCBW"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import spacy\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2 \n",
        "import multiprocessing as mp\n",
        "import imp\n",
        "import threading\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5GXZyKr_abl"
      },
      "source": [
        "Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqCknGEtyL9_"
      },
      "outputs": [],
      "source": [
        "# Train data \n",
        "multi_traindata = pd.read_csv('/content/drive/MyDrive/multimodal_train.tsv',sep='\\t')\n",
        "# Validation data \n",
        "multi_validata = pd.read_csv('/content/drive/MyDrive/multimodal_validate.tsv',sep='\\t')\n",
        "# Test data \n",
        "multi_testdata = pd.read_csv('/content/drive/MyDrive/multimodal_test_public.tsv',sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqHNNjzc_eeL"
      },
      "source": [
        "Subset of the dataframe with no missing values in the 'title' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj4cyMkgyMBE"
      },
      "outputs": [],
      "source": [
        "# Train data with no missing values\n",
        "train_data = multi_traindata[multi_traindata['title'].notna()]\n",
        "\n",
        "# Validation data with no missing values\n",
        "valid_data = multi_validata[multi_validata['title'].notna()]\n",
        "\n",
        "# Test data with no missing values\n",
        "test_data = multi_testdata[multi_testdata['title'].notna()]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVxirpqk_jlQ"
      },
      "source": [
        "Separates the dataset into three sets of data: texts, labels and image names.\n",
        "It firstly defines the train, validation and test dataset and then it separates the columns 'title', '6_way_label' and 'id' into separate variables.\n",
        "\n",
        "In the train dataset, it separates the columns 'title', '6_way_label' and 'id' into three separate variables called 'train_news', 'train_labels' and 'train_images' respectively by using the .values.T property. This .values.T is used to obtain a transposed view of the dataframe, where the rows and columns are flipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JkyTf2UyMD8"
      },
      "outputs": [],
      "source": [
        "train_news, train_labels, train_images = train_data['title'].tolist(), train_data['6_way_label'].tolist(), train_data['id'].tolist()\n",
        "valid_news, valid_labels, valid_images = valid_data['title'].tolist(), valid_data['6_way_label'].tolist(), valid_data['id'].tolist()\n",
        "test_news, test_labels, test_images = test_data['title'].tolist(), test_data['6_way_label'].tolist(), test_data['id'].tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_rzKEv_89d"
      },
      "source": [
        "Add the '.jpg' termination to all the image names in the previous lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE0-HFmc_3nC"
      },
      "outputs": [],
      "source": [
        "def add_suffix(images, suffix='.jpg'):\n",
        "    return [image + suffix for image in images]\n",
        "\n",
        "train_images_final = add_suffix(train_images)\n",
        "valid_images_final = add_suffix(valid_images)\n",
        "test_images_final = add_suffix(test_images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G5amdiTAHWU"
      },
      "source": [
        "Preprocessing\n",
        "\n",
        "First, preprocess the text that will feed to the neural network. define a function to preprocess the data. remove punctuations, numbers and also multiple spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removes punctuations, numbers, and multiple spaces from the input text. The function uses regular expressions (re) to replace any non-alphabetic characters with a space and also replaces multiple spaces with a single space."
      ],
      "metadata": {
        "id": "nWUHkW6ySGIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caYpCoT6yMGz"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocess_text(sentence):\n",
        "    return re.sub(r'[^a-zA-Z\\s]|\\s+', ' ', sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywHsYUdIyMJa"
      },
      "outputs": [],
      "source": [
        "# Preprocess the news text\n",
        "train_news_clean = [preprocess_text(new) for new in train_news]\n",
        "valid_news_clean = [preprocess_text(new) for new in valid_news]\n",
        "test_news_clean = [preprocess_text(new) for new in test_news]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EOsgH6iAwlY"
      },
      "source": [
        "Using nltk's pos_tag() method to get the POS tag of each word and then passing that tag as an argument to the lemmatizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP6ALMFRyMMR"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def remove_stopwords_lem(text):\n",
        "    text = word_tokenize(text)\n",
        "    filtered_words = [lemmatizer.lemmatize(word, pos = get_wordnet_pos(word)) for word in text if word not in stop_words]\n",
        "    filtered_words\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1]\n",
        "    tag\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWEM9HtsyMPJ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Stop-words removal and lemmatization\n",
        "# Remove stopwords and lemmatize\n",
        "train_stwrd_lem = [remove_stopwords_lem(new) for new in train_news_clean]\n",
        "valid_stwrd_lem = [remove_stopwords_lem(new) for new in valid_news_clean]\n",
        "test_stwrd_lem = [remove_stopwords_lem(new) for new in test_news_clean]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3EMECh7BExU"
      },
      "source": [
        "Using the fit_on_texts() method only on the training set and then use texts_to_sequences() for both validation and test sets as well. Also, it is not necessary to set the num_words parameter to a fixed value, I can use the num_words parameter to set the maximum number of words to keep, based on word frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOusPDfQyMRv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "news_all = train_stwrd_lem + valid_stwrd_lem + test_stwrd_lem\n",
        "tokenizer = Tokenizer(num_words = 128022)\n",
        "tokenizer.fit_on_texts(news_all)\n",
        "train_tokenized = tokenizer.texts_to_sequences(train_stwrd_lem)\n",
        "valid_tokenized = tokenizer.texts_to_sequences(valid_stwrd_lem)\n",
        "test_tokenized = tokenizer.texts_to_sequences(test_stwrd_lem)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjCtMf3ryMUn",
        "outputId": "045628a9-3991-42eb-eae4-0859c9123ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length:  110688\n"
          ]
        }
      ],
      "source": [
        "# Obtain the vocabulary length\n",
        "\n",
        "print(\"Vocabulary length: \", len(tokenizer.word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF82C3gZyMXe"
      },
      "outputs": [],
      "source": [
        "# Pad/truncate the tokenized news\n",
        "# Train\n",
        "train_tokenized_padding = pad_sequences(train_tokenized, maxlen = 15, truncating='post', padding='post')\n",
        "\n",
        "# Validation\n",
        "valid_tokenized_padding = pad_sequences(valid_tokenized, maxlen = 15, truncating='post', padding='post')\n",
        "\n",
        "# Test\n",
        "test_tokenized_padding = pad_sequences(test_tokenized, maxlen = 15, truncating='post', padding='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**\n"
      ],
      "metadata": {
        "id": "65PN9C1IXXEF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juhMUT1x_INe"
      },
      "source": [
        "Removing the stripping of the last element of embd and converting embd to a float list in a single line. Also, the file can be opened and read using with statement to automatically close the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdUcel9g5cTz"
      },
      "outputs": [],
      "source": [
        "def load_embedd(filename):\n",
        "    words = []\n",
        "    vectors = []\n",
        "    with open(filename,'r', encoding=\"utf8\") as file:\n",
        "        for line in file:\n",
        "           row = line.split(' ')\n",
        "           vocab = row[0]\n",
        "           embd = list(map(float, row[1:-1]))\n",
        "           words.append(vocab)\n",
        "           vectors.append(embd)\n",
        "           words, vectors\n",
        "    return words, vectors\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN-Uhq4f5cWX"
      },
      "outputs": [],
      "source": [
        "def embed_matrix(word_index, vocab, embeddings, vocab_len, embedding_len):\n",
        "    embedding_matrix = np.zeros((vocab_len + 1, embedding_len))\n",
        "    for word, i in word_index.items():\n",
        "        if word in vocab:\n",
        "            idx = vocab.index(word)\n",
        "            vector = embeddings[idx]\n",
        "            vector = np.pad(vector, (0, embedding_len - len(vector)), 'constant')\n",
        "            embedding_matrix[i] = vector\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyiN4QH2FYm_"
      },
      "source": [
        "Use GloVe embeddings of dimension 300."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuicde8-5cZf"
      },
      "outputs": [],
      "source": [
        "# Use GloVe embeddings of dimension 300\n",
        "vocab_gv_300, vectors_gv_300 = load_embedd(filename = \"/content/drive/MyDrive/SaveModels/glove.6B.300d.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-uLmU6acjC6"
      },
      "source": [
        "This way the function can use the vocab list to check if a word is present in the embeddings list before adding it to the embedding matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryEghBc2MFfc"
      },
      "outputs": [],
      "source": [
        "# Create the embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix_gv_300 = embed_matrix(word_index=word_index, vocab=vocab_gv_300, embeddings=vectors_gv_300,\n",
        "vocab_len=110688, embedding_len=300)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_wCKRq0czVq"
      },
      "source": [
        "\n",
        "The os.path.join() function combines the different parts of the path and uses the appropriate separator for the current operating system.\n",
        "This way the code will work on any operating system, regardless of the separator used in the file path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5b016KrMFh9",
        "outputId": "c84962da-9a5b-4ca6-aef3-1f2e74245a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length all_images: 178112\n"
          ]
        }
      ],
      "source": [
        "# Get names of available images\n",
        "all_images = os.listdir(\"/content/drive/MyDrive/public_image_set/\")\n",
        "path = \"/content/drive/MyDrive/public_image_set/\"\n",
        "\n",
        "\n",
        "print(\"length all_images:\",len(all_images))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kngzdlRbgagM"
      },
      "source": [
        "The function will resize the image to 560x560 and fill any remaining pixels with zeroes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxy-SrqWMFk0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pad_images(image):\n",
        "    h, w, c = image.shape\n",
        "    img_reshaped = np.zeros((3, 560, 560))\n",
        "    rh = min(h, 560)\n",
        "    rw = min(w, 560)\n",
        "    img_reshaped[0, :rh, :rw] = image[:rh, :rw, 0]\n",
        "    img_reshaped[1, :rh, :rw] = image[:rh, :rw, 1]\n",
        "    img_reshaped[2, :rh, :rw] = image[:rh, :rw, 2]\n",
        "    return img_reshaped\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an implementation of a deep learning model that takes both an image and a title as input, processes them with different neural network components, and outputs a prediction of a label."
      ],
      "metadata": {
        "id": "rsJbEO4DYYGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "\n",
        "class CNN_Title_Images(nn.Module):\n",
        "    \n",
        "    def __init__(self, image_dimx, nlabels):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Embedding layer for the titles\n",
        "        self.title_embedding = nn.Embedding(\n",
        "            num_embeddings=110688,\n",
        "            embedding_dim=300\n",
        "        )\n",
        "        self.title_embedding.weight = nn.Parameter(\n",
        "            torch.from_numpy(embedding_matrix_gv_300),\n",
        "            requires_grad=False\n",
        "        )\n",
        "        \n",
        "        # Convolutional layer for the images\n",
        "        self.image_cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(6, 3, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        # Convolutional layer for the titles\n",
        "        self.title_cnn = nn.ModuleList([\n",
        "            nn.Conv2d(1, 50, (k, 300), padding=(k-1,0))\n",
        "            for k in [2, 3, 4, 5]\n",
        "        ])\n",
        "        \n",
        "        self.fc1 = nn.Linear(200 + 3 * 137 * 137, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, nlabels)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "        # Dimension of the image at the output of the second convolutional layer\n",
        "        self.final_image_dim = int(((image_dimx - 4) / 2 - 4) / 2)\n",
        "\n",
        "    def forward(self, image, title):\n",
        "        # Pass the image tensor through the CNN operations\n",
        "        image = self.image_cnn(image)\n",
        "        image = image.view(image.shape[0], self.final_image_dim * self.final_image_dim * 3)\n",
        "\n",
        "        # Pass the title tensor through the different operations\n",
        "        title = self.title_embedding(title)\n",
        "        title = title.unsqueeze(1)\n",
        "        title = [F.relu(conv(title.float())).squeeze(3) for conv in self.title_cnn]\n",
        "        title = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in title] \n",
        "        title = torch.cat(title, 1)\n",
        "        \n",
        "        # Join image and title output\n",
        "        x = torch.cat([image, title], 1)\n",
        "        \n",
        "        # Pass result through the linear layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.logsoftmax(x)\n",
        "        return x\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "WJGjqrxDwY4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e30Hqhr05ccW"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model_CNN_image_text = CNN_Title_Images(image_dimx = 560 ,nlabels = 6 )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trains a CNN image and text classification model using PyTorch. It uses the Adam optimizer and the NLLLoss criterion to optimize the model's parameters. The training data is processed in batches of 60, and the code performs forward and backward propagation on each batch. After processing each batch, it calculates the accuracy of the model, updates the parameters using the optimizer, and resets the image, title, and label tensors. The average training accuracy is printed every 100 batches processed."
      ],
      "metadata": {
        "id": "rIP7XurPYtEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create counter to be used in the loop\n",
        "counter = 0\n",
        "# Error function\n",
        "criterion = nn.NLLLoss()\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model_CNN_image_text.parameters(), lr=0.001)\n",
        "# To store training accuracy\n",
        "train_accuracy = 0\n",
        "# To store the number of training batches processed\n",
        "train_batches_processed = 0\n",
        "\n",
        "images_tensor = torch.zeros(60, 3, 560, 560)\n",
        "titles_tensor = torch.zeros(60, 15)\n",
        "labels_tensor = torch.zeros(60)\n",
        "\n",
        "for i in range(len(train_images_final)):\n",
        "    \n",
        "    # First check if image is available\n",
        "    img = cv2.imread(os.path.join(path, train_images_final[i])) \n",
        "        \n",
        "    if type(img) is not type(None):\n",
        "        counter += 1 \n",
        "        \n",
        "        # Pad image with zeros or truncate it to obtain 560 x 560 shape\n",
        "        img_padded = pad_images(img)\n",
        "        \n",
        "        # Store image, corresponding title, and label \n",
        "        images_tensor[counter-1, :,:,:] = torch.from_numpy(img_padded)\n",
        "        titles_tensor[counter-1, :] = torch.from_numpy(train_tokenized_padding[i]).int()\n",
        "        labels_tensor[counter - 1] = train_labels[i]\n",
        "           \n",
        "        \n",
        "        if counter % 60 == 0: \n",
        "           train_batches_processed += 1\n",
        "           print(\"Training Batch Processed: \", train_batches_processed)\n",
        "\n",
        "           # Reset gradients\n",
        "           optimizer.zero_grad() \n",
        "\n",
        "           # Pass image and text through the different layers\n",
        "           out = model_CNN_image_text.forward(images_tensor, titles_tensor.long())            \n",
        "            # Compute loss\n",
        "           loss = criterion(out, labels_tensor.long())\n",
        "\n",
        "            \n",
        "           # Backpropagation\n",
        "           loss.backward()\n",
        "        \n",
        "           # Optimize parameters\n",
        "           optimizer.step()\n",
        "            \n",
        "           # Obtain number of correct predictions and store accuracy\n",
        "           top_p, top_class = out.topk(1, dim=1) \n",
        "           equals = (top_class == labels_tensor.view(images_tensor.shape[0], 1))\n",
        "           train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "           # Reset image, title, and label tensors\n",
        "           images_tensor = torch.zeros(60, 3, 560, 560)\n",
        "           titles_tensor = torch.zeros(60, 15)\n",
        "           labels_tensor = torch.zeros(60)\n",
        "            \n",
        "           counter = 0 \n",
        "                \n",
        "           # Print average accuracy every 100 training batches\n",
        "           if train_batches_processed % 100 == 0:\n",
        "\n",
        "                print(\"Average Training Accuracy:\", train_accuracy / train_batches_processed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL9szO4MCZhJ",
        "outputId": "4bc07dd1-17cd-4d6c-8fdc-3e5c3680620a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Batch Processed:  1\n",
            "Training Batch Processed:  2\n",
            "Training Batch Processed:  3\n",
            "Training Batch Processed:  4\n",
            "Training Batch Processed:  5\n",
            "Training Batch Processed:  6\n",
            "Training Batch Processed:  7\n",
            "Training Batch Processed:  8\n",
            "Training Batch Processed:  9\n",
            "Training Batch Processed:  10\n",
            "Training Batch Processed:  11\n",
            "Training Batch Processed:  12\n",
            "Training Batch Processed:  13\n",
            "Training Batch Processed:  14\n",
            "Training Batch Processed:  15\n",
            "Training Batch Processed:  16\n",
            "Training Batch Processed:  17\n",
            "Training Batch Processed:  18\n",
            "Training Batch Processed:  19\n",
            "Training Batch Processed:  20\n",
            "Training Batch Processed:  21\n",
            "Training Batch Processed:  22\n",
            "Training Batch Processed:  23\n",
            "Training Batch Processed:  24\n",
            "Training Batch Processed:  25\n",
            "Training Batch Processed:  26\n",
            "Training Batch Processed:  27\n",
            "Training Batch Processed:  28\n",
            "Training Batch Processed:  29\n",
            "Training Batch Processed:  30\n",
            "Training Batch Processed:  31\n",
            "Training Batch Processed:  32\n",
            "Training Batch Processed:  33\n",
            "Training Batch Processed:  34\n",
            "Training Batch Processed:  35\n",
            "Training Batch Processed:  36\n",
            "Training Batch Processed:  37\n",
            "Training Batch Processed:  38\n",
            "Training Batch Processed:  39\n",
            "Training Batch Processed:  40\n",
            "Training Batch Processed:  41\n",
            "Training Batch Processed:  42\n",
            "Training Batch Processed:  43\n",
            "Training Batch Processed:  44\n",
            "Training Batch Processed:  45\n",
            "Training Batch Processed:  46\n",
            "Training Batch Processed:  47\n",
            "Training Batch Processed:  48\n",
            "Training Batch Processed:  49\n",
            "Training Batch Processed:  50\n",
            "Training Batch Processed:  51\n",
            "Training Batch Processed:  52\n",
            "Training Batch Processed:  53\n",
            "Training Batch Processed:  54\n",
            "Training Batch Processed:  55\n",
            "Training Batch Processed:  56\n",
            "Training Batch Processed:  57\n",
            "Training Batch Processed:  58\n",
            "Training Batch Processed:  59\n",
            "Training Batch Processed:  60\n",
            "Training Batch Processed:  61\n",
            "Training Batch Processed:  62\n",
            "Training Batch Processed:  63\n",
            "Training Batch Processed:  64\n",
            "Training Batch Processed:  65\n",
            "Training Batch Processed:  66\n",
            "Training Batch Processed:  67\n",
            "Training Batch Processed:  68\n",
            "Training Batch Processed:  69\n",
            "Training Batch Processed:  70\n",
            "Training Batch Processed:  71\n",
            "Training Batch Processed:  72\n",
            "Training Batch Processed:  73\n",
            "Training Batch Processed:  74\n",
            "Training Batch Processed:  75\n",
            "Training Batch Processed:  76\n",
            "Training Batch Processed:  77\n",
            "Training Batch Processed:  78\n",
            "Training Batch Processed:  79\n",
            "Training Batch Processed:  80\n",
            "Training Batch Processed:  81\n",
            "Training Batch Processed:  82\n",
            "Training Batch Processed:  83\n",
            "Training Batch Processed:  84\n",
            "Training Batch Processed:  85\n",
            "Training Batch Processed:  86\n",
            "Training Batch Processed:  87\n",
            "Training Batch Processed:  88\n",
            "Training Batch Processed:  89\n",
            "Training Batch Processed:  90\n",
            "Training Batch Processed:  91\n",
            "Training Batch Processed:  92\n",
            "Training Batch Processed:  93\n",
            "Training Batch Processed:  94\n",
            "Training Batch Processed:  95\n",
            "Training Batch Processed:  96\n",
            "Training Batch Processed:  97\n",
            "Training Batch Processed:  98\n",
            "Training Batch Processed:  99\n",
            "Training Batch Processed:  100\n",
            "Average Training Accuracy: tensor(0.6922)\n",
            "Training Batch Processed:  101\n",
            "Training Batch Processed:  102\n",
            "Training Batch Processed:  103\n",
            "Training Batch Processed:  104\n",
            "Training Batch Processed:  105\n",
            "Training Batch Processed:  106\n",
            "Training Batch Processed:  107\n",
            "Training Batch Processed:  108\n",
            "Training Batch Processed:  109\n",
            "Training Batch Processed:  110\n",
            "Training Batch Processed:  111\n",
            "Training Batch Processed:  112\n",
            "Training Batch Processed:  113\n",
            "Training Batch Processed:  114\n",
            "Training Batch Processed:  115\n",
            "Training Batch Processed:  116\n",
            "Training Batch Processed:  117\n",
            "Training Batch Processed:  118\n",
            "Training Batch Processed:  119\n",
            "Training Batch Processed:  120\n",
            "Training Batch Processed:  121\n",
            "Training Batch Processed:  122\n",
            "Training Batch Processed:  123\n",
            "Training Batch Processed:  124\n",
            "Training Batch Processed:  125\n",
            "Training Batch Processed:  126\n",
            "Training Batch Processed:  127\n",
            "Training Batch Processed:  128\n",
            "Training Batch Processed:  129\n",
            "Training Batch Processed:  130\n",
            "Training Batch Processed:  131\n",
            "Training Batch Processed:  132\n",
            "Training Batch Processed:  133\n",
            "Training Batch Processed:  134\n",
            "Training Batch Processed:  135\n",
            "Training Batch Processed:  136\n",
            "Training Batch Processed:  137\n",
            "Training Batch Processed:  138\n",
            "Training Batch Processed:  139\n",
            "Training Batch Processed:  140\n",
            "Training Batch Processed:  141\n",
            "Training Batch Processed:  142\n",
            "Training Batch Processed:  143\n",
            "Training Batch Processed:  144\n",
            "Training Batch Processed:  145\n",
            "Training Batch Processed:  146\n",
            "Training Batch Processed:  147\n",
            "Training Batch Processed:  148\n",
            "Training Batch Processed:  149\n",
            "Training Batch Processed:  150\n",
            "Training Batch Processed:  151\n",
            "Training Batch Processed:  152\n",
            "Training Batch Processed:  153\n",
            "Training Batch Processed:  154\n",
            "Training Batch Processed:  155\n",
            "Training Batch Processed:  156\n",
            "Training Batch Processed:  157\n",
            "Training Batch Processed:  158\n",
            "Training Batch Processed:  159\n",
            "Training Batch Processed:  160\n",
            "Training Batch Processed:  161\n",
            "Training Batch Processed:  162\n",
            "Training Batch Processed:  163\n",
            "Training Batch Processed:  164\n",
            "Training Batch Processed:  165\n",
            "Training Batch Processed:  166\n",
            "Training Batch Processed:  167\n",
            "Training Batch Processed:  168\n",
            "Training Batch Processed:  169\n",
            "Training Batch Processed:  170\n",
            "Training Batch Processed:  171\n",
            "Training Batch Processed:  172\n",
            "Training Batch Processed:  173\n",
            "Training Batch Processed:  174\n",
            "Training Batch Processed:  175\n",
            "Training Batch Processed:  176\n",
            "Training Batch Processed:  177\n",
            "Training Batch Processed:  178\n",
            "Training Batch Processed:  179\n",
            "Training Batch Processed:  180\n",
            "Training Batch Processed:  181\n",
            "Training Batch Processed:  182\n",
            "Training Batch Processed:  183\n",
            "Training Batch Processed:  184\n",
            "Training Batch Processed:  185\n",
            "Training Batch Processed:  186\n",
            "Training Batch Processed:  187\n",
            "Training Batch Processed:  188\n",
            "Training Batch Processed:  189\n",
            "Training Batch Processed:  190\n",
            "Training Batch Processed:  191\n",
            "Training Batch Processed:  192\n",
            "Training Batch Processed:  193\n",
            "Training Batch Processed:  194\n",
            "Training Batch Processed:  195\n",
            "Training Batch Processed:  196\n",
            "Training Batch Processed:  197\n",
            "Training Batch Processed:  198\n",
            "Training Batch Processed:  199\n",
            "Training Batch Processed:  200\n",
            "Average Training Accuracy: tensor(0.7234)\n",
            "Training Batch Processed:  201\n",
            "Training Batch Processed:  202\n",
            "Training Batch Processed:  203\n",
            "Training Batch Processed:  204\n",
            "Training Batch Processed:  205\n",
            "Training Batch Processed:  206\n",
            "Training Batch Processed:  207\n",
            "Training Batch Processed:  208\n",
            "Training Batch Processed:  209\n",
            "Training Batch Processed:  210\n",
            "Training Batch Processed:  211\n",
            "Training Batch Processed:  212\n",
            "Training Batch Processed:  213\n",
            "Training Batch Processed:  214\n",
            "Training Batch Processed:  215\n",
            "Training Batch Processed:  216\n",
            "Training Batch Processed:  217\n",
            "Training Batch Processed:  218\n",
            "Training Batch Processed:  219\n",
            "Training Batch Processed:  220\n",
            "Training Batch Processed:  221\n",
            "Training Batch Processed:  222\n",
            "Training Batch Processed:  223\n",
            "Training Batch Processed:  224\n",
            "Training Batch Processed:  225\n",
            "Training Batch Processed:  226\n",
            "Training Batch Processed:  227\n",
            "Training Batch Processed:  228\n",
            "Training Batch Processed:  229\n",
            "Training Batch Processed:  230\n",
            "Training Batch Processed:  231\n",
            "Training Batch Processed:  232\n",
            "Training Batch Processed:  233\n",
            "Training Batch Processed:  234\n",
            "Training Batch Processed:  235\n",
            "Training Batch Processed:  236\n",
            "Training Batch Processed:  237\n",
            "Training Batch Processed:  238\n",
            "Training Batch Processed:  239\n",
            "Training Batch Processed:  240\n",
            "Training Batch Processed:  241\n",
            "Training Batch Processed:  242\n",
            "Training Batch Processed:  243\n",
            "Training Batch Processed:  244\n",
            "Training Batch Processed:  245\n",
            "Training Batch Processed:  246\n",
            "Training Batch Processed:  247\n",
            "Training Batch Processed:  248\n",
            "Training Batch Processed:  249\n",
            "Training Batch Processed:  250\n",
            "Training Batch Processed:  251\n",
            "Training Batch Processed:  252\n",
            "Training Batch Processed:  253\n",
            "Training Batch Processed:  254\n",
            "Training Batch Processed:  255\n",
            "Training Batch Processed:  256\n",
            "Training Batch Processed:  257\n",
            "Training Batch Processed:  258\n",
            "Training Batch Processed:  259\n",
            "Training Batch Processed:  260\n",
            "Training Batch Processed:  261\n",
            "Training Batch Processed:  262\n",
            "Training Batch Processed:  263\n",
            "Training Batch Processed:  264\n",
            "Training Batch Processed:  265\n",
            "Training Batch Processed:  266\n",
            "Training Batch Processed:  267\n",
            "Training Batch Processed:  268\n",
            "Training Batch Processed:  269\n",
            "Training Batch Processed:  270\n",
            "Training Batch Processed:  271\n",
            "Training Batch Processed:  272\n",
            "Training Batch Processed:  273\n",
            "Training Batch Processed:  274\n",
            "Training Batch Processed:  275\n",
            "Training Batch Processed:  276\n",
            "Training Batch Processed:  277\n",
            "Training Batch Processed:  278\n",
            "Training Batch Processed:  279\n",
            "Training Batch Processed:  280\n",
            "Training Batch Processed:  281\n",
            "Training Batch Processed:  282\n",
            "Training Batch Processed:  283\n",
            "Training Batch Processed:  284\n",
            "Training Batch Processed:  285\n",
            "Training Batch Processed:  286\n",
            "Training Batch Processed:  287\n",
            "Training Batch Processed:  288\n",
            "Training Batch Processed:  289\n",
            "Training Batch Processed:  290\n",
            "Training Batch Processed:  291\n",
            "Training Batch Processed:  292\n",
            "Training Batch Processed:  293\n",
            "Training Batch Processed:  294\n",
            "Training Batch Processed:  295\n",
            "Training Batch Processed:  296\n",
            "Training Batch Processed:  297\n",
            "Training Batch Processed:  298\n",
            "Training Batch Processed:  299\n",
            "Training Batch Processed:  300\n",
            "Average Training Accuracy: tensor(0.7402)\n",
            "Training Batch Processed:  301\n",
            "Training Batch Processed:  302\n",
            "Training Batch Processed:  303\n",
            "Training Batch Processed:  304\n",
            "Training Batch Processed:  305\n",
            "Training Batch Processed:  306\n",
            "Training Batch Processed:  307\n",
            "Training Batch Processed:  308\n",
            "Training Batch Processed:  309\n",
            "Training Batch Processed:  310\n",
            "Training Batch Processed:  311\n",
            "Training Batch Processed:  312\n",
            "Training Batch Processed:  313\n",
            "Training Batch Processed:  314\n",
            "Training Batch Processed:  315\n",
            "Training Batch Processed:  316\n",
            "Training Batch Processed:  317\n",
            "Training Batch Processed:  318\n",
            "Training Batch Processed:  319\n",
            "Training Batch Processed:  320\n",
            "Training Batch Processed:  321\n",
            "Training Batch Processed:  322\n",
            "Training Batch Processed:  323\n",
            "Training Batch Processed:  324\n",
            "Training Batch Processed:  325\n",
            "Training Batch Processed:  326\n",
            "Training Batch Processed:  327\n",
            "Training Batch Processed:  328\n",
            "Training Batch Processed:  329\n",
            "Training Batch Processed:  330\n",
            "Training Batch Processed:  331\n",
            "Training Batch Processed:  332\n",
            "Training Batch Processed:  333\n",
            "Training Batch Processed:  334\n",
            "Training Batch Processed:  335\n",
            "Training Batch Processed:  336\n",
            "Training Batch Processed:  337\n",
            "Training Batch Processed:  338\n",
            "Training Batch Processed:  339\n",
            "Training Batch Processed:  340\n",
            "Training Batch Processed:  341\n",
            "Training Batch Processed:  342\n",
            "Training Batch Processed:  343\n",
            "Training Batch Processed:  344\n",
            "Training Batch Processed:  345\n",
            "Training Batch Processed:  346\n",
            "Training Batch Processed:  347\n",
            "Training Batch Processed:  348\n",
            "Training Batch Processed:  349\n",
            "Training Batch Processed:  350\n",
            "Training Batch Processed:  351\n",
            "Training Batch Processed:  352\n",
            "Training Batch Processed:  353\n",
            "Training Batch Processed:  354\n",
            "Training Batch Processed:  355\n",
            "Training Batch Processed:  356\n",
            "Training Batch Processed:  357\n",
            "Training Batch Processed:  358\n",
            "Training Batch Processed:  359\n",
            "Training Batch Processed:  360\n",
            "Training Batch Processed:  361\n",
            "Training Batch Processed:  362\n",
            "Training Batch Processed:  363\n",
            "Training Batch Processed:  364\n",
            "Training Batch Processed:  365\n",
            "Training Batch Processed:  366\n",
            "Training Batch Processed:  367\n",
            "Training Batch Processed:  368\n",
            "Training Batch Processed:  369\n",
            "Training Batch Processed:  370\n",
            "Training Batch Processed:  371\n",
            "Training Batch Processed:  372\n",
            "Training Batch Processed:  373\n",
            "Training Batch Processed:  374\n",
            "Training Batch Processed:  375\n",
            "Training Batch Processed:  376\n",
            "Training Batch Processed:  377\n",
            "Training Batch Processed:  378\n",
            "Training Batch Processed:  379\n",
            "Training Batch Processed:  380\n",
            "Training Batch Processed:  381\n",
            "Training Batch Processed:  382\n",
            "Training Batch Processed:  383\n",
            "Training Batch Processed:  384\n",
            "Training Batch Processed:  385\n",
            "Training Batch Processed:  386\n",
            "Training Batch Processed:  387\n",
            "Training Batch Processed:  388\n",
            "Training Batch Processed:  389\n",
            "Training Batch Processed:  390\n",
            "Training Batch Processed:  391\n",
            "Training Batch Processed:  392\n",
            "Training Batch Processed:  393\n",
            "Training Batch Processed:  394\n",
            "Training Batch Processed:  395\n",
            "Training Batch Processed:  396\n",
            "Training Batch Processed:  397\n",
            "Training Batch Processed:  398\n",
            "Training Batch Processed:  399\n",
            "Training Batch Processed:  400\n",
            "Average Training Accuracy: tensor(0.7514)\n",
            "Training Batch Processed:  401\n",
            "Training Batch Processed:  402\n",
            "Training Batch Processed:  403\n",
            "Training Batch Processed:  404\n",
            "Training Batch Processed:  405\n",
            "Training Batch Processed:  406\n",
            "Training Batch Processed:  407\n",
            "Training Batch Processed:  408\n",
            "Training Batch Processed:  409\n",
            "Training Batch Processed:  410\n",
            "Training Batch Processed:  411\n",
            "Training Batch Processed:  412\n",
            "Training Batch Processed:  413\n",
            "Training Batch Processed:  414\n",
            "Training Batch Processed:  415\n",
            "Training Batch Processed:  416\n",
            "Training Batch Processed:  417\n",
            "Training Batch Processed:  418\n",
            "Training Batch Processed:  419\n",
            "Training Batch Processed:  420\n",
            "Training Batch Processed:  421\n",
            "Training Batch Processed:  422\n",
            "Training Batch Processed:  423\n",
            "Training Batch Processed:  424\n",
            "Training Batch Processed:  425\n",
            "Training Batch Processed:  426\n",
            "Training Batch Processed:  427\n",
            "Training Batch Processed:  428\n",
            "Training Batch Processed:  429\n",
            "Training Batch Processed:  430\n",
            "Training Batch Processed:  431\n",
            "Training Batch Processed:  432\n",
            "Training Batch Processed:  433\n",
            "Training Batch Processed:  434\n",
            "Training Batch Processed:  435\n",
            "Training Batch Processed:  436\n",
            "Training Batch Processed:  437\n",
            "Training Batch Processed:  438\n",
            "Training Batch Processed:  439\n",
            "Training Batch Processed:  440\n",
            "Training Batch Processed:  441\n",
            "Training Batch Processed:  442\n",
            "Training Batch Processed:  443\n",
            "Training Batch Processed:  444\n",
            "Training Batch Processed:  445\n",
            "Training Batch Processed:  446\n",
            "Training Batch Processed:  447\n",
            "Training Batch Processed:  448\n",
            "Training Batch Processed:  449\n",
            "Training Batch Processed:  450\n",
            "Training Batch Processed:  451\n",
            "Training Batch Processed:  452\n",
            "Training Batch Processed:  453\n",
            "Training Batch Processed:  454\n",
            "Training Batch Processed:  455\n",
            "Training Batch Processed:  456\n",
            "Training Batch Processed:  457\n",
            "Training Batch Processed:  458\n",
            "Training Batch Processed:  459\n",
            "Training Batch Processed:  460\n",
            "Training Batch Processed:  461\n",
            "Training Batch Processed:  462\n",
            "Training Batch Processed:  463\n",
            "Training Batch Processed:  464\n",
            "Training Batch Processed:  465\n",
            "Training Batch Processed:  466\n",
            "Training Batch Processed:  467\n",
            "Training Batch Processed:  468\n",
            "Training Batch Processed:  469\n",
            "Training Batch Processed:  470\n",
            "Training Batch Processed:  471\n",
            "Training Batch Processed:  472\n",
            "Training Batch Processed:  473\n",
            "Training Batch Processed:  474\n",
            "Training Batch Processed:  475\n",
            "Training Batch Processed:  476\n",
            "Training Batch Processed:  477\n",
            "Training Batch Processed:  478\n",
            "Training Batch Processed:  479\n",
            "Training Batch Processed:  480\n",
            "Training Batch Processed:  481\n",
            "Training Batch Processed:  482\n",
            "Training Batch Processed:  483\n",
            "Training Batch Processed:  484\n",
            "Training Batch Processed:  485\n",
            "Training Batch Processed:  486\n",
            "Training Batch Processed:  487\n",
            "Training Batch Processed:  488\n",
            "Training Batch Processed:  489\n",
            "Training Batch Processed:  490\n",
            "Training Batch Processed:  491\n",
            "Training Batch Processed:  492\n",
            "Training Batch Processed:  493\n",
            "Training Batch Processed:  494\n",
            "Training Batch Processed:  495\n",
            "Training Batch Processed:  496\n",
            "Training Batch Processed:  497\n",
            "Training Batch Processed:  498\n",
            "Training Batch Processed:  499\n",
            "Training Batch Processed:  500\n",
            "Average Training Accuracy: tensor(0.7590)\n",
            "Training Batch Processed:  501\n",
            "Training Batch Processed:  502\n",
            "Training Batch Processed:  503\n",
            "Training Batch Processed:  504\n",
            "Training Batch Processed:  505\n",
            "Training Batch Processed:  506\n",
            "Training Batch Processed:  507\n",
            "Training Batch Processed:  508\n",
            "Training Batch Processed:  509\n",
            "Training Batch Processed:  510\n",
            "Training Batch Processed:  511\n",
            "Training Batch Processed:  512\n",
            "Training Batch Processed:  513\n",
            "Training Batch Processed:  514\n",
            "Training Batch Processed:  515\n",
            "Training Batch Processed:  516\n",
            "Training Batch Processed:  517\n",
            "Training Batch Processed:  518\n",
            "Training Batch Processed:  519\n",
            "Training Batch Processed:  520\n",
            "Training Batch Processed:  521\n",
            "Training Batch Processed:  522\n",
            "Training Batch Processed:  523\n",
            "Training Batch Processed:  524\n",
            "Training Batch Processed:  525\n",
            "Training Batch Processed:  526\n",
            "Training Batch Processed:  527\n",
            "Training Batch Processed:  528\n",
            "Training Batch Processed:  529\n",
            "Training Batch Processed:  530\n",
            "Training Batch Processed:  531\n",
            "Training Batch Processed:  532\n",
            "Training Batch Processed:  533\n",
            "Training Batch Processed:  534\n",
            "Training Batch Processed:  535\n",
            "Training Batch Processed:  536\n",
            "Training Batch Processed:  537\n",
            "Training Batch Processed:  538\n",
            "Training Batch Processed:  539\n",
            "Training Batch Processed:  540\n",
            "Training Batch Processed:  541\n",
            "Training Batch Processed:  542\n",
            "Training Batch Processed:  543\n",
            "Training Batch Processed:  544\n",
            "Training Batch Processed:  545\n",
            "Training Batch Processed:  546\n",
            "Training Batch Processed:  547\n",
            "Training Batch Processed:  548\n",
            "Training Batch Processed:  549\n",
            "Training Batch Processed:  550\n",
            "Training Batch Processed:  551\n",
            "Training Batch Processed:  552\n",
            "Training Batch Processed:  553\n",
            "Training Batch Processed:  554\n",
            "Training Batch Processed:  555\n",
            "Training Batch Processed:  556\n",
            "Training Batch Processed:  557\n",
            "Training Batch Processed:  558\n",
            "Training Batch Processed:  559\n",
            "Training Batch Processed:  560\n",
            "Training Batch Processed:  561\n",
            "Training Batch Processed:  562\n",
            "Training Batch Processed:  563\n",
            "Training Batch Processed:  564\n",
            "Training Batch Processed:  565\n",
            "Training Batch Processed:  566\n",
            "Training Batch Processed:  567\n",
            "Training Batch Processed:  568\n",
            "Training Batch Processed:  569\n",
            "Training Batch Processed:  570\n",
            "Training Batch Processed:  571\n",
            "Training Batch Processed:  572\n",
            "Training Batch Processed:  573\n",
            "Training Batch Processed:  574\n",
            "Training Batch Processed:  575\n",
            "Training Batch Processed:  576\n",
            "Training Batch Processed:  577\n",
            "Training Batch Processed:  578\n",
            "Training Batch Processed:  579\n",
            "Training Batch Processed:  580\n",
            "Training Batch Processed:  581\n",
            "Training Batch Processed:  582\n",
            "Training Batch Processed:  583\n",
            "Training Batch Processed:  584\n",
            "Training Batch Processed:  585\n",
            "Training Batch Processed:  586\n",
            "Training Batch Processed:  587\n",
            "Training Batch Processed:  588\n",
            "Training Batch Processed:  589\n",
            "Training Batch Processed:  590\n",
            "Training Batch Processed:  591\n",
            "Training Batch Processed:  592\n",
            "Training Batch Processed:  593\n",
            "Training Batch Processed:  594\n",
            "Training Batch Processed:  595\n",
            "Training Batch Processed:  596\n",
            "Training Batch Processed:  597\n",
            "Training Batch Processed:  598\n",
            "Training Batch Processed:  599\n",
            "Training Batch Processed:  600\n",
            "Average Training Accuracy: tensor(0.7655)\n",
            "Training Batch Processed:  601\n",
            "Training Batch Processed:  602\n",
            "Training Batch Processed:  603\n",
            "Training Batch Processed:  604\n",
            "Training Batch Processed:  605\n",
            "Training Batch Processed:  606\n",
            "Training Batch Processed:  607\n",
            "Training Batch Processed:  608\n",
            "Training Batch Processed:  609\n",
            "Training Batch Processed:  610\n",
            "Training Batch Processed:  611\n",
            "Training Batch Processed:  612\n",
            "Training Batch Processed:  613\n",
            "Training Batch Processed:  614\n",
            "Training Batch Processed:  615\n",
            "Training Batch Processed:  616\n",
            "Training Batch Processed:  617\n",
            "Training Batch Processed:  618\n",
            "Training Batch Processed:  619\n",
            "Training Batch Processed:  620\n",
            "Training Batch Processed:  621\n",
            "Training Batch Processed:  622\n",
            "Training Batch Processed:  623\n",
            "Training Batch Processed:  624\n",
            "Training Batch Processed:  625\n",
            "Training Batch Processed:  626\n",
            "Training Batch Processed:  627\n",
            "Training Batch Processed:  628\n",
            "Training Batch Processed:  629\n",
            "Training Batch Processed:  630\n",
            "Training Batch Processed:  631\n",
            "Training Batch Processed:  632\n",
            "Training Batch Processed:  633\n",
            "Training Batch Processed:  634\n",
            "Training Batch Processed:  635\n",
            "Training Batch Processed:  636\n",
            "Training Batch Processed:  637\n",
            "Training Batch Processed:  638\n",
            "Training Batch Processed:  639\n",
            "Training Batch Processed:  640\n",
            "Training Batch Processed:  641\n",
            "Training Batch Processed:  642\n",
            "Training Batch Processed:  643\n",
            "Training Batch Processed:  644\n",
            "Training Batch Processed:  645\n",
            "Training Batch Processed:  646\n",
            "Training Batch Processed:  647\n",
            "Training Batch Processed:  648\n",
            "Training Batch Processed:  649\n",
            "Training Batch Processed:  650\n",
            "Training Batch Processed:  651\n",
            "Training Batch Processed:  652\n",
            "Training Batch Processed:  653\n",
            "Training Batch Processed:  654\n",
            "Training Batch Processed:  655\n",
            "Training Batch Processed:  656\n",
            "Training Batch Processed:  657\n",
            "Training Batch Processed:  658\n",
            "Training Batch Processed:  659\n",
            "Training Batch Processed:  660\n",
            "Training Batch Processed:  661\n",
            "Training Batch Processed:  662\n",
            "Training Batch Processed:  663\n",
            "Training Batch Processed:  664\n",
            "Training Batch Processed:  665\n",
            "Training Batch Processed:  666\n",
            "Training Batch Processed:  667\n",
            "Training Batch Processed:  668\n",
            "Training Batch Processed:  669\n",
            "Training Batch Processed:  670\n",
            "Training Batch Processed:  671\n",
            "Training Batch Processed:  672\n",
            "Training Batch Processed:  673\n",
            "Training Batch Processed:  674\n",
            "Training Batch Processed:  675\n",
            "Training Batch Processed:  676\n",
            "Training Batch Processed:  677\n",
            "Training Batch Processed:  678\n",
            "Training Batch Processed:  679\n",
            "Training Batch Processed:  680\n",
            "Training Batch Processed:  681\n",
            "Training Batch Processed:  682\n",
            "Training Batch Processed:  683\n",
            "Training Batch Processed:  684\n",
            "Training Batch Processed:  685\n",
            "Training Batch Processed:  686\n",
            "Training Batch Processed:  687\n",
            "Training Batch Processed:  688\n",
            "Training Batch Processed:  689\n",
            "Training Batch Processed:  690\n",
            "Training Batch Processed:  691\n",
            "Training Batch Processed:  692\n",
            "Training Batch Processed:  693\n",
            "Training Batch Processed:  694\n",
            "Training Batch Processed:  695\n",
            "Training Batch Processed:  696\n",
            "Training Batch Processed:  697\n",
            "Training Batch Processed:  698\n",
            "Training Batch Processed:  699\n",
            "Training Batch Processed:  700\n",
            "Average Training Accuracy: tensor(0.7714)\n",
            "Training Batch Processed:  701\n",
            "Training Batch Processed:  702\n",
            "Training Batch Processed:  703\n",
            "Training Batch Processed:  704\n",
            "Training Batch Processed:  705\n",
            "Training Batch Processed:  706\n",
            "Training Batch Processed:  707\n",
            "Training Batch Processed:  708\n",
            "Training Batch Processed:  709\n",
            "Training Batch Processed:  710\n",
            "Training Batch Processed:  711\n",
            "Training Batch Processed:  712\n",
            "Training Batch Processed:  713\n",
            "Training Batch Processed:  714\n",
            "Training Batch Processed:  715\n",
            "Training Batch Processed:  716\n",
            "Training Batch Processed:  717\n",
            "Training Batch Processed:  718\n",
            "Training Batch Processed:  719\n",
            "Training Batch Processed:  720\n",
            "Training Batch Processed:  721\n",
            "Training Batch Processed:  722\n",
            "Training Batch Processed:  723\n",
            "Training Batch Processed:  724\n",
            "Training Batch Processed:  725\n",
            "Training Batch Processed:  726\n",
            "Training Batch Processed:  727\n",
            "Training Batch Processed:  728\n",
            "Training Batch Processed:  729\n",
            "Training Batch Processed:  730\n",
            "Training Batch Processed:  731\n",
            "Training Batch Processed:  732\n",
            "Training Batch Processed:  733\n",
            "Training Batch Processed:  734\n",
            "Training Batch Processed:  735\n",
            "Training Batch Processed:  736\n",
            "Training Batch Processed:  737\n",
            "Training Batch Processed:  738\n",
            "Training Batch Processed:  739\n",
            "Training Batch Processed:  740\n",
            "Training Batch Processed:  741\n",
            "Training Batch Processed:  742\n",
            "Training Batch Processed:  743\n",
            "Training Batch Processed:  744\n",
            "Training Batch Processed:  745\n",
            "Training Batch Processed:  746\n",
            "Training Batch Processed:  747\n",
            "Training Batch Processed:  748\n",
            "Training Batch Processed:  749\n",
            "Training Batch Processed:  750\n",
            "Training Batch Processed:  751\n",
            "Training Batch Processed:  752\n",
            "Training Batch Processed:  753\n",
            "Training Batch Processed:  754\n",
            "Training Batch Processed:  755\n",
            "Training Batch Processed:  756\n",
            "Training Batch Processed:  757\n",
            "Training Batch Processed:  758\n",
            "Training Batch Processed:  759\n",
            "Training Batch Processed:  760\n",
            "Training Batch Processed:  761\n",
            "Training Batch Processed:  762\n",
            "Training Batch Processed:  763\n",
            "Training Batch Processed:  764\n",
            "Training Batch Processed:  765\n",
            "Training Batch Processed:  766\n",
            "Training Batch Processed:  767\n",
            "Training Batch Processed:  768\n",
            "Training Batch Processed:  769\n",
            "Training Batch Processed:  770\n",
            "Training Batch Processed:  771\n",
            "Training Batch Processed:  772\n",
            "Training Batch Processed:  773\n",
            "Training Batch Processed:  774\n",
            "Training Batch Processed:  775\n",
            "Training Batch Processed:  776\n",
            "Training Batch Processed:  777\n",
            "Training Batch Processed:  778\n",
            "Training Batch Processed:  779\n",
            "Training Batch Processed:  780\n",
            "Training Batch Processed:  781\n",
            "Training Batch Processed:  782\n",
            "Training Batch Processed:  783\n",
            "Training Batch Processed:  784\n",
            "Training Batch Processed:  785\n",
            "Training Batch Processed:  786\n",
            "Training Batch Processed:  787\n",
            "Training Batch Processed:  788\n",
            "Training Batch Processed:  789\n",
            "Training Batch Processed:  790\n",
            "Training Batch Processed:  791\n",
            "Training Batch Processed:  792\n",
            "Training Batch Processed:  793\n",
            "Training Batch Processed:  794\n",
            "Training Batch Processed:  795\n",
            "Training Batch Processed:  796\n",
            "Training Batch Processed:  797\n",
            "Training Batch Processed:  798\n",
            "Training Batch Processed:  799\n",
            "Training Batch Processed:  800\n",
            "Average Training Accuracy: tensor(0.7761)\n",
            "Training Batch Processed:  801\n",
            "Training Batch Processed:  802\n",
            "Training Batch Processed:  803\n",
            "Training Batch Processed:  804\n",
            "Training Batch Processed:  805\n",
            "Training Batch Processed:  806\n",
            "Training Batch Processed:  807\n",
            "Training Batch Processed:  808\n",
            "Training Batch Processed:  809\n",
            "Training Batch Processed:  810\n",
            "Training Batch Processed:  811\n",
            "Training Batch Processed:  812\n",
            "Training Batch Processed:  813\n",
            "Training Batch Processed:  814\n",
            "Training Batch Processed:  815\n",
            "Training Batch Processed:  816\n",
            "Training Batch Processed:  817\n",
            "Training Batch Processed:  818\n",
            "Training Batch Processed:  819\n",
            "Training Batch Processed:  820\n",
            "Training Batch Processed:  821\n",
            "Training Batch Processed:  822\n",
            "Training Batch Processed:  823\n",
            "Training Batch Processed:  824\n",
            "Training Batch Processed:  825\n",
            "Training Batch Processed:  826\n",
            "Training Batch Processed:  827\n",
            "Training Batch Processed:  828\n",
            "Training Batch Processed:  829\n",
            "Training Batch Processed:  830\n",
            "Training Batch Processed:  831\n",
            "Training Batch Processed:  832\n",
            "Training Batch Processed:  833\n",
            "Training Batch Processed:  834\n",
            "Training Batch Processed:  835\n",
            "Training Batch Processed:  836\n",
            "Training Batch Processed:  837\n",
            "Training Batch Processed:  838\n",
            "Training Batch Processed:  839\n",
            "Training Batch Processed:  840\n",
            "Training Batch Processed:  841\n",
            "Training Batch Processed:  842\n",
            "Training Batch Processed:  843\n",
            "Training Batch Processed:  844\n",
            "Training Batch Processed:  845\n",
            "Training Batch Processed:  846\n",
            "Training Batch Processed:  847\n",
            "Training Batch Processed:  848\n",
            "Training Batch Processed:  849\n",
            "Training Batch Processed:  850\n",
            "Training Batch Processed:  851\n",
            "Training Batch Processed:  852\n",
            "Training Batch Processed:  853\n",
            "Training Batch Processed:  854\n",
            "Training Batch Processed:  855\n",
            "Training Batch Processed:  856\n",
            "Training Batch Processed:  857\n",
            "Training Batch Processed:  858\n",
            "Training Batch Processed:  859\n",
            "Training Batch Processed:  860\n",
            "Training Batch Processed:  861\n",
            "Training Batch Processed:  862\n",
            "Training Batch Processed:  863\n",
            "Training Batch Processed:  864\n",
            "Training Batch Processed:  865\n",
            "Training Batch Processed:  866\n",
            "Training Batch Processed:  867\n",
            "Training Batch Processed:  868\n",
            "Training Batch Processed:  869\n",
            "Training Batch Processed:  870\n",
            "Training Batch Processed:  871\n",
            "Training Batch Processed:  872\n",
            "Training Batch Processed:  873\n",
            "Training Batch Processed:  874\n",
            "Training Batch Processed:  875\n",
            "Training Batch Processed:  876\n",
            "Training Batch Processed:  877\n",
            "Training Batch Processed:  878\n",
            "Training Batch Processed:  879\n",
            "Training Batch Processed:  880\n",
            "Training Batch Processed:  881\n",
            "Training Batch Processed:  882\n",
            "Training Batch Processed:  883\n",
            "Training Batch Processed:  884\n",
            "Training Batch Processed:  885\n",
            "Training Batch Processed:  886\n",
            "Training Batch Processed:  887\n",
            "Training Batch Processed:  888\n",
            "Training Batch Processed:  889\n",
            "Training Batch Processed:  890\n",
            "Training Batch Processed:  891\n",
            "Training Batch Processed:  892\n",
            "Training Batch Processed:  893\n",
            "Training Batch Processed:  894\n",
            "Training Batch Processed:  895\n",
            "Training Batch Processed:  896\n",
            "Training Batch Processed:  897\n",
            "Training Batch Processed:  898\n",
            "Training Batch Processed:  899\n",
            "Training Batch Processed:  900\n",
            "Average Training Accuracy: tensor(0.7801)\n",
            "Training Batch Processed:  901\n",
            "Training Batch Processed:  902\n",
            "Training Batch Processed:  903\n",
            "Training Batch Processed:  904\n",
            "Training Batch Processed:  905\n",
            "Training Batch Processed:  906\n",
            "Training Batch Processed:  907\n",
            "Training Batch Processed:  908\n",
            "Training Batch Processed:  909\n",
            "Training Batch Processed:  910\n",
            "Training Batch Processed:  911\n",
            "Training Batch Processed:  912\n",
            "Training Batch Processed:  913\n",
            "Training Batch Processed:  914\n",
            "Training Batch Processed:  915\n",
            "Training Batch Processed:  916\n",
            "Training Batch Processed:  917\n",
            "Training Batch Processed:  918\n",
            "Training Batch Processed:  919\n",
            "Training Batch Processed:  920\n",
            "Training Batch Processed:  921\n",
            "Training Batch Processed:  922\n",
            "Training Batch Processed:  923\n",
            "Training Batch Processed:  924\n",
            "Training Batch Processed:  925\n",
            "Training Batch Processed:  926\n",
            "Training Batch Processed:  927\n",
            "Training Batch Processed:  928\n",
            "Training Batch Processed:  929\n",
            "Training Batch Processed:  930\n",
            "Training Batch Processed:  931\n",
            "Training Batch Processed:  932\n",
            "Training Batch Processed:  933\n",
            "Training Batch Processed:  934\n",
            "Training Batch Processed:  935\n",
            "Training Batch Processed:  936\n",
            "Training Batch Processed:  937\n",
            "Training Batch Processed:  938\n",
            "Training Batch Processed:  939\n",
            "Training Batch Processed:  940\n",
            "Training Batch Processed:  941\n",
            "Training Batch Processed:  942\n",
            "Training Batch Processed:  943\n",
            "Training Batch Processed:  944\n",
            "Training Batch Processed:  945\n",
            "Training Batch Processed:  946\n",
            "Training Batch Processed:  947\n",
            "Training Batch Processed:  948\n",
            "Training Batch Processed:  949\n",
            "Training Batch Processed:  950\n",
            "Training Batch Processed:  951\n",
            "Training Batch Processed:  952\n",
            "Training Batch Processed:  953\n",
            "Training Batch Processed:  954\n",
            "Training Batch Processed:  955\n",
            "Training Batch Processed:  956\n",
            "Training Batch Processed:  957\n",
            "Training Batch Processed:  958\n",
            "Training Batch Processed:  959\n",
            "Training Batch Processed:  960\n",
            "Training Batch Processed:  961\n",
            "Training Batch Processed:  962\n",
            "Training Batch Processed:  963\n",
            "Training Batch Processed:  964\n",
            "Training Batch Processed:  965\n",
            "Training Batch Processed:  966\n",
            "Training Batch Processed:  967\n",
            "Training Batch Processed:  968\n",
            "Training Batch Processed:  969\n",
            "Training Batch Processed:  970\n",
            "Training Batch Processed:  971\n",
            "Training Batch Processed:  972\n",
            "Training Batch Processed:  973\n",
            "Training Batch Processed:  974\n",
            "Training Batch Processed:  975\n",
            "Training Batch Processed:  976\n",
            "Training Batch Processed:  977\n",
            "Training Batch Processed:  978\n",
            "Training Batch Processed:  979\n",
            "Training Batch Processed:  980\n",
            "Training Batch Processed:  981\n",
            "Training Batch Processed:  982\n",
            "Training Batch Processed:  983\n",
            "Training Batch Processed:  984\n",
            "Training Batch Processed:  985\n",
            "Training Batch Processed:  986\n",
            "Training Batch Processed:  987\n",
            "Training Batch Processed:  988\n",
            "Training Batch Processed:  989\n",
            "Training Batch Processed:  990\n",
            "Training Batch Processed:  991\n",
            "Training Batch Processed:  992\n",
            "Training Batch Processed:  993\n",
            "Training Batch Processed:  994\n",
            "Training Batch Processed:  995\n",
            "Training Batch Processed:  996\n",
            "Training Batch Processed:  997\n",
            "Training Batch Processed:  998\n",
            "Training Batch Processed:  999\n",
            "Training Batch Processed:  1000\n",
            "Average Training Accuracy: tensor(0.7840)\n",
            "Training Batch Processed:  1001\n",
            "Training Batch Processed:  1002\n",
            "Training Batch Processed:  1003\n",
            "Training Batch Processed:  1004\n",
            "Training Batch Processed:  1005\n",
            "Training Batch Processed:  1006\n",
            "Training Batch Processed:  1007\n",
            "Training Batch Processed:  1008\n",
            "Training Batch Processed:  1009\n",
            "Training Batch Processed:  1010\n",
            "Training Batch Processed:  1011\n",
            "Training Batch Processed:  1012\n",
            "Training Batch Processed:  1013\n",
            "Training Batch Processed:  1014\n",
            "Training Batch Processed:  1015\n",
            "Training Batch Processed:  1016\n",
            "Training Batch Processed:  1017\n",
            "Training Batch Processed:  1018\n",
            "Training Batch Processed:  1019\n",
            "Training Batch Processed:  1020\n",
            "Training Batch Processed:  1021\n",
            "Training Batch Processed:  1022\n",
            "Training Batch Processed:  1023\n",
            "Training Batch Processed:  1024\n",
            "Training Batch Processed:  1025\n",
            "Training Batch Processed:  1026\n",
            "Training Batch Processed:  1027\n",
            "Training Batch Processed:  1028\n",
            "Training Batch Processed:  1029\n",
            "Training Batch Processed:  1030\n",
            "Training Batch Processed:  1031\n",
            "Training Batch Processed:  1032\n",
            "Training Batch Processed:  1033\n",
            "Training Batch Processed:  1034\n",
            "Training Batch Processed:  1035\n",
            "Training Batch Processed:  1036\n",
            "Training Batch Processed:  1037\n",
            "Training Batch Processed:  1038\n",
            "Training Batch Processed:  1039\n",
            "Training Batch Processed:  1040\n",
            "Training Batch Processed:  1041\n",
            "Training Batch Processed:  1042\n",
            "Training Batch Processed:  1043\n",
            "Training Batch Processed:  1044\n",
            "Training Batch Processed:  1045\n",
            "Training Batch Processed:  1046\n",
            "Training Batch Processed:  1047\n",
            "Training Batch Processed:  1048\n",
            "Training Batch Processed:  1049\n",
            "Training Batch Processed:  1050\n",
            "Training Batch Processed:  1051\n",
            "Training Batch Processed:  1052\n",
            "Training Batch Processed:  1053\n",
            "Training Batch Processed:  1054\n",
            "Training Batch Processed:  1055\n",
            "Training Batch Processed:  1056\n",
            "Training Batch Processed:  1057\n",
            "Training Batch Processed:  1058\n",
            "Training Batch Processed:  1059\n",
            "Training Batch Processed:  1060\n",
            "Training Batch Processed:  1061\n",
            "Training Batch Processed:  1062\n",
            "Training Batch Processed:  1063\n",
            "Training Batch Processed:  1064\n",
            "Training Batch Processed:  1065\n",
            "Training Batch Processed:  1066\n",
            "Training Batch Processed:  1067\n",
            "Training Batch Processed:  1068\n",
            "Training Batch Processed:  1069\n",
            "Training Batch Processed:  1070\n",
            "Training Batch Processed:  1071\n",
            "Training Batch Processed:  1072\n",
            "Training Batch Processed:  1073\n",
            "Training Batch Processed:  1074\n",
            "Training Batch Processed:  1075\n",
            "Training Batch Processed:  1076\n",
            "Training Batch Processed:  1077\n",
            "Training Batch Processed:  1078\n",
            "Training Batch Processed:  1079\n",
            "Training Batch Processed:  1080\n",
            "Training Batch Processed:  1081\n",
            "Training Batch Processed:  1082\n",
            "Training Batch Processed:  1083\n",
            "Training Batch Processed:  1084\n",
            "Training Batch Processed:  1085\n",
            "Training Batch Processed:  1086\n",
            "Training Batch Processed:  1087\n",
            "Training Batch Processed:  1088\n",
            "Training Batch Processed:  1089\n",
            "Training Batch Processed:  1090\n",
            "Training Batch Processed:  1091\n",
            "Training Batch Processed:  1092\n",
            "Training Batch Processed:  1093\n",
            "Training Batch Processed:  1094\n",
            "Training Batch Processed:  1095\n",
            "Training Batch Processed:  1096\n",
            "Training Batch Processed:  1097\n",
            "Training Batch Processed:  1098\n",
            "Training Batch Processed:  1099\n",
            "Training Batch Processed:  1100\n",
            "Average Training Accuracy: tensor(0.7870)\n",
            "Training Batch Processed:  1101\n",
            "Training Batch Processed:  1102\n",
            "Training Batch Processed:  1103\n",
            "Training Batch Processed:  1104\n",
            "Training Batch Processed:  1105\n",
            "Training Batch Processed:  1106\n",
            "Training Batch Processed:  1107\n",
            "Training Batch Processed:  1108\n",
            "Training Batch Processed:  1109\n",
            "Training Batch Processed:  1110\n",
            "Training Batch Processed:  1111\n",
            "Training Batch Processed:  1112\n",
            "Training Batch Processed:  1113\n",
            "Training Batch Processed:  1114\n",
            "Training Batch Processed:  1115\n",
            "Training Batch Processed:  1116\n",
            "Training Batch Processed:  1117\n",
            "Training Batch Processed:  1118\n",
            "Training Batch Processed:  1119\n",
            "Training Batch Processed:  1120\n",
            "Training Batch Processed:  1121\n",
            "Training Batch Processed:  1122\n",
            "Training Batch Processed:  1123\n",
            "Training Batch Processed:  1124\n",
            "Training Batch Processed:  1125\n",
            "Training Batch Processed:  1126\n",
            "Training Batch Processed:  1127\n",
            "Training Batch Processed:  1128\n",
            "Training Batch Processed:  1129\n",
            "Training Batch Processed:  1130\n",
            "Training Batch Processed:  1131\n",
            "Training Batch Processed:  1132\n",
            "Training Batch Processed:  1133\n",
            "Training Batch Processed:  1134\n",
            "Training Batch Processed:  1135\n",
            "Training Batch Processed:  1136\n",
            "Training Batch Processed:  1137\n",
            "Training Batch Processed:  1138\n",
            "Training Batch Processed:  1139\n",
            "Training Batch Processed:  1140\n",
            "Training Batch Processed:  1141\n",
            "Training Batch Processed:  1142\n",
            "Training Batch Processed:  1143\n",
            "Training Batch Processed:  1144\n",
            "Training Batch Processed:  1145\n",
            "Training Batch Processed:  1146\n",
            "Training Batch Processed:  1147\n",
            "Training Batch Processed:  1148\n",
            "Training Batch Processed:  1149\n",
            "Training Batch Processed:  1150\n",
            "Training Batch Processed:  1151\n",
            "Training Batch Processed:  1152\n",
            "Training Batch Processed:  1153\n",
            "Training Batch Processed:  1154\n",
            "Training Batch Processed:  1155\n",
            "Training Batch Processed:  1156\n",
            "Training Batch Processed:  1157\n",
            "Training Batch Processed:  1158\n",
            "Training Batch Processed:  1159\n",
            "Training Batch Processed:  1160\n",
            "Training Batch Processed:  1161\n",
            "Training Batch Processed:  1162\n",
            "Training Batch Processed:  1163\n",
            "Training Batch Processed:  1164\n",
            "Training Batch Processed:  1165\n",
            "Training Batch Processed:  1166\n",
            "Training Batch Processed:  1167\n",
            "Training Batch Processed:  1168\n",
            "Training Batch Processed:  1169\n",
            "Training Batch Processed:  1170\n",
            "Training Batch Processed:  1171\n",
            "Training Batch Processed:  1172\n",
            "Training Batch Processed:  1173\n",
            "Training Batch Processed:  1174\n",
            "Training Batch Processed:  1175\n",
            "Training Batch Processed:  1176\n",
            "Training Batch Processed:  1177\n",
            "Training Batch Processed:  1178\n",
            "Training Batch Processed:  1179\n",
            "Training Batch Processed:  1180\n",
            "Training Batch Processed:  1181\n",
            "Training Batch Processed:  1182\n",
            "Training Batch Processed:  1183\n",
            "Training Batch Processed:  1184\n",
            "Training Batch Processed:  1185\n",
            "Training Batch Processed:  1186\n",
            "Training Batch Processed:  1187\n",
            "Training Batch Processed:  1188\n",
            "Training Batch Processed:  1189\n",
            "Training Batch Processed:  1190\n",
            "Training Batch Processed:  1191\n",
            "Training Batch Processed:  1192\n",
            "Training Batch Processed:  1193\n",
            "Training Batch Processed:  1194\n",
            "Training Batch Processed:  1195\n",
            "Training Batch Processed:  1196\n",
            "Training Batch Processed:  1197\n",
            "Training Batch Processed:  1198\n",
            "Training Batch Processed:  1199\n",
            "Training Batch Processed:  1200\n",
            "Average Training Accuracy: tensor(0.7899)\n",
            "Training Batch Processed:  1201\n",
            "Training Batch Processed:  1202\n",
            "Training Batch Processed:  1203\n",
            "Training Batch Processed:  1204\n",
            "Training Batch Processed:  1205\n",
            "Training Batch Processed:  1206\n",
            "Training Batch Processed:  1207\n",
            "Training Batch Processed:  1208\n",
            "Training Batch Processed:  1209\n",
            "Training Batch Processed:  1210\n",
            "Training Batch Processed:  1211\n",
            "Training Batch Processed:  1212\n",
            "Training Batch Processed:  1213\n",
            "Training Batch Processed:  1214\n",
            "Training Batch Processed:  1215\n",
            "Training Batch Processed:  1216\n",
            "Training Batch Processed:  1217\n",
            "Training Batch Processed:  1218\n",
            "Training Batch Processed:  1219\n",
            "Training Batch Processed:  1220\n",
            "Training Batch Processed:  1221\n",
            "Training Batch Processed:  1222\n",
            "Training Batch Processed:  1223\n",
            "Training Batch Processed:  1224\n",
            "Training Batch Processed:  1225\n",
            "Training Batch Processed:  1226\n",
            "Training Batch Processed:  1227\n",
            "Training Batch Processed:  1228\n",
            "Training Batch Processed:  1229\n",
            "Training Batch Processed:  1230\n",
            "Training Batch Processed:  1231\n",
            "Training Batch Processed:  1232\n",
            "Training Batch Processed:  1233\n",
            "Training Batch Processed:  1234\n",
            "Training Batch Processed:  1235\n",
            "Training Batch Processed:  1236\n",
            "Training Batch Processed:  1237\n",
            "Training Batch Processed:  1238\n",
            "Training Batch Processed:  1239\n",
            "Training Batch Processed:  1240\n",
            "Training Batch Processed:  1241\n",
            "Training Batch Processed:  1242\n",
            "Training Batch Processed:  1243\n",
            "Training Batch Processed:  1244\n",
            "Training Batch Processed:  1245\n",
            "Training Batch Processed:  1246\n",
            "Training Batch Processed:  1247\n",
            "Training Batch Processed:  1248\n",
            "Training Batch Processed:  1249\n",
            "Training Batch Processed:  1250\n",
            "Training Batch Processed:  1251\n",
            "Training Batch Processed:  1252\n",
            "Training Batch Processed:  1253\n",
            "Training Batch Processed:  1254\n",
            "Training Batch Processed:  1255\n",
            "Training Batch Processed:  1256\n",
            "Training Batch Processed:  1257\n",
            "Training Batch Processed:  1258\n",
            "Training Batch Processed:  1259\n",
            "Training Batch Processed:  1260\n",
            "Training Batch Processed:  1261\n",
            "Training Batch Processed:  1262\n",
            "Training Batch Processed:  1263\n",
            "Training Batch Processed:  1264\n",
            "Training Batch Processed:  1265\n",
            "Training Batch Processed:  1266\n",
            "Training Batch Processed:  1267\n",
            "Training Batch Processed:  1268\n",
            "Training Batch Processed:  1269\n",
            "Training Batch Processed:  1270\n",
            "Training Batch Processed:  1271\n",
            "Training Batch Processed:  1272\n",
            "Training Batch Processed:  1273\n",
            "Training Batch Processed:  1274\n",
            "Training Batch Processed:  1275\n",
            "Training Batch Processed:  1276\n",
            "Training Batch Processed:  1277\n",
            "Training Batch Processed:  1278\n",
            "Training Batch Processed:  1279\n",
            "Training Batch Processed:  1280\n",
            "Training Batch Processed:  1281\n",
            "Training Batch Processed:  1282\n",
            "Training Batch Processed:  1283\n",
            "Training Batch Processed:  1284\n",
            "Training Batch Processed:  1285\n",
            "Training Batch Processed:  1286\n",
            "Training Batch Processed:  1287\n",
            "Training Batch Processed:  1288\n",
            "Training Batch Processed:  1289\n",
            "Training Batch Processed:  1290\n",
            "Training Batch Processed:  1291\n",
            "Training Batch Processed:  1292\n",
            "Training Batch Processed:  1293\n",
            "Training Batch Processed:  1294\n",
            "Training Batch Processed:  1295\n",
            "Training Batch Processed:  1296\n",
            "Training Batch Processed:  1297\n",
            "Training Batch Processed:  1298\n",
            "Training Batch Processed:  1299\n",
            "Training Batch Processed:  1300\n",
            "Average Training Accuracy: tensor(0.7921)\n",
            "Training Batch Processed:  1301\n",
            "Training Batch Processed:  1302\n",
            "Training Batch Processed:  1303\n",
            "Training Batch Processed:  1304\n",
            "Training Batch Processed:  1305\n",
            "Training Batch Processed:  1306\n",
            "Training Batch Processed:  1307\n",
            "Training Batch Processed:  1308\n",
            "Training Batch Processed:  1309\n",
            "Training Batch Processed:  1310\n",
            "Training Batch Processed:  1311\n",
            "Training Batch Processed:  1312\n",
            "Training Batch Processed:  1313\n",
            "Training Batch Processed:  1314\n",
            "Training Batch Processed:  1315\n",
            "Training Batch Processed:  1316\n",
            "Training Batch Processed:  1317\n",
            "Training Batch Processed:  1318\n",
            "Training Batch Processed:  1319\n",
            "Training Batch Processed:  1320\n",
            "Training Batch Processed:  1321\n",
            "Training Batch Processed:  1322\n",
            "Training Batch Processed:  1323\n",
            "Training Batch Processed:  1324\n",
            "Training Batch Processed:  1325\n",
            "Training Batch Processed:  1326\n",
            "Training Batch Processed:  1327\n",
            "Training Batch Processed:  1328\n",
            "Training Batch Processed:  1329\n",
            "Training Batch Processed:  1330\n",
            "Training Batch Processed:  1331\n",
            "Training Batch Processed:  1332\n",
            "Training Batch Processed:  1333\n",
            "Training Batch Processed:  1334\n",
            "Training Batch Processed:  1335\n",
            "Training Batch Processed:  1336\n",
            "Training Batch Processed:  1337\n",
            "Training Batch Processed:  1338\n",
            "Training Batch Processed:  1339\n",
            "Training Batch Processed:  1340\n",
            "Training Batch Processed:  1341\n",
            "Training Batch Processed:  1342\n",
            "Training Batch Processed:  1343\n",
            "Training Batch Processed:  1344\n",
            "Training Batch Processed:  1345\n",
            "Training Batch Processed:  1346\n",
            "Training Batch Processed:  1347\n",
            "Training Batch Processed:  1348\n",
            "Training Batch Processed:  1349\n",
            "Training Batch Processed:  1350\n",
            "Training Batch Processed:  1351\n",
            "Training Batch Processed:  1352\n",
            "Training Batch Processed:  1353\n",
            "Training Batch Processed:  1354\n",
            "Training Batch Processed:  1355\n",
            "Training Batch Processed:  1356\n",
            "Training Batch Processed:  1357\n",
            "Training Batch Processed:  1358\n",
            "Training Batch Processed:  1359\n",
            "Training Batch Processed:  1360\n",
            "Training Batch Processed:  1361\n",
            "Training Batch Processed:  1362\n",
            "Training Batch Processed:  1363\n",
            "Training Batch Processed:  1364\n",
            "Training Batch Processed:  1365\n",
            "Training Batch Processed:  1366\n",
            "Training Batch Processed:  1367\n",
            "Training Batch Processed:  1368\n",
            "Training Batch Processed:  1369\n",
            "Training Batch Processed:  1370\n",
            "Training Batch Processed:  1371\n",
            "Training Batch Processed:  1372\n",
            "Training Batch Processed:  1373\n",
            "Training Batch Processed:  1374\n",
            "Training Batch Processed:  1375\n",
            "Training Batch Processed:  1376\n",
            "Training Batch Processed:  1377\n",
            "Training Batch Processed:  1378\n",
            "Training Batch Processed:  1379\n",
            "Training Batch Processed:  1380\n",
            "Training Batch Processed:  1381\n",
            "Training Batch Processed:  1382\n",
            "Training Batch Processed:  1383\n",
            "Training Batch Processed:  1384\n",
            "Training Batch Processed:  1385\n",
            "Training Batch Processed:  1386\n",
            "Training Batch Processed:  1387\n",
            "Training Batch Processed:  1388\n",
            "Training Batch Processed:  1389\n",
            "Training Batch Processed:  1390\n",
            "Training Batch Processed:  1391\n",
            "Training Batch Processed:  1392\n",
            "Training Batch Processed:  1393\n",
            "Training Batch Processed:  1394\n",
            "Training Batch Processed:  1395\n",
            "Training Batch Processed:  1396\n",
            "Training Batch Processed:  1397\n",
            "Training Batch Processed:  1398\n",
            "Training Batch Processed:  1399\n",
            "Training Batch Processed:  1400\n",
            "Average Training Accuracy: tensor(0.7944)\n",
            "Training Batch Processed:  1401\n",
            "Training Batch Processed:  1402\n",
            "Training Batch Processed:  1403\n",
            "Training Batch Processed:  1404\n",
            "Training Batch Processed:  1405\n",
            "Training Batch Processed:  1406\n",
            "Training Batch Processed:  1407\n",
            "Training Batch Processed:  1408\n",
            "Training Batch Processed:  1409\n",
            "Training Batch Processed:  1410\n",
            "Training Batch Processed:  1411\n",
            "Training Batch Processed:  1412\n",
            "Training Batch Processed:  1413\n",
            "Training Batch Processed:  1414\n",
            "Training Batch Processed:  1415\n",
            "Training Batch Processed:  1416\n",
            "Training Batch Processed:  1417\n",
            "Training Batch Processed:  1418\n",
            "Training Batch Processed:  1419\n",
            "Training Batch Processed:  1420\n",
            "Training Batch Processed:  1421\n",
            "Training Batch Processed:  1422\n",
            "Training Batch Processed:  1423\n",
            "Training Batch Processed:  1424\n",
            "Training Batch Processed:  1425\n",
            "Training Batch Processed:  1426\n",
            "Training Batch Processed:  1427\n",
            "Training Batch Processed:  1428\n",
            "Training Batch Processed:  1429\n",
            "Training Batch Processed:  1430\n",
            "Training Batch Processed:  1431\n",
            "Training Batch Processed:  1432\n",
            "Training Batch Processed:  1433\n",
            "Training Batch Processed:  1434\n",
            "Training Batch Processed:  1435\n",
            "Training Batch Processed:  1436\n",
            "Training Batch Processed:  1437\n",
            "Training Batch Processed:  1438\n",
            "Training Batch Processed:  1439\n",
            "Training Batch Processed:  1440\n",
            "Training Batch Processed:  1441\n",
            "Training Batch Processed:  1442\n",
            "Training Batch Processed:  1443\n",
            "Training Batch Processed:  1444\n",
            "Training Batch Processed:  1445\n",
            "Training Batch Processed:  1446\n",
            "Training Batch Processed:  1447\n",
            "Training Batch Processed:  1448\n",
            "Training Batch Processed:  1449\n",
            "Training Batch Processed:  1450\n",
            "Training Batch Processed:  1451\n",
            "Training Batch Processed:  1452\n",
            "Training Batch Processed:  1453\n",
            "Training Batch Processed:  1454\n",
            "Training Batch Processed:  1455\n",
            "Training Batch Processed:  1456\n",
            "Training Batch Processed:  1457\n",
            "Training Batch Processed:  1458\n",
            "Training Batch Processed:  1459\n",
            "Training Batch Processed:  1460\n",
            "Training Batch Processed:  1461\n",
            "Training Batch Processed:  1462\n",
            "Training Batch Processed:  1463\n",
            "Training Batch Processed:  1464\n",
            "Training Batch Processed:  1465\n",
            "Training Batch Processed:  1466\n",
            "Training Batch Processed:  1467\n",
            "Training Batch Processed:  1468\n",
            "Training Batch Processed:  1469\n",
            "Training Batch Processed:  1470\n",
            "Training Batch Processed:  1471\n",
            "Training Batch Processed:  1472\n",
            "Training Batch Processed:  1473\n",
            "Training Batch Processed:  1474\n",
            "Training Batch Processed:  1475\n",
            "Training Batch Processed:  1476\n",
            "Training Batch Processed:  1477\n",
            "Training Batch Processed:  1478\n",
            "Training Batch Processed:  1479\n",
            "Training Batch Processed:  1480\n",
            "Training Batch Processed:  1481\n",
            "Training Batch Processed:  1482\n",
            "Training Batch Processed:  1483\n",
            "Training Batch Processed:  1484\n",
            "Training Batch Processed:  1485\n",
            "Training Batch Processed:  1486\n",
            "Training Batch Processed:  1487\n",
            "Training Batch Processed:  1488\n",
            "Training Batch Processed:  1489\n",
            "Training Batch Processed:  1490\n",
            "Training Batch Processed:  1491\n",
            "Training Batch Processed:  1492\n",
            "Training Batch Processed:  1493\n",
            "Training Batch Processed:  1494\n",
            "Training Batch Processed:  1495\n",
            "Training Batch Processed:  1496\n",
            "Training Batch Processed:  1497\n",
            "Training Batch Processed:  1498\n",
            "Training Batch Processed:  1499\n",
            "Training Batch Processed:  1500\n",
            "Average Training Accuracy: tensor(0.7964)\n",
            "Training Batch Processed:  1501\n",
            "Training Batch Processed:  1502\n",
            "Training Batch Processed:  1503\n",
            "Training Batch Processed:  1504\n",
            "Training Batch Processed:  1505\n",
            "Training Batch Processed:  1506\n",
            "Training Batch Processed:  1507\n",
            "Training Batch Processed:  1508\n",
            "Training Batch Processed:  1509\n",
            "Training Batch Processed:  1510\n",
            "Training Batch Processed:  1511\n",
            "Training Batch Processed:  1512\n",
            "Training Batch Processed:  1513\n",
            "Training Batch Processed:  1514\n",
            "Training Batch Processed:  1515\n",
            "Training Batch Processed:  1516\n",
            "Training Batch Processed:  1517\n",
            "Training Batch Processed:  1518\n",
            "Training Batch Processed:  1519\n",
            "Training Batch Processed:  1520\n",
            "Training Batch Processed:  1521\n",
            "Training Batch Processed:  1522\n",
            "Training Batch Processed:  1523\n",
            "Training Batch Processed:  1524\n",
            "Training Batch Processed:  1525\n",
            "Training Batch Processed:  1526\n",
            "Training Batch Processed:  1527\n",
            "Training Batch Processed:  1528\n",
            "Training Batch Processed:  1529\n",
            "Training Batch Processed:  1530\n",
            "Training Batch Processed:  1531\n",
            "Training Batch Processed:  1532\n",
            "Training Batch Processed:  1533\n",
            "Training Batch Processed:  1534\n",
            "Training Batch Processed:  1535\n",
            "Training Batch Processed:  1536\n",
            "Training Batch Processed:  1537\n",
            "Training Batch Processed:  1538\n",
            "Training Batch Processed:  1539\n",
            "Training Batch Processed:  1540\n",
            "Training Batch Processed:  1541\n",
            "Training Batch Processed:  1542\n",
            "Training Batch Processed:  1543\n",
            "Training Batch Processed:  1544\n",
            "Training Batch Processed:  1545\n",
            "Training Batch Processed:  1546\n",
            "Training Batch Processed:  1547\n",
            "Training Batch Processed:  1548\n",
            "Training Batch Processed:  1549\n",
            "Training Batch Processed:  1550\n",
            "Training Batch Processed:  1551\n",
            "Training Batch Processed:  1552\n",
            "Training Batch Processed:  1553\n",
            "Training Batch Processed:  1554\n",
            "Training Batch Processed:  1555\n",
            "Training Batch Processed:  1556\n",
            "Training Batch Processed:  1557\n",
            "Training Batch Processed:  1558\n",
            "Training Batch Processed:  1559\n",
            "Training Batch Processed:  1560\n",
            "Training Batch Processed:  1561\n",
            "Training Batch Processed:  1562\n",
            "Training Batch Processed:  1563\n",
            "Training Batch Processed:  1564\n",
            "Training Batch Processed:  1565\n",
            "Training Batch Processed:  1566\n",
            "Training Batch Processed:  1567\n",
            "Training Batch Processed:  1568\n",
            "Training Batch Processed:  1569\n",
            "Training Batch Processed:  1570\n",
            "Training Batch Processed:  1571\n",
            "Training Batch Processed:  1572\n",
            "Training Batch Processed:  1573\n",
            "Training Batch Processed:  1574\n",
            "Training Batch Processed:  1575\n",
            "Training Batch Processed:  1576\n",
            "Training Batch Processed:  1577\n",
            "Training Batch Processed:  1578\n",
            "Training Batch Processed:  1579\n",
            "Training Batch Processed:  1580\n",
            "Training Batch Processed:  1581\n",
            "Training Batch Processed:  1582\n",
            "Training Batch Processed:  1583\n",
            "Training Batch Processed:  1584\n",
            "Training Batch Processed:  1585\n",
            "Training Batch Processed:  1586\n",
            "Training Batch Processed:  1587\n",
            "Training Batch Processed:  1588\n",
            "Training Batch Processed:  1589\n",
            "Training Batch Processed:  1590\n",
            "Training Batch Processed:  1591\n",
            "Training Batch Processed:  1592\n",
            "Training Batch Processed:  1593\n",
            "Training Batch Processed:  1594\n",
            "Training Batch Processed:  1595\n",
            "Training Batch Processed:  1596\n",
            "Training Batch Processed:  1597\n",
            "Training Batch Processed:  1598\n",
            "Training Batch Processed:  1599\n",
            "Training Batch Processed:  1600\n",
            "Average Training Accuracy: tensor(0.7987)\n",
            "Training Batch Processed:  1601\n",
            "Training Batch Processed:  1602\n",
            "Training Batch Processed:  1603\n",
            "Training Batch Processed:  1604\n",
            "Training Batch Processed:  1605\n",
            "Training Batch Processed:  1606\n",
            "Training Batch Processed:  1607\n",
            "Training Batch Processed:  1608\n",
            "Training Batch Processed:  1609\n",
            "Training Batch Processed:  1610\n",
            "Training Batch Processed:  1611\n",
            "Training Batch Processed:  1612\n",
            "Training Batch Processed:  1613\n",
            "Training Batch Processed:  1614\n",
            "Training Batch Processed:  1615\n",
            "Training Batch Processed:  1616\n",
            "Training Batch Processed:  1617\n",
            "Training Batch Processed:  1618\n",
            "Training Batch Processed:  1619\n",
            "Training Batch Processed:  1620\n",
            "Training Batch Processed:  1621\n",
            "Training Batch Processed:  1622\n",
            "Training Batch Processed:  1623\n",
            "Training Batch Processed:  1624\n",
            "Training Batch Processed:  1625\n",
            "Training Batch Processed:  1626\n",
            "Training Batch Processed:  1627\n",
            "Training Batch Processed:  1628\n",
            "Training Batch Processed:  1629\n",
            "Training Batch Processed:  1630\n",
            "Training Batch Processed:  1631\n",
            "Training Batch Processed:  1632\n",
            "Training Batch Processed:  1633\n",
            "Training Batch Processed:  1634\n",
            "Training Batch Processed:  1635\n",
            "Training Batch Processed:  1636\n",
            "Training Batch Processed:  1637\n",
            "Training Batch Processed:  1638\n",
            "Training Batch Processed:  1639\n",
            "Training Batch Processed:  1640\n",
            "Training Batch Processed:  1641\n",
            "Training Batch Processed:  1642\n",
            "Training Batch Processed:  1643\n",
            "Training Batch Processed:  1644\n",
            "Training Batch Processed:  1645\n",
            "Training Batch Processed:  1646\n",
            "Training Batch Processed:  1647\n",
            "Training Batch Processed:  1648\n",
            "Training Batch Processed:  1649\n",
            "Training Batch Processed:  1650\n",
            "Training Batch Processed:  1651\n",
            "Training Batch Processed:  1652\n",
            "Training Batch Processed:  1653\n",
            "Training Batch Processed:  1654\n",
            "Training Batch Processed:  1655\n",
            "Training Batch Processed:  1656\n",
            "Training Batch Processed:  1657\n",
            "Training Batch Processed:  1658\n",
            "Training Batch Processed:  1659\n",
            "Training Batch Processed:  1660\n",
            "Training Batch Processed:  1661\n",
            "Training Batch Processed:  1662\n",
            "Training Batch Processed:  1663\n",
            "Training Batch Processed:  1664\n",
            "Training Batch Processed:  1665\n",
            "Training Batch Processed:  1666\n",
            "Training Batch Processed:  1667\n",
            "Training Batch Processed:  1668\n",
            "Training Batch Processed:  1669\n",
            "Training Batch Processed:  1670\n",
            "Training Batch Processed:  1671\n",
            "Training Batch Processed:  1672\n",
            "Training Batch Processed:  1673\n",
            "Training Batch Processed:  1674\n",
            "Training Batch Processed:  1675\n",
            "Training Batch Processed:  1676\n",
            "Training Batch Processed:  1677\n",
            "Training Batch Processed:  1678\n",
            "Training Batch Processed:  1679\n",
            "Training Batch Processed:  1680\n",
            "Training Batch Processed:  1681\n",
            "Training Batch Processed:  1682\n",
            "Training Batch Processed:  1683\n",
            "Training Batch Processed:  1684\n",
            "Training Batch Processed:  1685\n",
            "Training Batch Processed:  1686\n",
            "Training Batch Processed:  1687\n",
            "Training Batch Processed:  1688\n",
            "Training Batch Processed:  1689\n",
            "Training Batch Processed:  1690\n",
            "Training Batch Processed:  1691\n",
            "Training Batch Processed:  1692\n",
            "Training Batch Processed:  1693\n",
            "Training Batch Processed:  1694\n",
            "Training Batch Processed:  1695\n",
            "Training Batch Processed:  1696\n",
            "Training Batch Processed:  1697\n",
            "Training Batch Processed:  1698\n",
            "Training Batch Processed:  1699\n",
            "Training Batch Processed:  1700\n",
            "Average Training Accuracy: tensor(0.8004)\n",
            "Training Batch Processed:  1701\n",
            "Training Batch Processed:  1702\n",
            "Training Batch Processed:  1703\n",
            "Training Batch Processed:  1704\n",
            "Training Batch Processed:  1705\n",
            "Training Batch Processed:  1706\n",
            "Training Batch Processed:  1707\n",
            "Training Batch Processed:  1708\n",
            "Training Batch Processed:  1709\n",
            "Training Batch Processed:  1710\n",
            "Training Batch Processed:  1711\n",
            "Training Batch Processed:  1712\n",
            "Training Batch Processed:  1713\n",
            "Training Batch Processed:  1714\n",
            "Training Batch Processed:  1715\n",
            "Training Batch Processed:  1716\n",
            "Training Batch Processed:  1717\n",
            "Training Batch Processed:  1718\n",
            "Training Batch Processed:  1719\n",
            "Training Batch Processed:  1720\n",
            "Training Batch Processed:  1721\n",
            "Training Batch Processed:  1722\n",
            "Training Batch Processed:  1723\n",
            "Training Batch Processed:  1724\n",
            "Training Batch Processed:  1725\n",
            "Training Batch Processed:  1726\n",
            "Training Batch Processed:  1727\n",
            "Training Batch Processed:  1728\n",
            "Training Batch Processed:  1729\n",
            "Training Batch Processed:  1730\n",
            "Training Batch Processed:  1731\n",
            "Training Batch Processed:  1732\n",
            "Training Batch Processed:  1733\n",
            "Training Batch Processed:  1734\n",
            "Training Batch Processed:  1735\n",
            "Training Batch Processed:  1736\n",
            "Training Batch Processed:  1737\n",
            "Training Batch Processed:  1738\n",
            "Training Batch Processed:  1739\n",
            "Training Batch Processed:  1740\n",
            "Training Batch Processed:  1741\n",
            "Training Batch Processed:  1742\n",
            "Training Batch Processed:  1743\n",
            "Training Batch Processed:  1744\n",
            "Training Batch Processed:  1745\n",
            "Training Batch Processed:  1746\n",
            "Training Batch Processed:  1747\n",
            "Training Batch Processed:  1748\n",
            "Training Batch Processed:  1749\n",
            "Training Batch Processed:  1750\n",
            "Training Batch Processed:  1751\n",
            "Training Batch Processed:  1752\n",
            "Training Batch Processed:  1753\n",
            "Training Batch Processed:  1754\n",
            "Training Batch Processed:  1755\n",
            "Training Batch Processed:  1756\n",
            "Training Batch Processed:  1757\n",
            "Training Batch Processed:  1758\n",
            "Training Batch Processed:  1759\n",
            "Training Batch Processed:  1760\n",
            "Training Batch Processed:  1761\n",
            "Training Batch Processed:  1762\n",
            "Training Batch Processed:  1763\n",
            "Training Batch Processed:  1764\n",
            "Training Batch Processed:  1765\n",
            "Training Batch Processed:  1766\n",
            "Training Batch Processed:  1767\n",
            "Training Batch Processed:  1768\n",
            "Training Batch Processed:  1769\n",
            "Training Batch Processed:  1770\n",
            "Training Batch Processed:  1771\n",
            "Training Batch Processed:  1772\n",
            "Training Batch Processed:  1773\n",
            "Training Batch Processed:  1774\n",
            "Training Batch Processed:  1775\n",
            "Training Batch Processed:  1776\n",
            "Training Batch Processed:  1777\n",
            "Training Batch Processed:  1778\n",
            "Training Batch Processed:  1779\n",
            "Training Batch Processed:  1780\n",
            "Training Batch Processed:  1781\n",
            "Training Batch Processed:  1782\n",
            "Training Batch Processed:  1783\n",
            "Training Batch Processed:  1784\n",
            "Training Batch Processed:  1785\n",
            "Training Batch Processed:  1786\n",
            "Training Batch Processed:  1787\n",
            "Training Batch Processed:  1788\n",
            "Training Batch Processed:  1789\n",
            "Training Batch Processed:  1790\n",
            "Training Batch Processed:  1791\n",
            "Training Batch Processed:  1792\n",
            "Training Batch Processed:  1793\n",
            "Training Batch Processed:  1794\n",
            "Training Batch Processed:  1795\n",
            "Training Batch Processed:  1796\n",
            "Training Batch Processed:  1797\n",
            "Training Batch Processed:  1798\n",
            "Training Batch Processed:  1799\n",
            "Training Batch Processed:  1800\n",
            "Average Training Accuracy: tensor(0.8015)\n",
            "Training Batch Processed:  1801\n",
            "Training Batch Processed:  1802\n",
            "Training Batch Processed:  1803\n",
            "Training Batch Processed:  1804\n",
            "Training Batch Processed:  1805\n",
            "Training Batch Processed:  1806\n",
            "Training Batch Processed:  1807\n",
            "Training Batch Processed:  1808\n",
            "Training Batch Processed:  1809\n",
            "Training Batch Processed:  1810\n",
            "Training Batch Processed:  1811\n",
            "Training Batch Processed:  1812\n",
            "Training Batch Processed:  1813\n",
            "Training Batch Processed:  1814\n",
            "Training Batch Processed:  1815\n",
            "Training Batch Processed:  1816\n",
            "Training Batch Processed:  1817\n",
            "Training Batch Processed:  1818\n",
            "Training Batch Processed:  1819\n",
            "Training Batch Processed:  1820\n",
            "Training Batch Processed:  1821\n",
            "Training Batch Processed:  1822\n",
            "Training Batch Processed:  1823\n",
            "Training Batch Processed:  1824\n",
            "Training Batch Processed:  1825\n",
            "Training Batch Processed:  1826\n",
            "Training Batch Processed:  1827\n",
            "Training Batch Processed:  1828\n",
            "Training Batch Processed:  1829\n",
            "Training Batch Processed:  1830\n",
            "Training Batch Processed:  1831\n",
            "Training Batch Processed:  1832\n",
            "Training Batch Processed:  1833\n",
            "Training Batch Processed:  1834\n",
            "Training Batch Processed:  1835\n",
            "Training Batch Processed:  1836\n",
            "Training Batch Processed:  1837\n",
            "Training Batch Processed:  1838\n",
            "Training Batch Processed:  1839\n",
            "Training Batch Processed:  1840\n",
            "Training Batch Processed:  1841\n",
            "Training Batch Processed:  1842\n",
            "Training Batch Processed:  1843\n",
            "Training Batch Processed:  1844\n",
            "Training Batch Processed:  1845\n",
            "Training Batch Processed:  1846\n",
            "Training Batch Processed:  1847\n",
            "Training Batch Processed:  1848\n",
            "Training Batch Processed:  1849\n",
            "Training Batch Processed:  1850\n",
            "Training Batch Processed:  1851\n",
            "Training Batch Processed:  1852\n",
            "Training Batch Processed:  1853\n",
            "Training Batch Processed:  1854\n",
            "Training Batch Processed:  1855\n",
            "Training Batch Processed:  1856\n",
            "Training Batch Processed:  1857\n",
            "Training Batch Processed:  1858\n",
            "Training Batch Processed:  1859\n",
            "Training Batch Processed:  1860\n",
            "Training Batch Processed:  1861\n",
            "Training Batch Processed:  1862\n",
            "Training Batch Processed:  1863\n",
            "Training Batch Processed:  1864\n",
            "Training Batch Processed:  1865\n",
            "Training Batch Processed:  1866\n",
            "Training Batch Processed:  1867\n",
            "Training Batch Processed:  1868\n",
            "Training Batch Processed:  1869\n",
            "Training Batch Processed:  1870\n",
            "Training Batch Processed:  1871\n",
            "Training Batch Processed:  1872\n",
            "Training Batch Processed:  1873\n",
            "Training Batch Processed:  1874\n",
            "Training Batch Processed:  1875\n",
            "Training Batch Processed:  1876\n",
            "Training Batch Processed:  1877\n",
            "Training Batch Processed:  1878\n",
            "Training Batch Processed:  1879\n",
            "Training Batch Processed:  1880\n",
            "Training Batch Processed:  1881\n",
            "Training Batch Processed:  1882\n",
            "Training Batch Processed:  1883\n",
            "Training Batch Processed:  1884\n",
            "Training Batch Processed:  1885\n",
            "Training Batch Processed:  1886\n",
            "Training Batch Processed:  1887\n",
            "Training Batch Processed:  1888\n",
            "Training Batch Processed:  1889\n",
            "Training Batch Processed:  1890\n",
            "Training Batch Processed:  1891\n",
            "Training Batch Processed:  1892\n",
            "Training Batch Processed:  1893\n",
            "Training Batch Processed:  1894\n",
            "Training Batch Processed:  1895\n",
            "Training Batch Processed:  1896\n",
            "Training Batch Processed:  1897\n",
            "Training Batch Processed:  1898\n",
            "Training Batch Processed:  1899\n",
            "Training Batch Processed:  1900\n",
            "Average Training Accuracy: tensor(0.8033)\n",
            "Training Batch Processed:  1901\n",
            "Training Batch Processed:  1902\n",
            "Training Batch Processed:  1903\n",
            "Training Batch Processed:  1904\n",
            "Training Batch Processed:  1905\n",
            "Training Batch Processed:  1906\n",
            "Training Batch Processed:  1907\n",
            "Training Batch Processed:  1908\n",
            "Training Batch Processed:  1909\n",
            "Training Batch Processed:  1910\n",
            "Training Batch Processed:  1911\n",
            "Training Batch Processed:  1912\n",
            "Training Batch Processed:  1913\n",
            "Training Batch Processed:  1914\n",
            "Training Batch Processed:  1915\n",
            "Training Batch Processed:  1916\n",
            "Training Batch Processed:  1917\n",
            "Training Batch Processed:  1918\n",
            "Training Batch Processed:  1919\n",
            "Training Batch Processed:  1920\n",
            "Training Batch Processed:  1921\n",
            "Training Batch Processed:  1922\n",
            "Training Batch Processed:  1923\n",
            "Training Batch Processed:  1924\n",
            "Training Batch Processed:  1925\n",
            "Training Batch Processed:  1926\n",
            "Training Batch Processed:  1927\n",
            "Training Batch Processed:  1928\n",
            "Training Batch Processed:  1929\n",
            "Training Batch Processed:  1930\n",
            "Training Batch Processed:  1931\n",
            "Training Batch Processed:  1932\n",
            "Training Batch Processed:  1933\n",
            "Training Batch Processed:  1934\n",
            "Training Batch Processed:  1935\n",
            "Training Batch Processed:  1936\n",
            "Training Batch Processed:  1937\n",
            "Training Batch Processed:  1938\n",
            "Training Batch Processed:  1939\n",
            "Training Batch Processed:  1940\n",
            "Training Batch Processed:  1941\n",
            "Training Batch Processed:  1942\n",
            "Training Batch Processed:  1943\n",
            "Training Batch Processed:  1944\n",
            "Training Batch Processed:  1945\n",
            "Training Batch Processed:  1946\n",
            "Training Batch Processed:  1947\n",
            "Training Batch Processed:  1948\n",
            "Training Batch Processed:  1949\n",
            "Training Batch Processed:  1950\n",
            "Training Batch Processed:  1951\n",
            "Training Batch Processed:  1952\n",
            "Training Batch Processed:  1953\n",
            "Training Batch Processed:  1954\n",
            "Training Batch Processed:  1955\n",
            "Training Batch Processed:  1956\n",
            "Training Batch Processed:  1957\n",
            "Training Batch Processed:  1958\n",
            "Training Batch Processed:  1959\n",
            "Training Batch Processed:  1960\n",
            "Training Batch Processed:  1961\n",
            "Training Batch Processed:  1962\n",
            "Training Batch Processed:  1963\n",
            "Training Batch Processed:  1964\n",
            "Training Batch Processed:  1965\n",
            "Training Batch Processed:  1966\n",
            "Training Batch Processed:  1967\n",
            "Training Batch Processed:  1968\n",
            "Training Batch Processed:  1969\n",
            "Training Batch Processed:  1970\n",
            "Training Batch Processed:  1971\n",
            "Training Batch Processed:  1972\n",
            "Training Batch Processed:  1973\n",
            "Training Batch Processed:  1974\n",
            "Training Batch Processed:  1975\n",
            "Training Batch Processed:  1976\n",
            "Training Batch Processed:  1977\n",
            "Training Batch Processed:  1978\n",
            "Training Batch Processed:  1979\n",
            "Training Batch Processed:  1980\n",
            "Training Batch Processed:  1981\n",
            "Training Batch Processed:  1982\n",
            "Training Batch Processed:  1983\n",
            "Training Batch Processed:  1984\n",
            "Training Batch Processed:  1985\n",
            "Training Batch Processed:  1986\n",
            "Training Batch Processed:  1987\n",
            "Training Batch Processed:  1988\n",
            "Training Batch Processed:  1989\n",
            "Training Batch Processed:  1990\n",
            "Training Batch Processed:  1991\n",
            "Training Batch Processed:  1992\n",
            "Training Batch Processed:  1993\n",
            "Training Batch Processed:  1994\n",
            "Training Batch Processed:  1995\n",
            "Training Batch Processed:  1996\n",
            "Training Batch Processed:  1997\n",
            "Training Batch Processed:  1998\n",
            "Training Batch Processed:  1999\n",
            "Training Batch Processed:  2000\n",
            "Average Training Accuracy: tensor(0.8044)\n",
            "Training Batch Processed:  2001\n",
            "Training Batch Processed:  2002\n",
            "Training Batch Processed:  2003\n",
            "Training Batch Processed:  2004\n",
            "Training Batch Processed:  2005\n",
            "Training Batch Processed:  2006\n",
            "Training Batch Processed:  2007\n",
            "Training Batch Processed:  2008\n",
            "Training Batch Processed:  2009\n",
            "Training Batch Processed:  2010\n",
            "Training Batch Processed:  2011\n",
            "Training Batch Processed:  2012\n",
            "Training Batch Processed:  2013\n",
            "Training Batch Processed:  2014\n",
            "Training Batch Processed:  2015\n",
            "Training Batch Processed:  2016\n",
            "Training Batch Processed:  2017\n",
            "Training Batch Processed:  2018\n",
            "Training Batch Processed:  2019\n",
            "Training Batch Processed:  2020\n",
            "Training Batch Processed:  2021\n",
            "Training Batch Processed:  2022\n",
            "Training Batch Processed:  2023\n",
            "Training Batch Processed:  2024\n",
            "Training Batch Processed:  2025\n",
            "Training Batch Processed:  2026\n",
            "Training Batch Processed:  2027\n",
            "Training Batch Processed:  2028\n",
            "Training Batch Processed:  2029\n",
            "Training Batch Processed:  2030\n",
            "Training Batch Processed:  2031\n",
            "Training Batch Processed:  2032\n",
            "Training Batch Processed:  2033\n",
            "Training Batch Processed:  2034\n",
            "Training Batch Processed:  2035\n",
            "Training Batch Processed:  2036\n",
            "Training Batch Processed:  2037\n",
            "Training Batch Processed:  2038\n",
            "Training Batch Processed:  2039\n",
            "Training Batch Processed:  2040\n",
            "Training Batch Processed:  2041\n",
            "Training Batch Processed:  2042\n",
            "Training Batch Processed:  2043\n",
            "Training Batch Processed:  2044\n",
            "Training Batch Processed:  2045\n",
            "Training Batch Processed:  2046\n",
            "Training Batch Processed:  2047\n",
            "Training Batch Processed:  2048\n",
            "Training Batch Processed:  2049\n",
            "Training Batch Processed:  2050\n",
            "Training Batch Processed:  2051\n",
            "Training Batch Processed:  2052\n",
            "Training Batch Processed:  2053\n",
            "Training Batch Processed:  2054\n",
            "Training Batch Processed:  2055\n",
            "Training Batch Processed:  2056\n",
            "Training Batch Processed:  2057\n",
            "Training Batch Processed:  2058\n",
            "Training Batch Processed:  2059\n",
            "Training Batch Processed:  2060\n",
            "Training Batch Processed:  2061\n",
            "Training Batch Processed:  2062\n",
            "Training Batch Processed:  2063\n",
            "Training Batch Processed:  2064\n",
            "Training Batch Processed:  2065\n",
            "Training Batch Processed:  2066\n",
            "Training Batch Processed:  2067\n",
            "Training Batch Processed:  2068\n",
            "Training Batch Processed:  2069\n",
            "Training Batch Processed:  2070\n",
            "Training Batch Processed:  2071\n",
            "Training Batch Processed:  2072\n",
            "Training Batch Processed:  2073\n",
            "Training Batch Processed:  2074\n",
            "Training Batch Processed:  2075\n",
            "Training Batch Processed:  2076\n",
            "Training Batch Processed:  2077\n",
            "Training Batch Processed:  2078\n",
            "Training Batch Processed:  2079\n",
            "Training Batch Processed:  2080\n",
            "Training Batch Processed:  2081\n",
            "Training Batch Processed:  2082\n",
            "Training Batch Processed:  2083\n",
            "Training Batch Processed:  2084\n",
            "Training Batch Processed:  2085\n",
            "Training Batch Processed:  2086\n",
            "Training Batch Processed:  2087\n",
            "Training Batch Processed:  2088\n",
            "Training Batch Processed:  2089\n",
            "Training Batch Processed:  2090\n",
            "Training Batch Processed:  2091\n",
            "Training Batch Processed:  2092\n",
            "Training Batch Processed:  2093\n",
            "Training Batch Processed:  2094\n",
            "Training Batch Processed:  2095\n",
            "Training Batch Processed:  2096\n",
            "Training Batch Processed:  2097\n",
            "Training Batch Processed:  2098\n",
            "Training Batch Processed:  2099\n",
            "Training Batch Processed:  2100\n",
            "Average Training Accuracy: tensor(0.8058)\n",
            "Training Batch Processed:  2101\n",
            "Training Batch Processed:  2102\n",
            "Training Batch Processed:  2103\n",
            "Training Batch Processed:  2104\n",
            "Training Batch Processed:  2105\n",
            "Training Batch Processed:  2106\n",
            "Training Batch Processed:  2107\n",
            "Training Batch Processed:  2108\n",
            "Training Batch Processed:  2109\n",
            "Training Batch Processed:  2110\n",
            "Training Batch Processed:  2111\n",
            "Training Batch Processed:  2112\n",
            "Training Batch Processed:  2113\n",
            "Training Batch Processed:  2114\n",
            "Training Batch Processed:  2115\n",
            "Training Batch Processed:  2116\n",
            "Training Batch Processed:  2117\n",
            "Training Batch Processed:  2118\n",
            "Training Batch Processed:  2119\n",
            "Training Batch Processed:  2120\n",
            "Training Batch Processed:  2121\n",
            "Training Batch Processed:  2122\n",
            "Training Batch Processed:  2123\n",
            "Training Batch Processed:  2124\n",
            "Training Batch Processed:  2125\n",
            "Training Batch Processed:  2126\n",
            "Training Batch Processed:  2127\n",
            "Training Batch Processed:  2128\n",
            "Training Batch Processed:  2129\n",
            "Training Batch Processed:  2130\n",
            "Training Batch Processed:  2131\n",
            "Training Batch Processed:  2132\n",
            "Training Batch Processed:  2133\n",
            "Training Batch Processed:  2134\n",
            "Training Batch Processed:  2135\n",
            "Training Batch Processed:  2136\n",
            "Training Batch Processed:  2137\n",
            "Training Batch Processed:  2138\n",
            "Training Batch Processed:  2139\n",
            "Training Batch Processed:  2140\n",
            "Training Batch Processed:  2141\n",
            "Training Batch Processed:  2142\n",
            "Training Batch Processed:  2143\n",
            "Training Batch Processed:  2144\n",
            "Training Batch Processed:  2145\n",
            "Training Batch Processed:  2146\n",
            "Training Batch Processed:  2147\n",
            "Training Batch Processed:  2148\n",
            "Training Batch Processed:  2149\n",
            "Training Batch Processed:  2150\n",
            "Training Batch Processed:  2151\n",
            "Training Batch Processed:  2152\n",
            "Training Batch Processed:  2153\n",
            "Training Batch Processed:  2154\n",
            "Training Batch Processed:  2155\n",
            "Training Batch Processed:  2156\n",
            "Training Batch Processed:  2157\n",
            "Training Batch Processed:  2158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxCX77yphDLA"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "torch.save(model_CNN_image_text.state_dict(), 'model_with_images_test.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing a validation pass on a model that combines image and text information to make predictions."
      ],
      "metadata": {
        "id": "4nTZ7HowZW8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X30CUko7hDN3"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "counter = 0\n",
        "batch_size = 60\n",
        "images_tensor = torch.zeros(batch_size, 3, 560, 560)\n",
        "titles_tensor = torch.zeros(batch_size, 15).int()\n",
        "labels_tensor = torch.zeros(batch_size).int()\n",
        "\n",
        "predictions = []\n",
        "labels_test = []\n",
        "\n",
        "# Validation pass\n",
        "with torch.no_grad():\n",
        "    for i in range(len(test_images_final)):\n",
        "        # First check if image is available\n",
        "        img = cv2.imread(path + test_images_final[i])\n",
        "        if type(img) is not type(None):\n",
        "            # Add 1 to counter\n",
        "            counter += 1\n",
        "            # Pad it with zeros to obtain 560 x 560 shape\n",
        "            img_padded = pad_images(img)\n",
        "            # Store image and corresponding title and label \n",
        "            images_tensor[counter - 1, :, :, :] = torch.from_numpy(img_padded)\n",
        "            titles_tensor[counter - 1, :] = torch.from_numpy(test_tokenized_padding[i])\n",
        "            labels_tensor[counter - 1] = test_labels[i] \n",
        "            if counter % batch_size == 0:\n",
        "                # Pass image and text through the different layers\n",
        "                out = model_CNN_image_text(images_tensor, titles_tensor)\n",
        "                # Obtain predictions\n",
        "                top_p, top_class = out.topk(1, dim=1)\n",
        "                predictions.extend(top_class.numpy().flatten().tolist())\n",
        "                labels_test.extend(labels_tensor.numpy().tolist())\n",
        "                # Reset tensors\n",
        "                images_tensor = torch.zeros(batch_size, 3, 560, 560)\n",
        "                titles_tensor = torch.zeros(batch_size, 15).int()\n",
        "                labels_tensor = torch.zeros(batch_size).int()\n",
        "                counter = 0\n",
        "    # Process the remaining data\n",
        "    if counter > 0:\n",
        "        out = model_CNN_image_text(images_tensor[:counter, ...], titles_tensor[:counter, ...])\n",
        "        top_p, top_class = out.topk(1, dim=1)\n",
        "        predictions.extend(top_class.numpy().flatten().tolist())\n",
        "        labels_test.extend(labels_tensor[:counter].numpy().tolist())\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "labels_test = np.array(labels_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(labels_test, predictions, labels=[0, 1, 2, 3, 4, 5]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os__XrpZyz8w",
        "outputId": "79193105-6d8d-48b6-cbf8-0a8f7428b13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.93      0.83      5448\n",
            "           1       0.70      0.75      0.72       823\n",
            "           2       0.80      0.53      0.64      2610\n",
            "           3       0.51      0.10      0.16       267\n",
            "           4       1.00      0.99      1.00      4049\n",
            "           5       0.87      0.60      0.71       549\n",
            "\n",
            "    accuracy                           0.83     13746\n",
            "   macro avg       0.77      0.65      0.68     13746\n",
            "weighted avg       0.83      0.83      0.82     13746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(labels_test).reshape(len(labels_test),1),predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCSXGQ5r-d-H",
        "outputId": "fdd76b6a-83b6-4ddf-973f-22fb6e461a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5052  119  255    7    1   14]\n",
            " [ 171  618   22    6    0    6]\n",
            " [1093  112 1379    4    2   20]\n",
            " [ 194   19   20   26    1    7]\n",
            " [   8    4    9    1 4027    0]\n",
            " [ 153   17   44    7    0  328]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(np.array(labels_test).reshape(len(labels_test),1),predictions)\n",
        "\n",
        "# Normalize the confusion matrix\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yK9hZG6i-dMI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "acf44a87-20a4-4bb0-d905-bf6f9301375a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate accuracy\n",
        "acc = accuracy_score(np.array(labels_test).reshape(len(labels_test),1),predictions)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(np.array(labels_test).reshape(len(labels_test),1),predictions, average='macro')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(np.array(labels_test).reshape(len(labels_test),1),predictions, average='macro')\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(np.array(labels_test).reshape(len(labels_test),1),predictions, average='macro')\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(acc * 100))\n",
        "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "print(\"F1-score: {:.2f}%\".format(f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRPGXWfrdL2Q",
        "outputId": "0af08e39-1273-43f2-8913-115c4100675d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.15%\n",
            "Precision: 77.23%\n",
            "Recall: 64.93%\n",
            "F1-score: 67.69%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}