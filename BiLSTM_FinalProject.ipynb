{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXHKc15JQLCJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF3QHFZKagay"
      },
      "source": [
        "**BiLSTM**\n",
        "\n",
        "Import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtYqlwwTag2o",
        "outputId": "e8666f0f-c6ab-4f68-9b08-3d7c18f13aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow \n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import spacy\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, SpatialDropout1D, Conv1D, MaxPooling1D, GRU, BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Bidirectional, GlobalAveragePooling1D, concatenate, LeakyReLU, GlobalMaxPooling1D, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WfZEZ8Ia20X"
      },
      "source": [
        "Mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhtOkBxuahWq",
        "outputId": "55486db6-8463-4590-914d-69f6dc692bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beUf5oFRgfbN"
      },
      "source": [
        "import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VCsK9kkfx0N"
      },
      "outputs": [],
      "source": [
        "# Train data \n",
        "multimodal_traindata = pd.read_csv('/content/drive/MyDrive/multimodal_train.tsv',sep='\\t')\n",
        "# Validation data \n",
        "multimodal_validata = pd.read_csv('/content/drive/MyDrive/multimodal_validate.tsv',sep='\\t')\n",
        "# Test data \n",
        "multimodal_test_publicdata = pd.read_csv('/content/drive/MyDrive/multimodal_test_public.tsv',sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZxbISEVCU2F"
      },
      "source": [
        "Select a subset of the dataframe with no missing values in the 'clean_title' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7DQVeEokvP0"
      },
      "outputs": [],
      "source": [
        "train_data = multimodal_traindata[multimodal_traindata['clean_title'].notna()]\n",
        "validation_data = multimodal_validata[multimodal_validata['clean_title'].notna()]\n",
        "test_data = multimodal_test_publicdata[multimodal_test_publicdata['clean_title'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KopmjDALDh9a"
      },
      "source": [
        "This code separates the datasets into the text and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP2eH7jqkvTI",
        "outputId": "db77dc7f-bd0d-4eb9-fa2e-2b7dc4792e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59319,)\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_news, train_labels = train_data['clean_title'], train_data['6_way_label']\n",
        "\n",
        "# Validation data\n",
        "validation_news, validation_labels = validation_data['clean_title'], validation_data['6_way_label']\n",
        "\n",
        "# Test data\n",
        "test_news, test_labels = test_data['clean_title'], test_data['6_way_label']\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n48YXfL1EuI9"
      },
      "source": [
        "**Preprocessing**\n",
        "\n",
        "Define a function to preprocess the data. Removing punctuations and numbers and also multiple spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utvqzSZyCfws"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = \"\".join(c for c in sen if c not in string.punctuation)\n",
        "    # Removing multiple spaces\n",
        "    sentence = \" \".join(sentence.split())\n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw0y5xQJCfzx"
      },
      "outputs": [],
      "source": [
        "# Remove puntuations and numbers and multiple spaces\n",
        "train_news_clean = list(map(preprocess_text, train_news))\n",
        "validation_news_clean = list(map(preprocess_text, validation_news))\n",
        "test_news_clean = list(map(preprocess_text, test_news))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS2giH47Hdkj"
      },
      "source": [
        "Using nltk's pos_tag() method to get the POS tag of each word and then passing that tag as an argument to the lemmatizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZkLcAfJCf9M"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def remove_stopwords_lem(text):\n",
        "    # Tokenize text\n",
        "    text = word_tokenize(text)\n",
        "    # POS tagging\n",
        "    tagged_text = pos_tag(text)\n",
        "    # Remove stopwords and perform lemmatization\n",
        "    lemmatized_text = [lemmatizer.lemmatize(word, tag[0].lower()) if tag[0].lower() in ['a','n','v'] else word for word, tag in tagged_text if word.lower() not in stop_words]\n",
        "    return ' '.join(lemmatized_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kUeiNfXCgAj",
        "outputId": "e2652c55-a92a-492a-d242-6c5f9ca65ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Stop-words removal and lemmatization\n",
        "train_stopword_lemma = list(map(remove_stopwords_lem, train_news_clean))\n",
        "validation_stopword_lemma = list(map(remove_stopwords_lem, validation_news_clean))\n",
        "test_stopword_lemma = list(map(remove_stopwords_lem, test_news_clean))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqKKMMUtUsnx"
      },
      "source": [
        "Using the fit_on_texts() method only on the training set and then use texts_to_sequences() for both validation and test sets as well. Also, it is not necessary to set the num_words parameter to a fixed value, I can use the num_words parameter to set the maximum number of words to keep, based on word frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6RrQub3HiaI"
      },
      "outputs": [],
      "source": [
        "# Tokenize news\n",
        "tokenizer = Tokenizer(num_words=None)\n",
        "# Fit the tokenizer on the train set\n",
        "tokenizer.fit_on_texts(train_stopword_lemma)\n",
        "\n",
        "# Tokenize the train, validation and test set\n",
        "train_tokenized = tokenizer.texts_to_sequences(train_stopword_lemma)\n",
        "validation_tokenized = tokenizer.texts_to_sequences(validation_stopword_lemma)\n",
        "test_tokenized = tokenizer.texts_to_sequences(test_stopword_lemma)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpTRiXSDXQt3"
      },
      "source": [
        "Obtain the vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWOTEUS8Hif1",
        "outputId": "1db24f8c-dec7-4547-945d-54fe7b4d8210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length:  111282\n"
          ]
        }
      ],
      "source": [
        "# Obtain the vocabulary length\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "print(\"Vocabulary length: \", vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1lrwVbSX-zT"
      },
      "source": [
        "It uses a list comprehension to iterate over the input data and returns a list of the length of each sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpjcM31yYRgK"
      },
      "source": [
        "Padding the sequences of numbers generated by the tokenizer. But first check how many sequences are shorter than a given length. By defining a function that counts the length of each sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC--a80QHiic"
      },
      "outputs": [],
      "source": [
        "# Function to count the lenght of each sequence\n",
        "def length_squences(data):\n",
        "    return [len(sequence) for sequence in data]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxPIjz5ZZX8w"
      },
      "source": [
        "It uses a list comprehension to iterate over the length list and calculate the percentage of sequences shorter than each length. This way the code is more efficient and concise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIqqlbXQkvV_",
        "outputId": "5d9fde02-0ddc-4210-e0a7-1f6eea7cf0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pertentages (train): [91.42251773049645, 98.45230496453901, 99.49361702127659, 99.81382978723404]\n",
            "Pertentages (validation): [91.98881062316741, 98.54908833541168, 99.53658454383067, 99.82980014155235]\n",
            "Pertentages (test): [91.81543856100069, 98.55189736846542, 99.55326286687234, 99.85839275780104]\n"
          ]
        }
      ],
      "source": [
        "length = [10, 15, 20, 25]\n",
        "\n",
        "# Train set\n",
        "lengths_train = np.array(length_squences(train_tokenized))\n",
        "pertentage_length_train = [np.sum(lengths_train < lgth)/len(lengths_train)*100 for lgth in length]\n",
        "print(\"Pertentages (train):\", pertentage_length_train)\n",
        "\n",
        "# Validation set \n",
        "lengths_validation = np.array(length_squences(validation_tokenized))\n",
        "pertentage_length_validation = [np.sum(lengths_validation < lgth)/len(lengths_validation)*100 for lgth in length]\n",
        "print(\"Pertentages (validation):\", pertentage_length_validation)\n",
        "\n",
        "# Test set\n",
        "lengths_test = np.array(length_squences(test_tokenized))\n",
        "pertentage_length_test = [np.sum(lengths_test < lgth)/len(lengths_test)*100 for lgth in length]\n",
        "print(\"Pertentages (test):\", pertentage_length_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1EoCcQRfK8O"
      },
      "source": [
        "Create a line plot to visualize the percentage of texts smaller than a given length for the train, validation, and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4hdgidM0aFiJ",
        "outputId": "49ecfd42-4aa7-4b5d-ead0-eb569931c407"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "train = [91.42, 91.55, 91.32, 98.45]\n",
        "valid = [98.43, 98.44, 99.49, 99.50]\n",
        "test = [99.50, 99.81, 99.81, 99.82]\n",
        "labels = ['< 10', '< 15', '< 20', '< 25']\n",
        "\n",
        "# Create the bar chart\n",
        "fig, ax = plt.subplots()\n",
        "bar_width = 0.25\n",
        "bar_train = ax.bar(np.arange(len(train)) - bar_width, train, bar_width, label='Train')\n",
        "bar_valid = ax.bar(np.arange(len(valid)), valid, bar_width, label='Validation')\n",
        "bar_test = ax.bar(np.arange(len(test)) + bar_width, test, bar_width, label='Test')\n",
        "\n",
        "# Add labels and titles\n",
        "ax.set_ylabel('Percentage (%)')\n",
        "ax.set_title('% of texts smaller than a given length')\n",
        "ax.set_xticks(np.arange(len(train)))\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPnPXyPCgJAp"
      },
      "source": [
        "Almost all news are smaller than 15 in length when tokenized so choosing this lenght to truncate the tokenized news will not eliminate any information from the news in almost any case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul85M7yefOE9"
      },
      "outputs": [],
      "source": [
        "# Pad the tokenized news\n",
        "\n",
        "news_tokenized = [train_tokenized, validation_tokenized, test_tokenized]\n",
        "news_tokenized_padding = [pad_sequences(news, maxlen = 15, truncating = 'post', padding = 'post') for news in news_tokenized]\n",
        "train_tokenized_padding, validation_tokenized_padding, test_tokenized_padding = news_tokenized_padding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvHy-ccr6FR"
      },
      "source": [
        "Convert the tokenized data into tensors, then create dataloaders using these tensors in one step, rather than creating separate lists for train, validation and test data and then converting them into tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guz0HRsffOHi"
      },
      "outputs": [],
      "source": [
        "# Transform data arrays into tensors\n",
        "train_tensor = torch.Tensor(train_tokenized_padding).int()\n",
        "validation_tensor = torch.Tensor(validation_tokenized_padding).int()\n",
        "test_tensor =  torch.Tensor(test_tokenized_padding).int()\n",
        "\n",
        "# Create dataloaders\n",
        "train_set = TensorDataset(train_tensor, torch.Tensor(np.array(train_labels)))\n",
        "train_dataloader = DataLoader(train_set, batch_size=60)\n",
        "\n",
        "validation_set = TensorDataset(validation_tensor, torch.Tensor(np.array(validation_labels)))\n",
        "valid_dataloader = DataLoader(validation_set, batch_size=60)\n",
        "\n",
        "test_set = TensorDataset(test_tensor, torch.Tensor(np.array(test_labels)))\n",
        "test_dataloader =  DataLoader(test_set, batch_size=60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz0DduXA08Mr"
      },
      "source": [
        "**Word embeddings**\n",
        "\n",
        "Trying different word embeddings an select the one which performs better. Create two functions: one which will be used to load the word embeddings and the other which will create the embedding matrix that will feed to the embedding layer of the models.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzI-tnDDfOK7"
      },
      "outputs": [],
      "source": [
        "# Function to load the word embeddings\n",
        "def load_embedd(filename):\n",
        "    with open(filename,'r', encoding=\"utf8\") as file:\n",
        "        lines = file.readlines()\n",
        "    words, vectors = zip(*[(line.split(\" \")[0], list(map(float, line.strip().split(\" \")[1:]))) for line in lines])\n",
        "    return words, vectors\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrI0-0hm1MXk"
      },
      "source": [
        "This version is optimized by replacing the list vocab with a set vocab_set for faster lookups during the iteration over the word_index. This way we can eliminate the need for a for loop and the lookup time will be reduced to O(1) from O(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfYHuSwnaFoJ"
      },
      "outputs": [],
      "source": [
        "# Function to create the embedding matrix\n",
        "def embed_matx(word_index, vocab, embeddings, length_vocab, length_embedding):\n",
        "    embedding_matrix = np.zeros((length_vocab +1, length_embedding))\n",
        "    for word, i in word_index.items():\n",
        "        if word in vocab:\n",
        "            idx = vocab.index(word)\n",
        "            vector =  embeddings[idx]\n",
        "            embedding_matrix[i] = vector\n",
        "    return embedding_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2aCZOc9KzLv"
      },
      "source": [
        "Use GloVe embeddings of dimension 300."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA7nQ4KF0wum"
      },
      "outputs": [],
      "source": [
        "# Use GloVe embeddings of dimension 300\n",
        "vocab_gv_300, vectors_gv_300 = load_embedd(filename = \"/content/drive/MyDrive/SaveModels/glove.6B.300d.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSM90dg_v46H",
        "outputId": "25900481-3d1f-4d5c-ca3c-25e94cc3966f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111282\n"
          ]
        }
      ],
      "source": [
        "# Create the embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))\n",
        "# Embedding matrix\n",
        "embedding_matrix_gv_300 = embed_matx(word_index = word_index, vocab = vocab_gv_300, embeddings = vectors_gv_300, \n",
        "                             length_vocab = len(word_index), length_embedding = 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxB2PDb1USu8"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, nlabels, train_parameters = True, random_embeddings = True): \n",
        "        super().__init__()\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix_gv_300))\n",
        "        self.embedding.weight.requiresGrad = train_parameters\n",
        "        \n",
        "        # BiLSTM layer \n",
        "        self.lstm1 = nn.LSTM(input_size = 300, hidden_size = 100,num_layers = 2, batch_first = True,  bidirectional = True)\n",
        "   \n",
        "        # Linear layers\n",
        "        self.linear1 = nn.Linear(15,64)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.linear2 = nn.Linear(64,nlabels)\n",
        "    \n",
        "        self.elu = nn.ELU()\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding\n",
        "        x = self.embedding(x)\n",
        "        # BiLSTM layer\n",
        "        x_1, _ = self.lstm1(x.float())\n",
        "        # Max pool\n",
        "        x_1 = F.max_pool1d(x_1, x_1.size(2)).squeeze(2)\n",
        "        # Linear layers\n",
        "        x = self.dropout(x_1)\n",
        "        # x = x.reshape(x.shape[0], -1)\n",
        "        x = self.linear1(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.logsoftmax(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEm-iTaf2fB3"
      },
      "source": [
        "It is also worth noting that you are using the ReduceLROnPlateau scheduler, which reduces the learning rate when the validation loss plateaus, rather than decreasing it linearly over time. which will reduce the learning rate over time, this helps the model converge faster and with a better accuracy.\n",
        "\n",
        "\n",
        "\n",
        "Also, added a method for early stopping, which will stop the training process if the validation loss does not improve for a certain number of consecutive epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFyUvVxwkvaM"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_extended(BiLSTM):\n",
        "    \n",
        "    def __init__(self,nlabels, train_parameters, random_embeddings, epochs=100, lr=0.001):\n",
        "        \n",
        "        super().__init__(nlabels, train_parameters, random_embeddings)  \n",
        "        \n",
        "        self.lr = lr #Learning Rate\n",
        "        \n",
        "        self.optim = optim.AdamW(self.parameters(), lr=self.lr, weight_decay=0.01)\n",
        "        \n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.criterion = nn.CrossEntropyLoss()               \n",
        "        \n",
        "        # A list to store the loss evolution along training\n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "\n",
        "        self.valid_loss_during_training = []\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.to(self.device)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optim, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "    \n",
        "    def trainloop(self,train_dataloader, valid_dataloader):\n",
        "      # Initialize early stopping\n",
        "      early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "\n",
        "      for e in range(int(self.epochs)):\n",
        "\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Random data permutation at each epoch\n",
        "        \n",
        "        running_loss = 0.\n",
        "        \n",
        "        i = 0\n",
        "        \n",
        "        length = 0\n",
        "        \n",
        "        accuracies = []\n",
        "        \n",
        "        for news, labels in train_dataloader:  \n",
        "\n",
        "             # Move input and label tensors to the default device\n",
        "            news, labels = news.to(self.device), labels.to(self.device)           \n",
        "    \n",
        "            self.optim.zero_grad()  # Reset gradients\n",
        "        \n",
        "            out = self.forward(news.int())\n",
        "\n",
        "            loss = self.criterion(out,labels.long())\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            self.optim.step()\n",
        "            \n",
        "            top_p, top_class = out.topk(1, dim=1)\n",
        "            \n",
        "            equals = (top_class == labels.view(news.shape[0], 1))\n",
        "            \n",
        "            length += news.shape[0]\n",
        "            \n",
        "            accuracies.append(sum(equals)) \n",
        "            \n",
        "            accuracy = sum(accuracies)/length\n",
        "            \n",
        "            i += 1\n",
        "            \n",
        "            if i%1000 == 0:\n",
        "                print(\" Train accuracy: \", accuracy)\n",
        "   \n",
        "            \n",
        "        self.loss_during_training.append(running_loss/len(train_dataloader))\n",
        "        \n",
        "        self.scheduler.step(accuracy)\n",
        "\n",
        "        # Validation Loss\n",
        "        \n",
        "        with torch.no_grad():            \n",
        "            \n",
        "            running_loss = 0.\n",
        "            \n",
        "            i = 0\n",
        "            \n",
        "            length = 0\n",
        "            \n",
        "            accuracies = []\n",
        "            \n",
        "            for news,labels in valid_dataloader:\n",
        "\n",
        "                # Move input and label tensors to the default device\n",
        "                news, labels = news.to(self.device), labels.to(self.device)\n",
        "                \n",
        "                out = self.forward(news.int())\n",
        "\n",
        "                loss = self.criterion(out,labels.long())\n",
        "\n",
        "                running_loss += loss.item()   \n",
        "                \n",
        "                top_p, top_class = out.topk(1, dim=1)\n",
        "            \n",
        "                equals = (top_class == labels.view(news.shape[0], 1))\n",
        "            \n",
        "                length += news.shape[0]\n",
        "            \n",
        "                accuracies.append(sum(equals)) \n",
        "            \n",
        "                accuracy = sum(accuracies)/length\n",
        "                \n",
        "\n",
        "            print(\" Validation accuracy: \", accuracy)                    \n",
        "\n",
        "            val_acc = running_loss/len(valid_dataloader)\n",
        "            self.valid_loss_during_training.append(val_acc)\n",
        "            early_stopping(val_acc, self)\n",
        "            if early_stopping.early_stop:\n",
        "                break   \n",
        "\n",
        "        if(e % 1 == 0): # Every 10 epochs\n",
        "\n",
        "            print(\"Training loss after %d epochs: %f\" \n",
        "                  %(e,self.loss_during_training[-1]), \"Validation loss after %d epochs: %f\" %(e,self.valid_loss_during_training[-1]),\n",
        "                  \"Time per epoch: %f seconds\"%(time.time() - start_time))\n",
        "            \n",
        "\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eidrS1pE4SfL"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_acc, model):\n",
        "\n",
        "        score = val_acc\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_acc, model)\n",
        "        elif score < self.best_score - self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_acc, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_acc, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOovq0T8TUt9"
      },
      "source": [
        "Train the CNN model in four different experments:\n",
        "\n",
        "1- Random embeddings + Training embeddings\n",
        "\n",
        "2- GloVe embeddings + Training embeddings\n",
        "\n",
        "3- Random embeddings + Not training embeddings\n",
        "\n",
        "4- GloVe embeddings + Not training embeddings\n",
        "\n",
        "Train the model for several epochs. This is completed in order to select the optimal number of epochs, which occurs once the validation loss stops decreasing and starts increasing (Early Stopping)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAYJr8tHL_bC",
        "outputId": "4de80b2f-567f-4ef6-fc2b-df7208421224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Train accuracy:  tensor([0.5702], device='cuda:0')\n",
            " Train accuracy:  tensor([0.5991], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6167], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6288], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6379], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6450], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6506], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6555], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6596], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.6940], device='cuda:0')\n",
            "Validation loss decreased (inf --> 0.895123).  Saving model ...\n",
            "Training loss after 0 epochs: 0.971502 Validation loss after 0 epochs: 0.895123 Time per epoch: 423.227950 seconds\n",
            " Train accuracy:  tensor([0.6952], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6975], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6997], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7010], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7029], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7046], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7059], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7071], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7085], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7075], device='cuda:0')\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Training loss after 1 epochs: 0.841609 Validation loss after 1 epochs: 0.851580 Time per epoch: 424.132737 seconds\n",
            " Train accuracy:  tensor([0.7178], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7189], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7194], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7200], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7214], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7221], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7228], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7236], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7246], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7125], device='cuda:0')\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Training loss after 2 epochs: 0.794363 Validation loss after 2 epochs: 0.839710 Time per epoch: 423.618641 seconds\n",
            " Train accuracy:  tensor([0.7324], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7333], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7335], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7334], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7344], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7349], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7352], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7357], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7364], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7155], device='cuda:0')\n",
            "EarlyStopping counter: 3 out of 10\n",
            "Training loss after 3 epochs: 0.760424 Validation loss after 3 epochs: 0.839266 Time per epoch: 423.753772 seconds\n",
            " Train accuracy:  tensor([0.7394], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7415], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7422], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7428], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7438], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7446], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7449], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7452], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7459], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7138], device='cuda:0')\n",
            "EarlyStopping counter: 4 out of 10\n",
            "Training loss after 4 epochs: 0.734324 Validation loss after 4 epochs: 0.862959 Time per epoch: 423.456473 seconds\n",
            " Train accuracy:  tensor([0.7488], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7509], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7517], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7517], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7522], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7526], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7527], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7529], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7534], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7173], device='cuda:0')\n",
            "EarlyStopping counter: 5 out of 10\n",
            "Training loss after 5 epochs: 0.712266 Validation loss after 5 epochs: 0.855218 Time per epoch: 424.268908 seconds\n",
            " Train accuracy:  tensor([0.7537], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7566], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7577], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7581], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7586], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7590], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7591], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7592], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7596], device='cuda:0')\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            " Validation accuracy:  tensor([0.7177], device='cuda:0')\n",
            "EarlyStopping counter: 6 out of 10\n",
            "Training loss after 6 epochs: 0.695553 Validation loss after 6 epochs: 0.862686 Time per epoch: 423.313430 seconds\n",
            " Train accuracy:  tensor([0.7661], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7691], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7695], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7710], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7727], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7748], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7769], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7793], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7822], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7217], device='cuda:0')\n",
            "EarlyStopping counter: 7 out of 10\n",
            "Training loss after 7 epochs: 0.630832 Validation loss after 7 epochs: 0.886429 Time per epoch: 424.175877 seconds\n",
            " Train accuracy:  tensor([0.7765], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7793], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7807], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7818], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7834], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7851], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7867], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7886], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7908], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7213], device='cuda:0')\n",
            "EarlyStopping counter: 8 out of 10\n",
            "Training loss after 8 epochs: 0.609408 Validation loss after 8 epochs: 0.886965 Time per epoch: 423.461862 seconds\n",
            " Train accuracy:  tensor([0.7825], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7851], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7864], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7874], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7888], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7903], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7914], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7931], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7951], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7220], device='cuda:0')\n",
            "Validation loss decreased (0.895123 --> 0.895347).  Saving model ...\n",
            "Training loss after 9 epochs: 0.597101 Validation loss after 9 epochs: 0.895347 Time per epoch: 425.252857 seconds\n",
            " Train accuracy:  tensor([0.7869], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7889], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7902], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7911], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7926], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7938], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7953], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7968], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7986], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7207], device='cuda:0')\n",
            "Validation loss decreased (0.895347 --> 0.909098).  Saving model ...\n",
            "Training loss after 10 epochs: 0.586893 Validation loss after 10 epochs: 0.909098 Time per epoch: 424.676856 seconds\n",
            " Train accuracy:  tensor([0.7893], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7921], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7938], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7948], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7962], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7974], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7987], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8000], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8016], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7208], device='cuda:0')\n",
            "Validation loss decreased (0.909098 --> 0.919505).  Saving model ...\n",
            "Training loss after 11 epochs: 0.578655 Validation loss after 11 epochs: 0.919505 Time per epoch: 426.053489 seconds\n",
            " Train accuracy:  tensor([0.7950], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7965], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7978], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7984], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7995], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8008], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8018], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8031], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8046], device='cuda:0')\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-05.\n",
            " Validation accuracy:  tensor([0.7214], device='cuda:0')\n",
            "Validation loss decreased (0.919505 --> 0.923590).  Saving model ...\n",
            "Training loss after 12 epochs: 0.571099 Validation loss after 12 epochs: 0.923590 Time per epoch: 425.628408 seconds\n",
            " Train accuracy:  tensor([0.7972], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7992], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7999], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8010], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8022], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8038], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8054], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8072], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8091], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7210], device='cuda:0')\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Training loss after 13 epochs: 0.557645 Validation loss after 13 epochs: 0.920647 Time per epoch: 424.999824 seconds\n",
            " Train accuracy:  tensor([0.7995], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8012], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8026], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8036], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8044], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8061], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8072], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8087], device='cuda:0')\n",
            " Train accuracy:  tensor([0.8106], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7212], device='cuda:0')\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Training loss after 14 epochs: 0.555249 Validation loss after 14 epochs: 0.920925 Time per epoch: 425.368376 seconds\n"
          ]
        }
      ],
      "source": [
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       # Initialize model\n",
        "model_random_train = BiLSTM_extended(nlabels = 6, epochs=15, train_parameters = True, random_embeddings = True)\n",
        "\n",
        "# Train model\n",
        "model_random_train.trainloop(train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKmHmjuES1u-"
      },
      "source": [
        "**GloVe embeddings + Training embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVH-mmU0Svoo",
        "outputId": "c51c3380-d1c4-4a71-dae8-4e3b93c310f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Train accuracy:  tensor([0.5755], device='cuda:0')\n",
            " Train accuracy:  tensor([0.5987], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6143], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6261], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6353], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6423], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6484], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6532], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6574], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.6929], device='cuda:0')\n",
            "Validation loss decreased (inf --> 0.889944).  Saving model ...\n",
            "Training loss after 0 epochs: 0.973658 Validation loss after 0 epochs: 0.889944 Time per epoch: 425.249387 seconds\n",
            " Train accuracy:  tensor([0.6957], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6980], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6992], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7005], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7019], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7030], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7041], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7054], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7066], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7071], device='cuda:0')\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Training loss after 1 epochs: 0.846475 Validation loss after 1 epochs: 0.860420 Time per epoch: 424.802705 seconds\n",
            " Train accuracy:  tensor([0.7161], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7177], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7188], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7193], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7199], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7208], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7218], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7227], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7234], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7097], device='cuda:0')\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Training loss after 2 epochs: 0.800404 Validation loss after 2 epochs: 0.850476 Time per epoch: 425.183922 seconds\n",
            " Train accuracy:  tensor([0.7297], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7306], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7318], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7319], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7327], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7333], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7339], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7346], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7354], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7113], device='cuda:0')\n",
            "EarlyStopping counter: 3 out of 10\n",
            "Training loss after 3 epochs: 0.767069 Validation loss after 3 epochs: 0.852817 Time per epoch: 425.163126 seconds\n",
            " Train accuracy:  tensor([0.7397], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7399], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7405], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7410], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7421], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7429], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7431], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7438], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7443], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7144], device='cuda:0')\n",
            "EarlyStopping counter: 4 out of 10\n",
            "Training loss after 4 epochs: 0.740066 Validation loss after 4 epochs: 0.854692 Time per epoch: 424.677992 seconds\n",
            " Train accuracy:  tensor([0.7475], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7483], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7491], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7492], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7500], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7509], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7510], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7514], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7519], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7165], device='cuda:0')\n",
            "EarlyStopping counter: 5 out of 10\n",
            "Training loss after 5 epochs: 0.718860 Validation loss after 5 epochs: 0.858634 Time per epoch: 425.399487 seconds\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "BiLSTM_train_not_random = BiLSTM_extended(nlabels = 6, epochs=6, train_parameters = True, random_embeddings = False)\n",
        "# Train model\n",
        "BiLSTM_train_not_random.trainloop(train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZu-CK2xNp8X"
      },
      "source": [
        "**Random embeddings + Not training embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy-JY-NGSvr7",
        "outputId": "1a494f72-42c1-43f4-9a76-92397879cf4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Train accuracy:  tensor([0.5713], device='cuda:0')\n",
            " Train accuracy:  tensor([0.5978], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6138], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6254], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6342], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6415], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6469], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6519], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6563], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.6915], device='cuda:0')\n",
            "Validation loss decreased (inf --> 0.892084).  Saving model ...\n",
            "Training loss after 0 epochs: 0.976209 Validation loss after 0 epochs: 0.892084 Time per epoch: 426.288996 seconds\n",
            " Train accuracy:  tensor([0.6951], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6967], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6973], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6983], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6998], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7012], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7022], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7035], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7046], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7049], device='cuda:0')\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Training loss after 1 epochs: 0.851104 Validation loss after 1 epochs: 0.867498 Time per epoch: 423.793269 seconds\n",
            " Train accuracy:  tensor([0.7169], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7175], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7184], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7191], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7199], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7207], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7211], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7220], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7227], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7107], device='cuda:0')\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Training loss after 2 epochs: 0.803522 Validation loss after 2 epochs: 0.856890 Time per epoch: 420.956376 seconds\n",
            " Train accuracy:  tensor([0.7275], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7290], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7290], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7291], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7303], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7310], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7318], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7327], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7336], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7138], device='cuda:0')\n",
            "EarlyStopping counter: 3 out of 10\n",
            "Training loss after 3 epochs: 0.772013 Validation loss after 3 epochs: 0.848286 Time per epoch: 421.087732 seconds\n",
            " Train accuracy:  tensor([0.7370], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7393], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7395], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7399], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7408], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7415], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7416], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7422], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7429], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7136], device='cuda:0')\n",
            "EarlyStopping counter: 4 out of 10\n",
            "Training loss after 4 epochs: 0.745450 Validation loss after 4 epochs: 0.857828 Time per epoch: 422.529812 seconds\n",
            " Train accuracy:  tensor([0.7441], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7462], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7470], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7474], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7482], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7485], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7490], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7497], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7505], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7133], device='cuda:0')\n",
            "EarlyStopping counter: 5 out of 10\n",
            "Training loss after 5 epochs: 0.724007 Validation loss after 5 epochs: 0.876593 Time per epoch: 420.625792 seconds\n",
            " Train accuracy:  tensor([0.7534], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7541], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7541], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7542], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7549], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7552], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7554], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7560], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7564], device='cuda:0')\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            " Validation accuracy:  tensor([0.7153], device='cuda:0')\n",
            "EarlyStopping counter: 6 out of 10\n",
            "Training loss after 6 epochs: 0.705397 Validation loss after 6 epochs: 0.866870 Time per epoch: 419.764306 seconds\n",
            " Train accuracy:  tensor([0.7611], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7639], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7653], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7666], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7687], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7710], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7730], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7754], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7784], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7197], device='cuda:0')\n",
            "EarlyStopping counter: 7 out of 10\n",
            "Training loss after 7 epochs: 0.641741 Validation loss after 7 epochs: 0.887877 Time per epoch: 415.298346 seconds\n",
            " Train accuracy:  tensor([0.7724], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7753], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7761], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7771], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7785], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7801], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7820], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7840], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7864], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7192], device='cuda:0')\n",
            "Validation loss decreased (0.892084 --> 0.893792).  Saving model ...\n",
            "Training loss after 8 epochs: 0.619572 Validation loss after 8 epochs: 0.893792 Time per epoch: 420.770934 seconds\n",
            " Train accuracy:  tensor([0.7795], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7818], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7824], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7830], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7844], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7861], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7876], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7893], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7915], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7206], device='cuda:0')\n",
            "Validation loss decreased (0.893792 --> 0.895813).  Saving model ...\n",
            "Training loss after 9 epochs: 0.607374 Validation loss after 9 epochs: 0.895813 Time per epoch: 417.471977 seconds\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "BiLSTM_not_train_random = BiLSTM_extended(nlabels = 6, epochs=10, train_parameters = False, random_embeddings = True)\n",
        "# Train model\n",
        "BiLSTM_not_train_random.trainloop(train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bthIFqDfiYbK"
      },
      "source": [
        "**GloVe embeddings + Not training embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHH4uzAJSvvD",
        "outputId": "9a7925d0-5916-48dc-8105-48241c5c1cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Train accuracy:  tensor([0.5740], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6007], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6170], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6285], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6372], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6443], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6497], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6546], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6587], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.6929], device='cuda:0')\n",
            "Validation loss decreased (inf --> 0.890015).  Saving model ...\n",
            "Training loss after 0 epochs: 0.971468 Validation loss after 0 epochs: 0.890015 Time per epoch: 415.687655 seconds\n",
            " Train accuracy:  tensor([0.6935], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6971], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6986], device='cuda:0')\n",
            " Train accuracy:  tensor([0.6999], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7011], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7027], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7037], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7049], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7064], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7036], device='cuda:0')\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Training loss after 1 epochs: 0.845774 Validation loss after 1 epochs: 0.859493 Time per epoch: 419.020356 seconds\n",
            " Train accuracy:  tensor([0.7178], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7183], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7191], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7196], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7205], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7215], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7220], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7224], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7233], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7117], device='cuda:0')\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Training loss after 2 epochs: 0.799566 Validation loss after 2 epochs: 0.848201 Time per epoch: 421.926715 seconds\n",
            " Train accuracy:  tensor([0.7284], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7296], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7311], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7317], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7326], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7333], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7339], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7344], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7352], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7114], device='cuda:0')\n",
            "EarlyStopping counter: 3 out of 10\n",
            "Training loss after 3 epochs: 0.766024 Validation loss after 3 epochs: 0.848528 Time per epoch: 420.204630 seconds\n",
            " Train accuracy:  tensor([0.7382], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7409], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7418], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7421], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7428], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7433], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7436], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7443], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7450], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7137], device='cuda:0')\n",
            "EarlyStopping counter: 4 out of 10\n",
            "Training loss after 4 epochs: 0.738446 Validation loss after 4 epochs: 0.858632 Time per epoch: 417.199073 seconds\n",
            " Train accuracy:  tensor([0.7480], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7502], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7512], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7513], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7519], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7524], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7523], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7528], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7535], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7150], device='cuda:0')\n",
            "EarlyStopping counter: 5 out of 10\n",
            "Training loss after 5 epochs: 0.716018 Validation loss after 5 epochs: 0.857292 Time per epoch: 416.066473 seconds\n",
            " Train accuracy:  tensor([0.7561], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7584], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7581], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7576], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7584], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7591], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7589], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7590], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7599], device='cuda:0')\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            " Validation accuracy:  tensor([0.7138], device='cuda:0')\n",
            "EarlyStopping counter: 6 out of 10\n",
            "Training loss after 6 epochs: 0.697729 Validation loss after 6 epochs: 0.857686 Time per epoch: 416.136100 seconds\n",
            " Train accuracy:  tensor([0.7630], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7662], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7685], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7693], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7715], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7736], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7759], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7787], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7822], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7221], device='cuda:0')\n",
            "EarlyStopping counter: 7 out of 10\n",
            "Training loss after 7 epochs: 0.633950 Validation loss after 7 epochs: 0.887595 Time per epoch: 412.940059 seconds\n",
            " Train accuracy:  tensor([0.7767], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7801], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7817], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7823], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7840], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7856], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7870], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7890], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7917], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7216], device='cuda:0')\n",
            "Validation loss decreased (0.890015 --> 0.895131).  Saving model ...\n",
            "Training loss after 8 epochs: 0.611118 Validation loss after 8 epochs: 0.895131 Time per epoch: 412.974706 seconds\n",
            " Train accuracy:  tensor([0.7831], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7857], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7874], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7876], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7894], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7910], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7921], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7939], device='cuda:0')\n",
            " Train accuracy:  tensor([0.7963], device='cuda:0')\n",
            " Validation accuracy:  tensor([0.7201], device='cuda:0')\n",
            "Validation loss decreased (0.895131 --> 0.902220).  Saving model ...\n",
            "Training loss after 9 epochs: 0.598120 Validation loss after 9 epochs: 0.902220 Time per epoch: 414.357013 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize model\n",
        "BiLSTM_not_train_not_random = BiLSTM_extended(nlabels = 6, epochs=10, train_parameters = False, random_embeddings = False)\n",
        "# Train model\n",
        "BiLSTM_not_train_not_random.trainloop(train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrOr4hfozgff"
      },
      "source": [
        "\n",
        "Test performance\n",
        "\n",
        "Use this class to train the model with the train and validation datasets, and then evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ-PtN4rhIRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680c6d8a-cd84-4296-f5c9-da5895a2a0e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_extended(\n",
              "  (embedding): Embedding(111283, 300)\n",
              "  (lstm1): LSTM(300, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (linear1): Linear(in_features=15, out_features=64, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (linear2): Linear(in_features=64, out_features=6, bias=True)\n",
              "  (elu): ELU(alpha=1.0)\n",
              "  (logsoftmax): LogSoftmax(dim=1)\n",
              "  (criterion): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "class BiLSTM_extended(BiLSTM):\n",
        "    \n",
        "    def __init__(self,nlabels, train_parameters, random_embeddings, epochs=100, lr=0.001):\n",
        "        \n",
        "        super().__init__(nlabels, train_parameters, random_embeddings)  \n",
        "        \n",
        "        self.lr = lr #Learning Rate\n",
        "        \n",
        "        self.optim = optim.AdamW(self.parameters(), lr=self.lr, weight_decay=0.01)\n",
        "        \n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.criterion = nn.CrossEntropyLoss()               \n",
        "        \n",
        "        # A list to store the loss evolution along training\n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "\n",
        "        self.valid_loss_during_training = []\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optim, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "    \n",
        "    def trainloop(self,train_dataloader, valid_dataloader):\n",
        "\n",
        "      for e in range(int(self.epochs)):\n",
        "\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Random data permutation at each epoch\n",
        "        \n",
        "        running_loss = 0.\n",
        "        \n",
        "        i = 0\n",
        "        \n",
        "        length = 0\n",
        "        \n",
        "        accuracies = []\n",
        "        \n",
        "        for news, labels in train_dataloader:         \n",
        "    \n",
        "            self.optim.zero_grad()  # Reset gradients\n",
        "        \n",
        "            out = self.forward(news.int())\n",
        "\n",
        "            loss = self.criterion(out,labels.long())\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            self.optim.step()\n",
        "            \n",
        "            top_p, top_class = out.topk(1, dim=1)\n",
        "            \n",
        "            equals = (top_class == labels.view(news.shape[0], 1))\n",
        "            \n",
        "            length += news.shape[0]\n",
        "            \n",
        "            accuracies.append(sum(equals)) \n",
        "            \n",
        "            accuracy = sum(accuracies)/length\n",
        "            accuracy\n",
        "            \n",
        "            i += 1\n",
        "            \n",
        "            if i%1000 == 0:\n",
        "                print(\" Train accuracy: \", accuracy)\n",
        "   \n",
        "            \n",
        "        self.loss_during_training.append(running_loss/len(train_dataloader))\n",
        "        \n",
        "        self.scheduler.step(accuracy)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(\"Time elapsed during epoch:\", end_time - start_time)\n",
        "\n",
        "    def evaluate_performance(self,dataloader):\n",
        "      predictions = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "          for news,labels in dataloader:\n",
        "\n",
        "              logprobs = self.forward(news)  \n",
        "              top_p, top_class = logprobs.topk(1, dim=1)\n",
        "\n",
        "              top_class_array = np.array(top_class).flatten()\n",
        "              predictions.extend(top_class_array)\n",
        "\n",
        "      return predictions\n",
        "\n",
        "\n",
        "          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwTJ7gzyrpkB"
      },
      "source": [
        "join the train and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55KvTiuKrJmI"
      },
      "source": [
        "This code uses the TensorDataset and DataLoader classes from PyTorch to create data loaders for the train and validation data, and the test data. The TensorDataset class is used to create a dataset object that contains the input tensors and their corresponding labels. The DataLoader class is then used to create data loaders for these datasets, with a batch size of 60. This makes it easy to iterate over the data in small batches during training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u3Qq7pDq73w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dcab9a-7f85-41c9-d18f-2338648585dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59319,)\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "# #  Join train and validation sequences and labels\n",
        "train_valid = np.concatenate((train_tokenized_padding, validation_tokenized_padding), axis=0)\n",
        "train_valid_labels = np.concatenate((np.array(train_labels), np.array(validation_labels)), axis=0)\n",
        "\n",
        "# Create a single tensor object for train+validation and test data\n",
        "tensor = torch.from_numpy(train_valid)\n",
        "test_tensor = torch.from_numpy(test_tokenized_padding)\n",
        "\n",
        "# Create a single TensorDataset and DataLoader object\n",
        "data = TensorDataset(tensor, torch.Tensor(train_valid_labels))\n",
        "batch_size = 60\n",
        "train_valid_loader = DataLoader(data, batch_size=batch_size)\n",
        "test_set = TensorDataset(test_tensor, torch.Tensor(np.array(test_labels)))\n",
        "testloader = DataLoader(test_set, batch_size=batch_size)\n",
        "print(test_labels.shape)\n",
        "print(type(testloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random embeddings + Training embeddings**"
      ],
      "metadata": {
        "id": "qfrLy58mj0Ah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9mC9N3WHa6e",
        "outputId": "4de2d8bb-891d-4a35-b77f-a91d6cdde866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train accuracy:  tensor([0.5536])\n",
            " Train accuracy:  tensor([0.5834])\n",
            " Train accuracy:  tensor([0.5988])\n",
            " Train accuracy:  tensor([0.6113])\n",
            " Train accuracy:  tensor([0.6222])\n",
            " Train accuracy:  tensor([0.6306])\n",
            " Train accuracy:  tensor([0.6375])\n",
            " Train accuracy:  tensor([0.6432])\n",
            " Train accuracy:  tensor([0.6482])\n",
            " Train accuracy:  tensor([0.6521])\n",
            "Time elapsed during epoch: 574.1420578956604\n",
            " Train accuracy:  tensor([0.6945])\n",
            " Train accuracy:  tensor([0.6950])\n",
            " Train accuracy:  tensor([0.6959])\n",
            " Train accuracy:  tensor([0.6970])\n",
            " Train accuracy:  tensor([0.6984])\n",
            " Train accuracy:  tensor([0.6998])\n",
            " Train accuracy:  tensor([0.7009])\n",
            " Train accuracy:  tensor([0.7022])\n",
            " Train accuracy:  tensor([0.7035])\n",
            " Train accuracy:  tensor([0.7043])\n",
            "Time elapsed during epoch: 575.6446743011475\n",
            " Train accuracy:  tensor([0.7132])\n",
            " Train accuracy:  tensor([0.7148])\n",
            " Train accuracy:  tensor([0.7161])\n",
            " Train accuracy:  tensor([0.7165])\n",
            " Train accuracy:  tensor([0.7176])\n",
            " Train accuracy:  tensor([0.7187])\n",
            " Train accuracy:  tensor([0.7193])\n",
            " Train accuracy:  tensor([0.7202])\n",
            " Train accuracy:  tensor([0.7210])\n",
            " Train accuracy:  tensor([0.7216])\n",
            "Time elapsed during epoch: 553.8061645030975\n",
            " Train accuracy:  tensor([0.7281])\n",
            " Train accuracy:  tensor([0.7294])\n",
            " Train accuracy:  tensor([0.7301])\n",
            " Train accuracy:  tensor([0.7301])\n",
            " Train accuracy:  tensor([0.7308])\n",
            " Train accuracy:  tensor([0.7318])\n",
            " Train accuracy:  tensor([0.7320])\n",
            " Train accuracy:  tensor([0.7327])\n",
            " Train accuracy:  tensor([0.7337])\n",
            " Train accuracy:  tensor([0.7339])\n",
            "Time elapsed during epoch: 551.2504372596741\n",
            " Train accuracy:  tensor([0.7392])\n",
            " Train accuracy:  tensor([0.7410])\n",
            " Train accuracy:  tensor([0.7404])\n",
            " Train accuracy:  tensor([0.7407])\n",
            " Train accuracy:  tensor([0.7411])\n",
            " Train accuracy:  tensor([0.7421])\n",
            " Train accuracy:  tensor([0.7420])\n",
            " Train accuracy:  tensor([0.7421])\n",
            " Train accuracy:  tensor([0.7428])\n",
            " Train accuracy:  tensor([0.7433])\n",
            "Time elapsed during epoch: 551.4434466362\n",
            " Train accuracy:  tensor([0.7479])\n",
            " Train accuracy:  tensor([0.7487])\n",
            " Train accuracy:  tensor([0.7487])\n",
            " Train accuracy:  tensor([0.7486])\n",
            " Train accuracy:  tensor([0.7493])\n",
            " Train accuracy:  tensor([0.7498])\n",
            " Train accuracy:  tensor([0.7494])\n",
            " Train accuracy:  tensor([0.7496])\n",
            " Train accuracy:  tensor([0.7501])\n",
            " Train accuracy:  tensor([0.7501])\n",
            "Time elapsed during epoch: 551.5674078464508\n",
            " Train accuracy:  tensor([0.7528])\n",
            " Train accuracy:  tensor([0.7546])\n",
            " Train accuracy:  tensor([0.7540])\n",
            " Train accuracy:  tensor([0.7545])\n",
            " Train accuracy:  tensor([0.7546])\n",
            " Train accuracy:  tensor([0.7553])\n",
            " Train accuracy:  tensor([0.7553])\n",
            " Train accuracy:  tensor([0.7557])\n",
            " Train accuracy:  tensor([0.7561])\n",
            " Train accuracy:  tensor([0.7562])\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Time elapsed during epoch: 552.2726678848267\n",
            " Train accuracy:  tensor([0.7632])\n",
            " Train accuracy:  tensor([0.7650])\n",
            " Train accuracy:  tensor([0.7658])\n",
            " Train accuracy:  tensor([0.7671])\n",
            " Train accuracy:  tensor([0.7687])\n",
            " Train accuracy:  tensor([0.7706])\n",
            " Train accuracy:  tensor([0.7720])\n",
            " Train accuracy:  tensor([0.7739])\n",
            " Train accuracy:  tensor([0.7762])\n",
            " Train accuracy:  tensor([0.7785])\n",
            "Time elapsed during epoch: 554.2439961433411\n",
            " Train accuracy:  tensor([0.7757])\n",
            " Train accuracy:  tensor([0.7780])\n",
            " Train accuracy:  tensor([0.7781])\n",
            " Train accuracy:  tensor([0.7791])\n",
            " Train accuracy:  tensor([0.7801])\n",
            " Train accuracy:  tensor([0.7816])\n",
            " Train accuracy:  tensor([0.7827])\n",
            " Train accuracy:  tensor([0.7840])\n",
            " Train accuracy:  tensor([0.7857])\n",
            " Train accuracy:  tensor([0.7875])\n",
            "Time elapsed during epoch: 557.8538055419922\n",
            " Train accuracy:  tensor([0.7819])\n",
            " Train accuracy:  tensor([0.7836])\n",
            " Train accuracy:  tensor([0.7840])\n",
            " Train accuracy:  tensor([0.7846])\n",
            " Train accuracy:  tensor([0.7857])\n",
            " Train accuracy:  tensor([0.7870])\n",
            " Train accuracy:  tensor([0.7879])\n",
            " Train accuracy:  tensor([0.7893])\n",
            " Train accuracy:  tensor([0.7909])\n",
            " Train accuracy:  tensor([0.7923])\n",
            "Time elapsed during epoch: 565.0173258781433\n",
            " Train accuracy:  tensor([0.7875])\n",
            " Train accuracy:  tensor([0.7898])\n",
            " Train accuracy:  tensor([0.7894])\n",
            " Train accuracy:  tensor([0.7900])\n",
            " Train accuracy:  tensor([0.7907])\n",
            " Train accuracy:  tensor([0.7918])\n",
            " Train accuracy:  tensor([0.7926])\n",
            " Train accuracy:  tensor([0.7935])\n",
            " Train accuracy:  tensor([0.7950])\n",
            " Train accuracy:  tensor([0.7962])\n",
            "Time elapsed during epoch: 569.0545787811279\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "BiLSTM_test_train_random = BiLSTM_extended(nlabels = 6, epochs=11, train_parameters = True, random_embeddings = True)\n",
        "\n",
        "# Train model\n",
        "BiLSTM_test_train_random.trainloop(train_valid_loader, valid_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "predictions1 = BiLSTM_test_train_random.evaluate_performance(testloader)"
      ],
      "metadata": {
        "id": "GABU5JD6jZ1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hodaoyWSER-h",
        "outputId": "4091a2e6-5a23-49f0-b792-16b5914d5ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1, 1)\n"
          ]
        }
      ],
      "source": [
        "print(type(predictions1))\n",
        "print(predictions1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBLVW2PVSv-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6624c843-fef0-4c90-d7e6-dfc81a67f6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80     23507\n",
            "           1       0.49      0.37      0.42      3514\n",
            "           2       0.69      0.54      0.61     11297\n",
            "           3       0.29      0.07      0.11      1224\n",
            "           4       0.74      0.85      0.79     17472\n",
            "           5       0.71      0.59      0.64      2305\n",
            "\n",
            "    accuracy                           0.73     59319\n",
            "   macro avg       0.61      0.54      0.56     59319\n",
            "weighted avg       0.71      0.73      0.72     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, predictions1, zero_division=1))\n",
        "\n",
        "# print(np.unique(test_labels))\n",
        "# print(np.unique(predictions1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr4xB-RuSwC3",
        "outputId": "339b6193-1339-4789-e98f-ab773538fc93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7286366931337346\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(test_labels, predictions1)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3eWzFJPSwGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44bd76e-938c-43e2-d49d-45630fa45836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score:  0.7162554964843888\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(test_labels, predictions1, average='weighted')\n",
        "print(\"F1 score: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Classification report without 'true' label\n",
        "print(classification_report(test_labels, predictions1, labels = [1,2,3,4,5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgH39yNMbP8D",
        "outputId": "ba5b42c4-b463-4cfb-94a0-144fd18783ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.49      0.37      0.42      3514\n",
            "           2       0.69      0.54      0.61     11297\n",
            "           3       0.29      0.07      0.11      1224\n",
            "           4       0.74      0.85      0.79     17472\n",
            "           5       0.71      0.59      0.64      2305\n",
            "\n",
            "   micro avg       0.70      0.66      0.68     35812\n",
            "   macro avg       0.58      0.48      0.51     35812\n",
            "weighted avg       0.68      0.66      0.66     35812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pFE-SMfvc05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163499a2-fe6b-4547-d0a4-2d364632810b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:  [[19586   582  1454    95  1573   217]\n",
            " [  902  1300   219    29   994    70]\n",
            " [ 2554   181  6127    21  2263   151]\n",
            " [  614   136   111    82   217    64]\n",
            " [ 1454   336   833    22 14770    57]\n",
            " [  431   108   180    32   197  1357]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(test_labels, predictions1)\n",
        "print(\"Confusion matrix: \", confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCtNfXz9vvFW"
      },
      "source": [
        "**GloVe embeddings + Training embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH3mDISevc4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6ff3b6-4278-4c7e-85f0-02f9f62f7d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train accuracy:  tensor([0.5667])\n",
            " Train accuracy:  tensor([0.5984])\n",
            " Train accuracy:  tensor([0.6161])\n",
            " Train accuracy:  tensor([0.6283])\n",
            " Train accuracy:  tensor([0.6371])\n",
            " Train accuracy:  tensor([0.6443])\n",
            " Train accuracy:  tensor([0.6499])\n",
            " Train accuracy:  tensor([0.6549])\n",
            " Train accuracy:  tensor([0.6592])\n",
            " Train accuracy:  tensor([0.6627])\n",
            "Time elapsed during epoch: 548.3103497028351\n",
            " Train accuracy:  tensor([0.6976])\n",
            " Train accuracy:  tensor([0.6994])\n",
            " Train accuracy:  tensor([0.7007])\n",
            " Train accuracy:  tensor([0.7020])\n",
            " Train accuracy:  tensor([0.7034])\n",
            " Train accuracy:  tensor([0.7049])\n",
            " Train accuracy:  tensor([0.7058])\n",
            " Train accuracy:  tensor([0.7070])\n",
            " Train accuracy:  tensor([0.7081])\n",
            " Train accuracy:  tensor([0.7088])\n",
            "Time elapsed during epoch: 542.9115703105927\n",
            " Train accuracy:  tensor([0.7200])\n",
            " Train accuracy:  tensor([0.7203])\n",
            " Train accuracy:  tensor([0.7206])\n",
            " Train accuracy:  tensor([0.7207])\n",
            " Train accuracy:  tensor([0.7214])\n",
            " Train accuracy:  tensor([0.7224])\n",
            " Train accuracy:  tensor([0.7229])\n",
            " Train accuracy:  tensor([0.7240])\n",
            " Train accuracy:  tensor([0.7246])\n",
            " Train accuracy:  tensor([0.7250])\n",
            "Time elapsed during epoch: 541.9956867694855\n",
            " Train accuracy:  tensor([0.7296])\n",
            " Train accuracy:  tensor([0.7307])\n",
            " Train accuracy:  tensor([0.7307])\n",
            " Train accuracy:  tensor([0.7318])\n",
            " Train accuracy:  tensor([0.7327])\n",
            " Train accuracy:  tensor([0.7332])\n",
            " Train accuracy:  tensor([0.7336])\n",
            " Train accuracy:  tensor([0.7343])\n",
            " Train accuracy:  tensor([0.7348])\n",
            " Train accuracy:  tensor([0.7352])\n",
            "Time elapsed during epoch: 542.052873134613\n",
            " Train accuracy:  tensor([0.7390])\n",
            " Train accuracy:  tensor([0.7407])\n",
            " Train accuracy:  tensor([0.7404])\n",
            " Train accuracy:  tensor([0.7407])\n",
            " Train accuracy:  tensor([0.7410])\n",
            " Train accuracy:  tensor([0.7416])\n",
            " Train accuracy:  tensor([0.7418])\n",
            " Train accuracy:  tensor([0.7423])\n",
            " Train accuracy:  tensor([0.7429])\n",
            " Train accuracy:  tensor([0.7431])\n",
            "Time elapsed during epoch: 542.001522064209\n",
            " Train accuracy:  tensor([0.7478])\n",
            " Train accuracy:  tensor([0.7494])\n",
            " Train accuracy:  tensor([0.7491])\n",
            " Train accuracy:  tensor([0.7488])\n",
            " Train accuracy:  tensor([0.7491])\n",
            " Train accuracy:  tensor([0.7496])\n",
            " Train accuracy:  tensor([0.7494])\n",
            " Train accuracy:  tensor([0.7500])\n",
            " Train accuracy:  tensor([0.7506])\n",
            " Train accuracy:  tensor([0.7507])\n",
            "Time elapsed during epoch: 541.2125642299652\n",
            " Train accuracy:  tensor([0.7537])\n",
            " Train accuracy:  tensor([0.7551])\n",
            " Train accuracy:  tensor([0.7545])\n",
            " Train accuracy:  tensor([0.7551])\n",
            " Train accuracy:  tensor([0.7552])\n",
            " Train accuracy:  tensor([0.7553])\n",
            " Train accuracy:  tensor([0.7554])\n",
            " Train accuracy:  tensor([0.7557])\n",
            " Train accuracy:  tensor([0.7563])\n",
            " Train accuracy:  tensor([0.7563])\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Time elapsed during epoch: 542.2902681827545\n",
            " Train accuracy:  tensor([0.7615])\n",
            " Train accuracy:  tensor([0.7646])\n",
            " Train accuracy:  tensor([0.7654])\n",
            " Train accuracy:  tensor([0.7668])\n",
            " Train accuracy:  tensor([0.7683])\n",
            " Train accuracy:  tensor([0.7701])\n",
            " Train accuracy:  tensor([0.7716])\n",
            " Train accuracy:  tensor([0.7737])\n",
            " Train accuracy:  tensor([0.7763])\n",
            " Train accuracy:  tensor([0.7786])\n",
            "Time elapsed during epoch: 541.9495732784271\n",
            " Train accuracy:  tensor([0.7753])\n",
            " Train accuracy:  tensor([0.7775])\n",
            " Train accuracy:  tensor([0.7777])\n",
            " Train accuracy:  tensor([0.7786])\n",
            " Train accuracy:  tensor([0.7796])\n",
            " Train accuracy:  tensor([0.7807])\n",
            " Train accuracy:  tensor([0.7819])\n",
            " Train accuracy:  tensor([0.7834])\n",
            " Train accuracy:  tensor([0.7854])\n",
            " Train accuracy:  tensor([0.7871])\n",
            "Time elapsed during epoch: 543.7337629795074\n",
            " Train accuracy:  tensor([0.7809])\n",
            " Train accuracy:  tensor([0.7835])\n",
            " Train accuracy:  tensor([0.7836])\n",
            " Train accuracy:  tensor([0.7845])\n",
            " Train accuracy:  tensor([0.7852])\n",
            " Train accuracy:  tensor([0.7862])\n",
            " Train accuracy:  tensor([0.7871])\n",
            " Train accuracy:  tensor([0.7885])\n",
            " Train accuracy:  tensor([0.7903])\n",
            " Train accuracy:  tensor([0.7917])\n",
            "Time elapsed during epoch: 542.6741530895233\n",
            " Train accuracy:  tensor([0.7834])\n",
            " Train accuracy:  tensor([0.7869])\n",
            " Train accuracy:  tensor([0.7877])\n",
            " Train accuracy:  tensor([0.7882])\n",
            " Train accuracy:  tensor([0.7889])\n",
            " Train accuracy:  tensor([0.7903])\n",
            " Train accuracy:  tensor([0.7912])\n",
            " Train accuracy:  tensor([0.7923])\n",
            " Train accuracy:  tensor([0.7940])\n",
            " Train accuracy:  tensor([0.7953])\n",
            "Time elapsed during epoch: 545.1668705940247\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize model\n",
        "BiLSTM_test_train_not_random = BiLSTM_extended(nlabels = 6, epochs=11, train_parameters = True, random_embeddings = False)\n",
        "# Train model\n",
        "BiLSTM_test_train_not_random.trainloop(train_valid_loader, valid_dataloader)\n",
        "# Get predictions\n",
        "predictions2 = BiLSTM_test_train_not_random.evaluate_performance(testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG4qPKlWvc7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74788bd1-a26f-47e6-eba5-0cf5fc69a9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.85      0.79     23507\n",
            "           1       0.52      0.37      0.43      3514\n",
            "           2       0.68      0.55      0.60     11297\n",
            "           3       0.39      0.06      0.10      1224\n",
            "           4       0.75      0.83      0.79     17472\n",
            "           5       0.71      0.56      0.63      2305\n",
            "\n",
            "    accuracy                           0.73     59319\n",
            "   macro avg       0.63      0.53      0.56     59319\n",
            "weighted avg       0.71      0.73      0.71     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, predictions2, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oTKkh5Bvc-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fd65df-c4e0-4deb-e3ba-c73a98c8da1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7271869047016976\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(test_labels, predictions2)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report with no 'true' label\n",
        "print(classification_report(test_labels, predictions2, labels = [1,2,3,4,5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfLgEBPebjXz",
        "outputId": "f646196a-7cca-4d6f-b83b-48193cd655b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.52      0.37      0.43      3514\n",
            "           2       0.68      0.55      0.60     11297\n",
            "           3       0.39      0.06      0.10      1224\n",
            "           4       0.75      0.83      0.79     17472\n",
            "           5       0.71      0.56      0.63      2305\n",
            "\n",
            "   micro avg       0.71      0.65      0.68     35812\n",
            "   macro avg       0.61      0.47      0.51     35812\n",
            "weighted avg       0.69      0.65      0.66     35812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Vz9jNtUvdBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a07440-c3f0-454e-9c91-7f8516e11f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score:  0.7137842584636908\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(test_labels, predictions2, average='weighted')\n",
        "print(\"F1 score: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt_GfxshwQjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fbd0ad-7a4c-4212-c918-6fa09e259712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:  [[19894   417  1477    46  1454   219]\n",
            " [  990  1287   231    20   929    57]\n",
            " [ 2802   194  6165     7  2004   125]\n",
            " [  668   119   123    69   176    69]\n",
            " [ 1681   378   927     9 14430    47]\n",
            " [  539    95   205    25   150  1291]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(test_labels, predictions2)\n",
        "print(\"Confusion matrix: \", confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBbsSVxvw3nS"
      },
      "source": [
        "**Random embeddings + Not training embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4A_Q7niw1Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75acad4-b1b3-4f4d-b9e1-8db0f8af21bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train accuracy:  tensor([0.5674])\n",
            " Train accuracy:  tensor([0.5914])\n",
            " Train accuracy:  tensor([0.6066])\n",
            " Train accuracy:  tensor([0.6184])\n",
            " Train accuracy:  tensor([0.6283])\n",
            " Train accuracy:  tensor([0.6359])\n",
            " Train accuracy:  tensor([0.6423])\n",
            " Train accuracy:  tensor([0.6477])\n",
            " Train accuracy:  tensor([0.6522])\n",
            " Train accuracy:  tensor([0.6558])\n",
            "Time elapsed during epoch: 542.0858280658722\n",
            " Train accuracy:  tensor([0.6944])\n",
            " Train accuracy:  tensor([0.6957])\n",
            " Train accuracy:  tensor([0.6963])\n",
            " Train accuracy:  tensor([0.6977])\n",
            " Train accuracy:  tensor([0.6992])\n",
            " Train accuracy:  tensor([0.7004])\n",
            " Train accuracy:  tensor([0.7017])\n",
            " Train accuracy:  tensor([0.7030])\n",
            " Train accuracy:  tensor([0.7041])\n",
            " Train accuracy:  tensor([0.7050])\n",
            "Time elapsed during epoch: 539.8221468925476\n",
            " Train accuracy:  tensor([0.7157])\n",
            " Train accuracy:  tensor([0.7168])\n",
            " Train accuracy:  tensor([0.7178])\n",
            " Train accuracy:  tensor([0.7185])\n",
            " Train accuracy:  tensor([0.7198])\n",
            " Train accuracy:  tensor([0.7206])\n",
            " Train accuracy:  tensor([0.7212])\n",
            " Train accuracy:  tensor([0.7222])\n",
            " Train accuracy:  tensor([0.7231])\n",
            " Train accuracy:  tensor([0.7236])\n",
            "Time elapsed during epoch: 542.7214245796204\n",
            " Train accuracy:  tensor([0.7299])\n",
            " Train accuracy:  tensor([0.7320])\n",
            " Train accuracy:  tensor([0.7328])\n",
            " Train accuracy:  tensor([0.7327])\n",
            " Train accuracy:  tensor([0.7335])\n",
            " Train accuracy:  tensor([0.7340])\n",
            " Train accuracy:  tensor([0.7347])\n",
            " Train accuracy:  tensor([0.7354])\n",
            " Train accuracy:  tensor([0.7360])\n",
            " Train accuracy:  tensor([0.7363])\n",
            "Time elapsed during epoch: 543.0587928295135\n",
            " Train accuracy:  tensor([0.7389])\n",
            " Train accuracy:  tensor([0.7410])\n",
            " Train accuracy:  tensor([0.7418])\n",
            " Train accuracy:  tensor([0.7421])\n",
            " Train accuracy:  tensor([0.7428])\n",
            " Train accuracy:  tensor([0.7433])\n",
            " Train accuracy:  tensor([0.7439])\n",
            " Train accuracy:  tensor([0.7444])\n",
            " Train accuracy:  tensor([0.7450])\n",
            " Train accuracy:  tensor([0.7452])\n",
            "Time elapsed during epoch: 540.59836769104\n",
            " Train accuracy:  tensor([0.7491])\n",
            " Train accuracy:  tensor([0.7509])\n",
            " Train accuracy:  tensor([0.7510])\n",
            " Train accuracy:  tensor([0.7506])\n",
            " Train accuracy:  tensor([0.7511])\n",
            " Train accuracy:  tensor([0.7517])\n",
            " Train accuracy:  tensor([0.7521])\n",
            " Train accuracy:  tensor([0.7527])\n",
            " Train accuracy:  tensor([0.7531])\n",
            " Train accuracy:  tensor([0.7531])\n",
            "Time elapsed during epoch: 541.5243470668793\n",
            " Train accuracy:  tensor([0.7563])\n",
            " Train accuracy:  tensor([0.7581])\n",
            " Train accuracy:  tensor([0.7581])\n",
            " Train accuracy:  tensor([0.7577])\n",
            " Train accuracy:  tensor([0.7583])\n",
            " Train accuracy:  tensor([0.7588])\n",
            " Train accuracy:  tensor([0.7592])\n",
            " Train accuracy:  tensor([0.7596])\n",
            " Train accuracy:  tensor([0.7603])\n",
            " Train accuracy:  tensor([0.7604])\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Time elapsed during epoch: 541.1049361228943\n",
            " Train accuracy:  tensor([0.7641])\n",
            " Train accuracy:  tensor([0.7662])\n",
            " Train accuracy:  tensor([0.7673])\n",
            " Train accuracy:  tensor([0.7686])\n",
            " Train accuracy:  tensor([0.7701])\n",
            " Train accuracy:  tensor([0.7721])\n",
            " Train accuracy:  tensor([0.7741])\n",
            " Train accuracy:  tensor([0.7764])\n",
            " Train accuracy:  tensor([0.7789])\n",
            " Train accuracy:  tensor([0.7811])\n",
            "Time elapsed during epoch: 541.8492205142975\n",
            " Train accuracy:  tensor([0.7772])\n",
            " Train accuracy:  tensor([0.7784])\n",
            " Train accuracy:  tensor([0.7799])\n",
            " Train accuracy:  tensor([0.7801])\n",
            " Train accuracy:  tensor([0.7812])\n",
            " Train accuracy:  tensor([0.7827])\n",
            " Train accuracy:  tensor([0.7842])\n",
            " Train accuracy:  tensor([0.7859])\n",
            " Train accuracy:  tensor([0.7879])\n",
            " Train accuracy:  tensor([0.7895])\n",
            "Time elapsed during epoch: 540.0743961334229\n",
            " Train accuracy:  tensor([0.7840])\n",
            " Train accuracy:  tensor([0.7851])\n",
            " Train accuracy:  tensor([0.7860])\n",
            " Train accuracy:  tensor([0.7864])\n",
            " Train accuracy:  tensor([0.7875])\n",
            " Train accuracy:  tensor([0.7887])\n",
            " Train accuracy:  tensor([0.7900])\n",
            " Train accuracy:  tensor([0.7916])\n",
            " Train accuracy:  tensor([0.7933])\n",
            " Train accuracy:  tensor([0.7948])\n",
            "Time elapsed during epoch: 539.601211309433\n",
            " Train accuracy:  tensor([0.7892])\n",
            " Train accuracy:  tensor([0.7908])\n",
            " Train accuracy:  tensor([0.7911])\n",
            " Train accuracy:  tensor([0.7917])\n",
            " Train accuracy:  tensor([0.7924])\n",
            " Train accuracy:  tensor([0.7936])\n",
            " Train accuracy:  tensor([0.7948])\n",
            " Train accuracy:  tensor([0.7962])\n",
            " Train accuracy:  tensor([0.7977])\n",
            " Train accuracy:  tensor([0.7988])\n",
            "Time elapsed during epoch: 542.2139027118683\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize model\n",
        "BiLSTM_test_not_train_random = BiLSTM_extended(nlabels = 6, epochs=11, train_parameters = False, random_embeddings = True)\n",
        "# Train model\n",
        "BiLSTM_test_not_train_random.trainloop(train_valid_loader, valid_dataloader)\n",
        "# Get predictions\n",
        "predictions3 = BiLSTM_test_not_train_random.evaluate_performance(testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YumyIdNww1LQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460b4088-4ee3-4ee1-c2be-e2c934c26963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.84      0.80     23507\n",
            "           1       0.49      0.39      0.43      3514\n",
            "           2       0.69      0.54      0.60     11297\n",
            "           3       0.24      0.02      0.04      1224\n",
            "           4       0.74      0.85      0.79     17472\n",
            "           5       0.69      0.58      0.63      2305\n",
            "\n",
            "    accuracy                           0.73     59319\n",
            "   macro avg       0.60      0.54      0.55     59319\n",
            "weighted avg       0.71      0.73      0.72     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, predictions3, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbjzvMn4w1OY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144da6ac-a7eb-4d17-f18b-8dc7cd8c5ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7289064212141135\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(test_labels, predictions3)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report without 'true' label\n",
        "print(classification_report(test_labels, predictions3, labels = [1,2,3,4,5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxdt--7nbo11",
        "outputId": "02c572e1-f225-4b34-d8a9-a4b1d7225d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.49      0.39      0.43      3514\n",
            "           2       0.69      0.54      0.60     11297\n",
            "           3       0.24      0.02      0.04      1224\n",
            "           4       0.74      0.85      0.79     17472\n",
            "           5       0.69      0.58      0.63      2305\n",
            "\n",
            "   micro avg       0.70      0.66      0.68     35812\n",
            "   macro avg       0.57      0.48      0.50     35812\n",
            "weighted avg       0.68      0.66      0.66     35812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxKuMSXqw1RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538bc13a-0476-41b5-fe4b-83b1a3a50aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score:  0.7152932816579283\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(test_labels, predictions3, average='weighted')\n",
        "print(\"F1 score: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv2lofk9w1Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53dcde0e-d829-46a0-fbe0-fa8ce64f9e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:  [[19633   512  1472    40  1631   219]\n",
            " [  852  1382   195    10   994    81]\n",
            " [ 2568   224  6078    10  2274   143]\n",
            " [  608   176   114    25   219    82]\n",
            " [ 1423   409   777     3 14786    74]\n",
            " [  455   141   192    16   167  1334]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(test_labels, predictions3)\n",
        "print(\"Confusion matrix: \", confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EABAKQKE8Sy_"
      },
      "source": [
        "**GloVe embeddings + Not training embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohe-HO1fw1jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978c06b1-10ff-41a1-d1d4-cd19dd429093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train accuracy:  tensor([0.5655])\n",
            " Train accuracy:  tensor([0.5889])\n",
            " Train accuracy:  tensor([0.6030])\n",
            " Train accuracy:  tensor([0.6142])\n",
            " Train accuracy:  tensor([0.6234])\n",
            " Train accuracy:  tensor([0.6314])\n",
            " Train accuracy:  tensor([0.6379])\n",
            " Train accuracy:  tensor([0.6434])\n",
            " Train accuracy:  tensor([0.6482])\n",
            " Train accuracy:  tensor([0.6520])\n",
            "Time elapsed during epoch: 540.4354031085968\n",
            " Train accuracy:  tensor([0.6904])\n",
            " Train accuracy:  tensor([0.6924])\n",
            " Train accuracy:  tensor([0.6941])\n",
            " Train accuracy:  tensor([0.6955])\n",
            " Train accuracy:  tensor([0.6976])\n",
            " Train accuracy:  tensor([0.6993])\n",
            " Train accuracy:  tensor([0.7006])\n",
            " Train accuracy:  tensor([0.7023])\n",
            " Train accuracy:  tensor([0.7037])\n",
            " Train accuracy:  tensor([0.7047])\n",
            "Time elapsed during epoch: 540.9570572376251\n",
            " Train accuracy:  tensor([0.7148])\n",
            " Train accuracy:  tensor([0.7158])\n",
            " Train accuracy:  tensor([0.7171])\n",
            " Train accuracy:  tensor([0.7178])\n",
            " Train accuracy:  tensor([0.7193])\n",
            " Train accuracy:  tensor([0.7203])\n",
            " Train accuracy:  tensor([0.7210])\n",
            " Train accuracy:  tensor([0.7221])\n",
            " Train accuracy:  tensor([0.7228])\n",
            " Train accuracy:  tensor([0.7233])\n",
            "Time elapsed during epoch: 541.4948282241821\n",
            " Train accuracy:  tensor([0.7297])\n",
            " Train accuracy:  tensor([0.7319])\n",
            " Train accuracy:  tensor([0.7315])\n",
            " Train accuracy:  tensor([0.7318])\n",
            " Train accuracy:  tensor([0.7327])\n",
            " Train accuracy:  tensor([0.7334])\n",
            " Train accuracy:  tensor([0.7341])\n",
            " Train accuracy:  tensor([0.7348])\n",
            " Train accuracy:  tensor([0.7353])\n",
            " Train accuracy:  tensor([0.7356])\n",
            "Time elapsed during epoch: 541.2181146144867\n",
            " Train accuracy:  tensor([0.7406])\n",
            " Train accuracy:  tensor([0.7426])\n",
            " Train accuracy:  tensor([0.7425])\n",
            " Train accuracy:  tensor([0.7427])\n",
            " Train accuracy:  tensor([0.7434])\n",
            " Train accuracy:  tensor([0.7441])\n",
            " Train accuracy:  tensor([0.7443])\n",
            " Train accuracy:  tensor([0.7449])\n",
            " Train accuracy:  tensor([0.7455])\n",
            " Train accuracy:  tensor([0.7457])\n",
            "Time elapsed during epoch: 541.5088074207306\n",
            " Train accuracy:  tensor([0.7477])\n",
            " Train accuracy:  tensor([0.7495])\n",
            " Train accuracy:  tensor([0.7498])\n",
            " Train accuracy:  tensor([0.7502])\n",
            " Train accuracy:  tensor([0.7509])\n",
            " Train accuracy:  tensor([0.7512])\n",
            " Train accuracy:  tensor([0.7516])\n",
            " Train accuracy:  tensor([0.7520])\n",
            " Train accuracy:  tensor([0.7527])\n",
            " Train accuracy:  tensor([0.7529])\n",
            "Time elapsed during epoch: 541.2842683792114\n",
            " Train accuracy:  tensor([0.7578])\n",
            " Train accuracy:  tensor([0.7583])\n",
            " Train accuracy:  tensor([0.7583])\n",
            " Train accuracy:  tensor([0.7582])\n",
            " Train accuracy:  tensor([0.7583])\n",
            " Train accuracy:  tensor([0.7588])\n",
            " Train accuracy:  tensor([0.7589])\n",
            " Train accuracy:  tensor([0.7593])\n",
            " Train accuracy:  tensor([0.7595])\n",
            " Train accuracy:  tensor([0.7599])\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Time elapsed during epoch: 542.4745898246765\n",
            " Train accuracy:  tensor([0.7641])\n",
            " Train accuracy:  tensor([0.7668])\n",
            " Train accuracy:  tensor([0.7677])\n",
            " Train accuracy:  tensor([0.7690])\n",
            " Train accuracy:  tensor([0.7707])\n",
            " Train accuracy:  tensor([0.7728])\n",
            " Train accuracy:  tensor([0.7746])\n",
            " Train accuracy:  tensor([0.7765])\n",
            " Train accuracy:  tensor([0.7789])\n",
            " Train accuracy:  tensor([0.7813])\n",
            "Time elapsed during epoch: 543.4303112030029\n",
            " Train accuracy:  tensor([0.7774])\n",
            " Train accuracy:  tensor([0.7790])\n",
            " Train accuracy:  tensor([0.7802])\n",
            " Train accuracy:  tensor([0.7813])\n",
            " Train accuracy:  tensor([0.7823])\n",
            " Train accuracy:  tensor([0.7839])\n",
            " Train accuracy:  tensor([0.7850])\n",
            " Train accuracy:  tensor([0.7865])\n",
            " Train accuracy:  tensor([0.7884])\n",
            " Train accuracy:  tensor([0.7902])\n",
            "Time elapsed during epoch: 541.3605325222015\n",
            " Train accuracy:  tensor([0.7845])\n",
            " Train accuracy:  tensor([0.7854])\n",
            " Train accuracy:  tensor([0.7864])\n",
            " Train accuracy:  tensor([0.7875])\n",
            " Train accuracy:  tensor([0.7882])\n",
            " Train accuracy:  tensor([0.7895])\n",
            " Train accuracy:  tensor([0.7907])\n",
            " Train accuracy:  tensor([0.7921])\n",
            " Train accuracy:  tensor([0.7937])\n",
            " Train accuracy:  tensor([0.7952])\n",
            "Time elapsed during epoch: 542.1909348964691\n",
            " Train accuracy:  tensor([0.7888])\n",
            " Train accuracy:  tensor([0.7899])\n",
            " Train accuracy:  tensor([0.7906])\n",
            " Train accuracy:  tensor([0.7915])\n",
            " Train accuracy:  tensor([0.7924])\n",
            " Train accuracy:  tensor([0.7938])\n",
            " Train accuracy:  tensor([0.7949])\n",
            " Train accuracy:  tensor([0.7961])\n",
            " Train accuracy:  tensor([0.7976])\n",
            " Train accuracy:  tensor([0.7990])\n",
            "Time elapsed during epoch: 543.0241298675537\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize model\n",
        "BiLSTM_test_not_train_not_random = BiLSTM_extended(nlabels = 6, epochs=11, train_parameters = False, random_embeddings = False)\n",
        "# Train model\n",
        "BiLSTM_test_not_train_not_random.trainloop(train_valid_loader, valid_dataloader)\n",
        "# Get predictions\n",
        "predictions4 = BiLSTM_test_not_train_not_random.evaluate_performance(testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfQwPBhv8QY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbc1f0c-89a0-411a-80a3-18a3298cc95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80     23507\n",
            "           1       0.49      0.36      0.41      3514\n",
            "           2       0.68      0.56      0.61     11297\n",
            "           3       0.14      0.00      0.00      1224\n",
            "           4       0.74      0.85      0.79     17472\n",
            "           5       0.68      0.60      0.63      2305\n",
            "\n",
            "    accuracy                           0.73     59319\n",
            "   macro avg       0.58      0.53      0.54     59319\n",
            "weighted avg       0.71      0.73      0.71     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, predictions4, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMr97PKX8QbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ddd04d-9909-4b07-f795-56d1fb89c8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7287546991689003\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(test_labels, predictions4)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report without 'true' label\n",
        "print(classification_report(test_labels, predictions4, labels = [1,2,3,4,5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj93GJ3Zbtgy",
        "outputId": "5afc7f7a-2886-456a-e0ab-6050d4a4f55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.49      0.36      0.41      3514\n",
            "           2       0.68      0.56      0.61     11297\n",
            "           3       0.14      0.00      0.00      1224\n",
            "           4       0.74      0.85      0.79     17472\n",
            "           5       0.68      0.60      0.63      2305\n",
            "\n",
            "   micro avg       0.70      0.66      0.68     35812\n",
            "   macro avg       0.54      0.47      0.49     35812\n",
            "weighted avg       0.67      0.66      0.66     35812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-2_6wTb8Qey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35477734-b587-46da-c445-c485a7802070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score:  0.7143758134183377\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(test_labels, predictions4, average='weighted')\n",
        "print(\"F1 score: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvPoW-vG8QhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71740ce0-7eac-497a-ebff-b1bb6ee07eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:  [[19419   537  1604     2  1682   263]\n",
            " [  898  1268   206     1  1041   100]\n",
            " [ 2513   205  6324     1  2113   141]\n",
            " [  640   144   121     1   225    93]\n",
            " [ 1346   325   893     1 14842    65]\n",
            " [  465   120   173     1   171  1375]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(test_labels, predictions4)\n",
        "print(\"Confusion matrix: \", confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVEa1iX88Qjv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnT7D5xX8Qm4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH-6A8-p8Qpc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tkSmHXm8QtG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}