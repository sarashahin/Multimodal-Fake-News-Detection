{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih8WlFLpT4zW"
      },
      "source": [
        "Loading the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWzOVHpHCdqu",
        "outputId": "f4aab6ed-e9d2-4ea2-af0b-fa9f01ba215d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow \n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import spacy\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, SpatialDropout1D, Conv1D, MaxPooling1D, GRU, BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Bidirectional, GlobalAveragePooling1D, concatenate, LeakyReLU, GlobalMaxPooling1D, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras_preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7zUD1sOY0wZ",
        "outputId": "27939d95-9285-4510-945e-d5f1f6862802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1YKA3TIA7Db"
      },
      "outputs": [],
      "source": [
        "# !pip install Keras-Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjGqnqpXH5C1",
        "outputId": "072cb70c-7d82-4b97-e2bc-dd1fe4bb4baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# Check if the GPU is detected\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfITUYMqIGzN",
        "outputId": "2b86c098-1511-4db8-a9d9-7e79420f97d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "       \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    \n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55QGZyN19MC5",
        "outputId": "bb30f9e2-c4f2-47a7-b79f-9d32676bbac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY0Aw3RJTQG4"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xdC-LJP9Sbf"
      },
      "outputs": [],
      "source": [
        "# Train data \n",
        "all_train = pd.read_csv('/content/gdrive/MyDrive/all_train.tsv',sep='\\t')\n",
        "# Validation data \n",
        "all_validate = pd.read_csv('/content/gdrive/MyDrive/all_validate.tsv',sep='\\t')\n",
        "# Test data \n",
        "all_test_public = pd.read_csv('/content/gdrive/MyDrive/all_test_public.tsv',sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MKRZXAZXaow"
      },
      "source": [
        "I select a subset of the dataframe with no missing values in the 'clean_title' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgn-fro3Uwlo"
      },
      "outputs": [],
      "source": [
        "# Train data with no missing values\n",
        "all_train_data = all_train[all_train['clean_title'].notna()]\n",
        "# Validation data with no missing values\n",
        "all_validate_data = all_validate[all_validate['clean_title'].notnull()]\n",
        "# Test data with no missing values\n",
        "all_test_public_data = all_test_public[all_test_public['clean_title'].notnull()]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiOKgKLRWv9B"
      },
      "source": [
        "I separate the datasets into text and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3weEt53Uwot"
      },
      "outputs": [],
      "source": [
        "## Train data\n",
        "train_Data_news = list(all_train_data['clean_title'])\n",
        "train_Data_labels = list(all_train_data['6_way_label'])\n",
        "## Valid data\n",
        "valid_Data_news = list(all_validate_data['clean_title'])\n",
        "valid_Data_labels = list(all_validate_data['6_way_label'])\n",
        "## Test data\n",
        "test_Data_news = list(all_test_public_data['clean_title'])\n",
        "test_Data_labels = list(all_test_public_data['6_way_label'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcHUEIqkSwYQ"
      },
      "source": [
        "**Preprocessing**\n",
        "\n",
        "Remove multiple spaces, punctuations and numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHKMf4ZmUwrS"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    # Remove punctuation\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    sen = sen.translate(translator)\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    sen = re.sub(r'\\s+', ' ', sen)\n",
        "\n",
        "    # Remove leading and trailing spaces\n",
        "    sen = sen.strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    sen = sen.lower()\n",
        "\n",
        "    return sen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMr8gZxWUwuK"
      },
      "outputs": [],
      "source": [
        "# Remove puntuations and numbers and multiple spaces\n",
        "\n",
        "clean_data_train_news = [preprocess_text(new) for new in train_Data_news]\n",
        "clean_data_valid_news = [preprocess_text(new) for new in valid_Data_news]\n",
        "clean_data_test_news = [preprocess_text(new) for new in test_Data_news]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm0gqYxqNqL"
      },
      "source": [
        "**Define a function to remove stop words and perform lemmatization.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Hu6r_fTFNL"
      },
      "source": [
        "use part-of-speech tagging to determine the part of speech of each word, which is used to determine the correct form of the word during lemmatization. \n",
        "A more efficient way to lemmatize the words would be to determine their part of speech using pos_tag, and then call the lemmatizer once with the correct part of speech.\n",
        "This version of the function uses the lemmatize() function of the WordNetLemmatizer class, which can work on words without specifying the part of speech. This version also removes the use of multiple round of lemmatization which is not needed. This method is simpler and faster than using part-of-speech tagging, but it may not be as accurate because it doesn't take the context of the word into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De6AJ3bdUwxB",
        "outputId": "f388e24e-8e12-4fe0-be71-5040cccd5db6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "# Initialize  lemmatizer and  stop_words\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def remove_stopwords_lem(text):\n",
        "    # Tokenize the text\n",
        "    text = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "\n",
        "    # Lemmatize the text\n",
        "    lemmatized_text = []\n",
        "    for word, treebank_pos in pos_tag(text):\n",
        "        if treebank_pos.startswith('J'):\n",
        "            wordnet_pos = wordnet.ADJ\n",
        "        elif treebank_pos.startswith('V'):\n",
        "            wordnet_pos = wordnet.VERB\n",
        "        elif treebank_pos.startswith('N'):\n",
        "            wordnet_pos = wordnet.NOUN\n",
        "        elif treebank_pos.startswith('R'):\n",
        "            wordnet_pos = wordnet.ADV\n",
        "        else:\n",
        "            wordnet_pos = wordnet.NOUN\n",
        "        lemmatized_text.append(lemmatizer.lemmatize(word, pos=wordnet_pos))\n",
        "\n",
        "    # Concatenate the lemmatized words into a single string\n",
        "    return ' '.join(lemmatized_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQnMVfLXXs0m"
      },
      "source": [
        "This will display a progress bar as the list comprehension runs, which can be helpful for tracking progress and estimating the time remaining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4NNsHPsLdJP",
        "outputId": "4ef56d03-2058-4907-8c09-2234bc82bb2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 802789/802789 [07:12<00:00, 1854.14it/s]\n",
            "100%|██████████| 84536/84536 [00:44<00:00, 1883.37it/s]\n",
            "100%|██████████| 84481/84481 [00:44<00:00, 1891.53it/s]\n"
          ]
        }
      ],
      "source": [
        "# Remove stop words and perform lemmatization\n",
        "from tqdm import tqdm\n",
        "train_stop_word_lemmatized = [remove_stopwords_lem(new) for new in tqdm(clean_data_train_news)]\n",
        "valid_stop_word_lematized = [remove_stopwords_lem(new) for new in tqdm(clean_data_valid_news)]\n",
        "test_stop_word_lemmtized = [remove_stopwords_lem(new) for new in tqdm(clean_data_test_news)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXgUolXMYpqC"
      },
      "source": [
        "Tokenize the news. In order to do this, loading the tokenizer which is included with BERT. Using the 'uncased' version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "43da489abec64024a6a584b32882ea38",
            "be4db30a0e564ca183eb555a42054e1c",
            "f24d7b29804443fbac587959db40f2e9",
            "bd7a9f3b943e41238e0de3f013d710ff",
            "130362262372456aafb417e85bb893f8",
            "665ae6e9a85a4fd4bf3be137681a84dc",
            "f5fa7ece707541bf92e1bf8a954d082c",
            "0ae68284a5ee410e99f178a40052a120",
            "7681b3beaad049f0828cc88f2c4268f1",
            "f3474f8b6c3e4dc1bf3cde9b3614a551",
            "26336371aea04664ab6949f4c77661ba",
            "a3081fb1362441d594f7cd79270aa2ca",
            "25093ecd994941bf96f98ef1c5a086a1",
            "240698cf4bd4430eb0fe4f2ab51d7ca5",
            "c9bea0b6cdfc42008d16c169c6572843",
            "8dd72db9caba40f39fa67e404f4b8a09",
            "3eb0da4497734b89a8c56010ae698115",
            "f616500124c143d8b3f0adef653af0fd",
            "d7e0a77f17404b84b1c10f39fef3432d",
            "d67a29c7f60541f89936a05a7b75c68a",
            "37d830e27ffe49178fba4b05700ba3a7",
            "477519260af94392ad4271df88ce3278",
            "3f8dd4b4c75346688c2f6eb61116f243",
            "1bb675d05a514fa2b279583716428edd",
            "ba761e8fec9449248471ea5f58ba1a73",
            "18fcb0d5ccf14045b3838d30de7fe018",
            "2cd889ffdb974d97836c27d1c55e7e90",
            "798a4c09282e4c4f8f2e2e2fda54cb1b",
            "3f6a7e95024b4de58256be670e05c697",
            "526ddd4299a347958ee758d0ce8db3d2",
            "cabf7b04eba844a6b7c971e798218580",
            "39aef75933cf487891e7b01dc4576689",
            "9a677501dcdd4c9f96a35b49128bcea8"
          ]
        },
        "id": "g3OnUXq_LdMX",
        "outputId": "69cf2242-f384-4097-dba1-7fa2514a3859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43da489abec64024a6a584b32882ea38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3081fb1362441d594f7cd79270aa2ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f8dd4b4c75346688c2f6eb61116f243",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZwIIcjvZiku"
      },
      "source": [
        "Define a function that will tokenize each sentence and map the tokens to their corresponding IDs in the tokenizer vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diUJSW34LdPg"
      },
      "outputs": [],
      "source": [
        "# Tokenize the sentence and add the '[CLS]' and '[SEP]' tokens.\n",
        "\n",
        "def bert_tokenize(text):\n",
        "\n",
        "    encoded_text = tokenizer.encode(\n",
        "                        text,                      \n",
        "                        add_special_tokens = True \n",
        "\n",
        "                       )\n",
        "    return encoded_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIDG1ji2gPo2"
      },
      "source": [
        "This will split the tokenization process across multiple cores, allowing you to tokenize multiple sentences in parallel.\n",
        "\n",
        "Performing the tokenization as a separate pre-processing step and save the tokenized data to disk so that you don't need to tokenize the text every time you work with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jPqmGel8djf1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
        "\n",
        "def tokenize_list(lst):\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        return list(executor.map(bert_tokenize, lst))\n",
        "train_tokenized = tokenize_list(train_stop_word_lemmatized )\n",
        "valid_tokenized = tokenize_list(valid_stop_word_lematized)\n",
        "test_tokenized = tokenize_list(test_stop_word_lemmtized)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "883O37f7jOHs"
      },
      "source": [
        "Tokenized each new and then pad the sequences so that all have the same length. The maximum length allowed by BERT is 512. In order to choose the appropiate length to pad the sequences, taking a look at what % of news have a length smaller than a given number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "08A_5AGdjSvT",
        "outputId": "0c8d9739-24f7-44e8-fe32-acfb84d6b1ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 92.53440194123237% of the tokenized news in the train partition has length smaller than 15\n",
            "The 92.4529194662629% of the tokenized news in the validation partition has length smaller than 15\n",
            "The 92.40539292858749% of the tokenized news in the test partition has length smaller than 15\n"
          ]
        }
      ],
      "source": [
        "lengths_train = np.array([len(new) for new in train_tokenized])\n",
        "lengths_valid = np.array([len(new) for new in valid_tokenized])\n",
        "lengths_test = np.array([len(new) for new in test_tokenized])                        \n",
        "\n",
        "length = 15\n",
        "\n",
        "for data_set, lengths in zip([\"train\", \"validation\", \"test\"],[lengths_train, lengths_valid, lengths_test]):\n",
        "    print(f\"The {(np.sum(lengths < length)/lengths.shape[0]) * 100}% of the tokenized news in the {data_set} partition has length smaller than {length}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ5ZcVQvBuGA"
      },
      "source": [
        "This will pad all the sequences to the same length, truncating any that are longer than the specified max length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c4Rrhu0_jSym"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 15\n",
        "\n",
        "# Train\n",
        "train_padded = pad_sequences(train_tokenized, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "# Validation\n",
        "valid_padded = pad_sequences(valid_tokenized, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "# Test\n",
        "test_padded = pad_sequences(test_tokenized, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENHkZ9myEmf5"
      },
      "source": [
        "This function takes in a tokenized sequence as an input and creates an attention mask for that sequence. It creates a mask with the same shape as the tokenized sequence, and sets all the values of the mask to 1 where the corresponding value in the tokenized sequence is not 0. This indicates that the corresponding token in the tokenized sequence is not a padding token. All the values in the mask that correspond to padding tokens in the tokenized sequence will be set to 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h7J_jnW-DQcR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to obtain the attention mask of each sequence\n",
        "\n",
        "def attention_mask(tokenized_sequence):\n",
        "    mask = (tokenized_sequence != 0).astype(int)\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJmKB0HbHg5-"
      },
      "source": [
        "This will take the padded sequences, which have already been tokenized and apply the attention mask function on them to create the attention mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gq_chsrXDQe3"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "train_attention_masks = attention_mask(train_padded)\n",
        "valid_attention_masks = attention_mask(valid_padded)\n",
        "test_attention_masks = attention_mask(test_padded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc3uNRI_JC_y"
      },
      "source": [
        "Using the numpy.concatenate() function to concatenate the padded sequences, masks, and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tdU1MxIXDQhx"
      },
      "outputs": [],
      "source": [
        "# Concatenate train and validation padded sequences\n",
        "train_valid_padded = np.concatenate([train_padded, valid_padded], axis = 0)\n",
        "# Concatenate train and validation attention masks\n",
        "train_valid_masks = np.concatenate([train_attention_masks, valid_attention_masks], axis = 0)\n",
        "# Concatenate train and validation labels\n",
        "train_valid_labels = np.concatenate([train_Data_labels, valid_Data_labels], axis = 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S862sJZMGcc"
      },
      "source": [
        "The torch.tensor() function allows you to convert numpy array to tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "65HCq0_ZDQkm"
      },
      "outputs": [],
      "source": [
        "# Convert inputs to torch tensor\n",
        "\n",
        "# Train\n",
        "train_inputs_tensor = torch.tensor(train_padded, dtype=torch.long)\n",
        "train_masks_tensor = torch.tensor(train_attention_masks, dtype=torch.long)\n",
        "train_labels_tensor = torch.tensor(train_Data_labels, dtype=torch.long)\n",
        "\n",
        "# Validation\n",
        "validation_inputs_tensor = torch.tensor(valid_padded, dtype=torch.long)\n",
        "validation_masks_tensor = torch.tensor(valid_attention_masks, dtype=torch.long)\n",
        "validation_labels_tensor = torch.tensor(valid_Data_labels, dtype=torch.long)\n",
        "\n",
        "# Train + Validation\n",
        "train_validation_inputs_tensor = torch.tensor(train_valid_padded, dtype=torch.long)\n",
        "train_validation_masks_tensor = torch.tensor(train_valid_masks, dtype=torch.long)\n",
        "train_validation_labels_tensor = torch.tensor(train_valid_labels, dtype=torch.long)\n",
        "\n",
        "# Test\n",
        "test_inputs_tensor = torch.tensor(test_padded, dtype=torch.long)\n",
        "test_masks_tensor = torch.tensor(test_attention_masks, dtype=torch.long)\n",
        "test_labels_tensor = torch.tensor(test_Data_labels, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7toCK9GfVvL"
      },
      "source": [
        "I used the shuffle=True argument when creating the DataLoader object. This way, the data will be shuffled during training automatically, and it makes the code less verbose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BXhnEqs0jS9R"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader objects\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 32\n",
        "\n",
        "# Train\n",
        "train_dataloader = DataLoader(TensorDataset(train_inputs_tensor, train_masks_tensor, train_labels_tensor), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Validation\n",
        "valid_dataloader = DataLoader(TensorDataset(validation_inputs_tensor, validation_masks_tensor, validation_labels_tensor), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train + Validation\n",
        "train_valid_dataloader = DataLoader(TensorDataset(train_validation_inputs_tensor, train_validation_masks_tensor, train_validation_labels_tensor), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Test\n",
        "test_dataloader = DataLoader(TensorDataset(test_inputs_tensor, test_masks_tensor, test_labels_tensor), batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2frU-rQfG5Ng"
      },
      "source": [
        "The torch.cuda.is_available() function is used to check if a CUDA-compatible GPU is available. If it returns True, we use the torch.device(\"cuda\") function to create a CUDA device, otherwise, it will use the CPU. Then we use .to() method on model to move the model to that device. This way, we can ensure that the code runs on the GPU if one is available, but it will still run on the CPU if a GPU is not available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "0bdc8fb9e8784c3ab6dc53729e9d292d"
          ]
        },
        "id": "Wihd-sIJFvZy",
        "outputId": "df8609c1-9605-4492-fe15-3d61681187a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bdc8fb9e8784c3ab6dc53729e9d292d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Defining the model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels=6,\n",
        "    output_attentions=False, \n",
        "    output_hidden_states=False\n",
        ")\n",
        "\n",
        "# Check for device availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Cf86xoGsWE"
      },
      "source": [
        "I've added a hyperparameter, weight_decay, to the optimizer. It is a regularization term that helps prevent overfitting by adding an additional term to the loss function which encourages the model to have smaller weights. The regularization strength is controlled by the weight_decay argument, which is a value between 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nSsxLi_iGugE"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr=2e-5, \n",
        "                  eps=1e-8,\n",
        "                  weight_decay=0.01\n",
        "                )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u8nFz-cIuRM"
      },
      "source": [
        "The get_linear_schedule_with_warmup function linearly increases the learning rate from 0 to the desired value over a certain number of steps defined by the user. The num_warmup_steps argument controls the number of steps over which the learning rate is increased. The learning rate scheduler is used to adjust the learning rate over time. A common technique is to linearly increase the learning rate over the course of the first few training steps, also called a warmup period.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H1psGLoMGuio"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs \n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps (batches * number of epochs).\n",
        "total_steps = len(train_valid_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler with a smaller warmup proportion \n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkHAOPc9JqmX"
      },
      "source": [
        "Define a function to obtain the accuracy\n",
        "the mean of the equality between preds and labels and returns the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cqlYUHQnGulg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1)\n",
        "    labels_flat = labels\n",
        "    return (pred_flat == labels_flat).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK-jw56rK17e"
      },
      "source": [
        "Function to obtain the elapsed times.\n",
        "\n",
        "use the strftime method to format the elapsed_rounded value into a string, which represents the elapsed time in the format of hours, minutes, and seconds. The gmtime function converts seconds to the time in format like (hours, minutes, seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J65E-vYtGuoI"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKxQnsh9OhOc"
      },
      "source": [
        "Tuning the optimal number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OsIfPbg-Guqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64be0dc8-06cc-4721-f6ed-3174ed65879f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:04\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:05\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:06\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:07\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:08\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.80\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:17\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:18\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:19\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:20\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:21\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:22\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:23\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:24\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:25\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:26\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:27\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:28\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:29\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:30\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:31\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:32\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:33\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:34\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:35\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:36\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:37\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:38\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:39\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:40\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:41\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:42\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:43\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:44\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:45\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:46\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:47\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:48\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:49\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:50\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:51\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:52\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:53\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:54\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:55\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:56\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:57\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:58\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:00:59\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:00\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:01\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:02\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:03\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:04\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:05\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:06\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:07\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:08\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:09\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:10\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:11\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:12\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:13\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:14\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:15\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "  Validation Accuracy: 0.79\n",
            "  Validation took: 00:01:16\n",
            "\n",
            "Training complete!\n",
            "Best Validation Accuracy: 0.79 at epoch 3\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Set seed for reproducibility.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Create an empty list to store the validation accuracy for each epoch\n",
        "valid_accuracies = []\n",
        "\n",
        "# Perform the training for the number of specified epochs\n",
        "for epoch_i in range(epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    \n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Initialize the variables used to track training time and loss\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    \n",
        "    # Perform a full pass over the training dataset\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # Unpack the training batch\n",
        "        batch_input_ids = batch[0].to(device)\n",
        "        batch_input_mask = batch[1].to(device)\n",
        "        batch_labels = batch[2].to(device)\n",
        "        \n",
        "        # Clear gradients\n",
        "        model.zero_grad()\n",
        "                # Forward pass\n",
        "        outputs = model(batch_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=batch_input_mask, \n",
        "                    labels=batch_labels)\n",
        "        \n",
        "        # Get loss value\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Store the loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate gradients (backward pass)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters \n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Average loss\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "     \n",
        "    # After each training epoch, obtain validation accuracy\n",
        "    accuracy_valid = 0\n",
        "    repetitions_valid = 0\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "      repetitions_valid += 1\n",
        "\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      # Unpack the inputs from our dataloader\n",
        "      batch_input_ids = batch[0]\n",
        "      batch_input_mask = batch[1]\n",
        "      batch_labels = batch[2]\n",
        "\n",
        "      with torch.no_grad():        \n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(batch_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=batch_input_mask)\n",
        "\n",
        "          # Get the logits\n",
        "          logits = outputs[0]\n",
        "\n",
        "          # Move logits and labels to CPU\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = batch_labels.to('cpu').numpy()\n",
        "          # Compute accuracy\n",
        "          accuracy_valid += flat_accuracy(logits, label_ids)\n",
        "\n",
        "          # Compute average validation accuracy\n",
        "          avg_valid_acc = accuracy_valid/repetitions_valid\n",
        "          valid_accuracies.append(avg_valid_acc)\n",
        "          print(\"  Validation Accuracy: {0:.2f}\".format(avg_valid_acc))\n",
        "          print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "# Select the best validation accuracy and the corresponding number of epochs\n",
        "best_acc = 0.0\n",
        "# Check if the current model is the best one.\n",
        "if avg_valid_acc > best_acc:\n",
        "  best_acc = avg_valid_acc\n",
        "  best_epoch = epoch_i + 1\n",
        "  best_model = model.state_dict()\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Best Validation Accuracy: {:.2f} at epoch {}\".format(best_acc, best_epoch))\n",
        "\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcVSF2p-2p4i"
      },
      "source": [
        "The following information shows the accuracy, obtaining for each number of epochs.\n",
        "\n",
        "Epochs \t    Accuracy\n",
        "\n",
        "1\t 0.77\n",
        "\n",
        "2\t 0.78\n",
        "\n",
        "3\t 0.79\n",
        "\n",
        "The model obtains the highest accuracy over the validation set when it is trained for 3 epochs therefore this is the number of epochs that I will use.\n",
        "\n",
        "\n",
        "Best Validation Accuracy: 0.79 at epoch 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSAFFNqHs3Pw"
      },
      "source": [
        "**Testing performance**\n",
        "\n",
        "In order to test the performance, training the model with the train and validation partitions and then evaluating it with the test set. Train the model for 3 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JYe6JOvTs2DA"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Select the number of epochs\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps (batches * number of epochs).\n",
        "total_steps = len(train_valid_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n",
        "# Early stopping: Stop training if the validation accuracy does not improve for a certain number of consecutive epochs.\n",
        "#add early stopping\n",
        "early_stop = EarlyStopping(patience=5, verbose=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SgRL0a3Is2GU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebcda38-b317-426c-91d2-ac8613bcd551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch 40  of  27729.    Elapsed: 00:00:05.\n",
            "  Batch 80  of  27729.    Elapsed: 00:00:10.\n",
            "  Batch 120  of  27729.    Elapsed: 00:00:15.\n",
            "  Batch 160  of  27729.    Elapsed: 00:00:20.\n",
            "  Batch 200  of  27729.    Elapsed: 00:00:25.\n",
            "  Batch 240  of  27729.    Elapsed: 00:00:30.\n",
            "  Batch 280  of  27729.    Elapsed: 00:00:35.\n",
            "  Batch 320  of  27729.    Elapsed: 00:00:40.\n",
            "  Batch 360  of  27729.    Elapsed: 00:00:45.\n",
            "  Batch 400  of  27729.    Elapsed: 00:00:50.\n",
            "  Batch 440  of  27729.    Elapsed: 00:00:55.\n",
            "  Batch 480  of  27729.    Elapsed: 00:01:00.\n",
            "  Batch 520  of  27729.    Elapsed: 00:01:05.\n",
            "  Batch 560  of  27729.    Elapsed: 00:01:10.\n",
            "  Batch 600  of  27729.    Elapsed: 00:01:15.\n",
            "  Batch 640  of  27729.    Elapsed: 00:01:20.\n",
            "  Batch 680  of  27729.    Elapsed: 00:01:25.\n",
            "  Batch 720  of  27729.    Elapsed: 00:01:30.\n",
            "  Batch 760  of  27729.    Elapsed: 00:01:35.\n",
            "  Batch 800  of  27729.    Elapsed: 00:01:40.\n",
            "  Batch 840  of  27729.    Elapsed: 00:01:45.\n",
            "  Batch 880  of  27729.    Elapsed: 00:01:50.\n",
            "  Batch 920  of  27729.    Elapsed: 00:01:55.\n",
            "  Batch 960  of  27729.    Elapsed: 00:02:00.\n",
            "  Batch 1000  of  27729.    Elapsed: 00:02:05.\n",
            "  Batch 1040  of  27729.    Elapsed: 00:02:10.\n",
            "  Batch 1080  of  27729.    Elapsed: 00:02:15.\n",
            "  Batch 1120  of  27729.    Elapsed: 00:02:20.\n",
            "  Batch 1160  of  27729.    Elapsed: 00:02:25.\n",
            "  Batch 1200  of  27729.    Elapsed: 00:02:30.\n",
            "  Batch 1240  of  27729.    Elapsed: 00:02:35.\n",
            "  Batch 1280  of  27729.    Elapsed: 00:02:40.\n",
            "  Batch 1320  of  27729.    Elapsed: 00:02:45.\n",
            "  Batch 1360  of  27729.    Elapsed: 00:02:50.\n",
            "  Batch 1400  of  27729.    Elapsed: 00:02:55.\n",
            "  Batch 1440  of  27729.    Elapsed: 00:03:00.\n",
            "  Batch 1480  of  27729.    Elapsed: 00:03:05.\n",
            "  Batch 1520  of  27729.    Elapsed: 00:03:10.\n",
            "  Batch 1560  of  27729.    Elapsed: 00:03:14.\n",
            "  Batch 1600  of  27729.    Elapsed: 00:03:19.\n",
            "  Batch 1640  of  27729.    Elapsed: 00:03:24.\n",
            "  Batch 1680  of  27729.    Elapsed: 00:03:29.\n",
            "  Batch 1720  of  27729.    Elapsed: 00:03:34.\n",
            "  Batch 1760  of  27729.    Elapsed: 00:03:39.\n",
            "  Batch 1800  of  27729.    Elapsed: 00:03:44.\n",
            "  Batch 1840  of  27729.    Elapsed: 00:03:49.\n",
            "  Batch 1880  of  27729.    Elapsed: 00:03:54.\n",
            "  Batch 1920  of  27729.    Elapsed: 00:03:59.\n",
            "  Batch 1960  of  27729.    Elapsed: 00:04:04.\n",
            "  Batch 2000  of  27729.    Elapsed: 00:04:09.\n",
            "  Batch 2040  of  27729.    Elapsed: 00:04:14.\n",
            "  Batch 2080  of  27729.    Elapsed: 00:04:19.\n",
            "  Batch 2120  of  27729.    Elapsed: 00:04:24.\n",
            "  Batch 2160  of  27729.    Elapsed: 00:04:29.\n",
            "  Batch 2200  of  27729.    Elapsed: 00:04:34.\n",
            "  Batch 2240  of  27729.    Elapsed: 00:04:39.\n",
            "  Batch 2280  of  27729.    Elapsed: 00:04:44.\n",
            "  Batch 2320  of  27729.    Elapsed: 00:04:49.\n",
            "  Batch 2360  of  27729.    Elapsed: 00:04:54.\n",
            "  Batch 2400  of  27729.    Elapsed: 00:04:59.\n",
            "  Batch 2440  of  27729.    Elapsed: 00:05:04.\n",
            "  Batch 2480  of  27729.    Elapsed: 00:05:09.\n",
            "  Batch 2520  of  27729.    Elapsed: 00:05:14.\n",
            "  Batch 2560  of  27729.    Elapsed: 00:05:19.\n",
            "  Batch 2600  of  27729.    Elapsed: 00:05:24.\n",
            "  Batch 2640  of  27729.    Elapsed: 00:05:29.\n",
            "  Batch 2680  of  27729.    Elapsed: 00:05:34.\n",
            "  Batch 2720  of  27729.    Elapsed: 00:05:39.\n",
            "  Batch 2760  of  27729.    Elapsed: 00:05:44.\n",
            "  Batch 2800  of  27729.    Elapsed: 00:05:49.\n",
            "  Batch 2840  of  27729.    Elapsed: 00:05:54.\n",
            "  Batch 2880  of  27729.    Elapsed: 00:05:59.\n",
            "  Batch 2920  of  27729.    Elapsed: 00:06:04.\n",
            "  Batch 2960  of  27729.    Elapsed: 00:06:09.\n",
            "  Batch 3000  of  27729.    Elapsed: 00:06:14.\n",
            "  Batch 3040  of  27729.    Elapsed: 00:06:19.\n",
            "  Batch 3080  of  27729.    Elapsed: 00:06:24.\n",
            "  Batch 3120  of  27729.    Elapsed: 00:06:29.\n",
            "  Batch 3160  of  27729.    Elapsed: 00:06:34.\n",
            "  Batch 3200  of  27729.    Elapsed: 00:06:39.\n",
            "  Batch 3240  of  27729.    Elapsed: 00:06:44.\n",
            "  Batch 3280  of  27729.    Elapsed: 00:06:49.\n",
            "  Batch 3320  of  27729.    Elapsed: 00:06:54.\n",
            "  Batch 3360  of  27729.    Elapsed: 00:06:59.\n",
            "  Batch 3400  of  27729.    Elapsed: 00:07:04.\n",
            "  Batch 3440  of  27729.    Elapsed: 00:07:09.\n",
            "  Batch 3480  of  27729.    Elapsed: 00:07:14.\n",
            "  Batch 3520  of  27729.    Elapsed: 00:07:19.\n",
            "  Batch 3560  of  27729.    Elapsed: 00:07:24.\n",
            "  Batch 3600  of  27729.    Elapsed: 00:07:29.\n",
            "  Batch 3640  of  27729.    Elapsed: 00:07:34.\n",
            "  Batch 3680  of  27729.    Elapsed: 00:07:39.\n",
            "  Batch 3720  of  27729.    Elapsed: 00:07:44.\n",
            "  Batch 3760  of  27729.    Elapsed: 00:07:49.\n",
            "  Batch 3800  of  27729.    Elapsed: 00:07:54.\n",
            "  Batch 3840  of  27729.    Elapsed: 00:07:59.\n",
            "  Batch 3880  of  27729.    Elapsed: 00:08:04.\n",
            "  Batch 3920  of  27729.    Elapsed: 00:08:09.\n",
            "  Batch 3960  of  27729.    Elapsed: 00:08:14.\n",
            "  Batch 4000  of  27729.    Elapsed: 00:08:19.\n",
            "  Batch 4040  of  27729.    Elapsed: 00:08:24.\n",
            "  Batch 4080  of  27729.    Elapsed: 00:08:29.\n",
            "  Batch 4120  of  27729.    Elapsed: 00:08:34.\n",
            "  Batch 4160  of  27729.    Elapsed: 00:08:39.\n",
            "  Batch 4200  of  27729.    Elapsed: 00:08:43.\n",
            "  Batch 4240  of  27729.    Elapsed: 00:08:48.\n",
            "  Batch 4280  of  27729.    Elapsed: 00:08:53.\n",
            "  Batch 4320  of  27729.    Elapsed: 00:08:58.\n",
            "  Batch 4360  of  27729.    Elapsed: 00:09:03.\n",
            "  Batch 4400  of  27729.    Elapsed: 00:09:08.\n",
            "  Batch 4440  of  27729.    Elapsed: 00:09:13.\n",
            "  Batch 4480  of  27729.    Elapsed: 00:09:18.\n",
            "  Batch 4520  of  27729.    Elapsed: 00:09:23.\n",
            "  Batch 4560  of  27729.    Elapsed: 00:09:28.\n",
            "  Batch 4600  of  27729.    Elapsed: 00:09:33.\n",
            "  Batch 4640  of  27729.    Elapsed: 00:09:38.\n",
            "  Batch 4680  of  27729.    Elapsed: 00:09:43.\n",
            "  Batch 4720  of  27729.    Elapsed: 00:09:48.\n",
            "  Batch 4760  of  27729.    Elapsed: 00:09:53.\n",
            "  Batch 4800  of  27729.    Elapsed: 00:09:58.\n",
            "  Batch 4840  of  27729.    Elapsed: 00:10:03.\n",
            "  Batch 4880  of  27729.    Elapsed: 00:10:08.\n",
            "  Batch 4920  of  27729.    Elapsed: 00:10:13.\n",
            "  Batch 4960  of  27729.    Elapsed: 00:10:18.\n",
            "  Batch 5000  of  27729.    Elapsed: 00:10:23.\n",
            "  Batch 5040  of  27729.    Elapsed: 00:10:28.\n",
            "  Batch 5080  of  27729.    Elapsed: 00:10:33.\n",
            "  Batch 5120  of  27729.    Elapsed: 00:10:38.\n",
            "  Batch 5160  of  27729.    Elapsed: 00:10:43.\n",
            "  Batch 5200  of  27729.    Elapsed: 00:10:48.\n",
            "  Batch 5240  of  27729.    Elapsed: 00:10:53.\n",
            "  Batch 5280  of  27729.    Elapsed: 00:10:58.\n",
            "  Batch 5320  of  27729.    Elapsed: 00:11:03.\n",
            "  Batch 5360  of  27729.    Elapsed: 00:11:08.\n",
            "  Batch 5400  of  27729.    Elapsed: 00:11:13.\n",
            "  Batch 5440  of  27729.    Elapsed: 00:11:18.\n",
            "  Batch 5480  of  27729.    Elapsed: 00:11:23.\n",
            "  Batch 5520  of  27729.    Elapsed: 00:11:28.\n",
            "  Batch 5560  of  27729.    Elapsed: 00:11:33.\n",
            "  Batch 5600  of  27729.    Elapsed: 00:11:38.\n",
            "  Batch 5640  of  27729.    Elapsed: 00:11:43.\n",
            "  Batch 5680  of  27729.    Elapsed: 00:11:48.\n",
            "  Batch 5720  of  27729.    Elapsed: 00:11:53.\n",
            "  Batch 5760  of  27729.    Elapsed: 00:11:58.\n",
            "  Batch 5800  of  27729.    Elapsed: 00:12:03.\n",
            "  Batch 5840  of  27729.    Elapsed: 00:12:08.\n",
            "  Batch 5880  of  27729.    Elapsed: 00:12:13.\n",
            "  Batch 5920  of  27729.    Elapsed: 00:12:18.\n",
            "  Batch 5960  of  27729.    Elapsed: 00:12:23.\n",
            "  Batch 6000  of  27729.    Elapsed: 00:12:28.\n",
            "  Batch 6040  of  27729.    Elapsed: 00:12:33.\n",
            "  Batch 6080  of  27729.    Elapsed: 00:12:38.\n",
            "  Batch 6120  of  27729.    Elapsed: 00:12:43.\n",
            "  Batch 6160  of  27729.    Elapsed: 00:12:48.\n",
            "  Batch 6200  of  27729.    Elapsed: 00:12:53.\n",
            "  Batch 6240  of  27729.    Elapsed: 00:12:58.\n",
            "  Batch 6280  of  27729.    Elapsed: 00:13:03.\n",
            "  Batch 6320  of  27729.    Elapsed: 00:13:08.\n",
            "  Batch 6360  of  27729.    Elapsed: 00:13:13.\n",
            "  Batch 6400  of  27729.    Elapsed: 00:13:18.\n",
            "  Batch 6440  of  27729.    Elapsed: 00:13:23.\n",
            "  Batch 6480  of  27729.    Elapsed: 00:13:28.\n",
            "  Batch 6520  of  27729.    Elapsed: 00:13:33.\n",
            "  Batch 6560  of  27729.    Elapsed: 00:13:38.\n",
            "  Batch 6600  of  27729.    Elapsed: 00:13:43.\n",
            "  Batch 6640  of  27729.    Elapsed: 00:13:48.\n",
            "  Batch 6680  of  27729.    Elapsed: 00:13:53.\n",
            "  Batch 6720  of  27729.    Elapsed: 00:13:58.\n",
            "  Batch 6760  of  27729.    Elapsed: 00:14:03.\n",
            "  Batch 6800  of  27729.    Elapsed: 00:14:08.\n",
            "  Batch 6840  of  27729.    Elapsed: 00:14:13.\n",
            "  Batch 6880  of  27729.    Elapsed: 00:14:18.\n",
            "  Batch 6920  of  27729.    Elapsed: 00:14:23.\n",
            "  Batch 6960  of  27729.    Elapsed: 00:14:28.\n",
            "  Batch 7000  of  27729.    Elapsed: 00:14:33.\n",
            "  Batch 7040  of  27729.    Elapsed: 00:14:38.\n",
            "  Batch 7080  of  27729.    Elapsed: 00:14:43.\n",
            "  Batch 7120  of  27729.    Elapsed: 00:14:47.\n",
            "  Batch 7160  of  27729.    Elapsed: 00:14:52.\n",
            "  Batch 7200  of  27729.    Elapsed: 00:14:58.\n",
            "  Batch 7240  of  27729.    Elapsed: 00:15:03.\n",
            "  Batch 7280  of  27729.    Elapsed: 00:15:08.\n",
            "  Batch 7320  of  27729.    Elapsed: 00:15:13.\n",
            "  Batch 7360  of  27729.    Elapsed: 00:15:18.\n",
            "  Batch 7400  of  27729.    Elapsed: 00:15:23.\n",
            "  Batch 7440  of  27729.    Elapsed: 00:15:28.\n",
            "  Batch 7480  of  27729.    Elapsed: 00:15:33.\n",
            "  Batch 7520  of  27729.    Elapsed: 00:15:38.\n",
            "  Batch 7560  of  27729.    Elapsed: 00:15:43.\n",
            "  Batch 7600  of  27729.    Elapsed: 00:15:48.\n",
            "  Batch 7640  of  27729.    Elapsed: 00:15:53.\n",
            "  Batch 7680  of  27729.    Elapsed: 00:15:58.\n",
            "  Batch 7720  of  27729.    Elapsed: 00:16:03.\n",
            "  Batch 7760  of  27729.    Elapsed: 00:16:08.\n",
            "  Batch 7800  of  27729.    Elapsed: 00:16:13.\n",
            "  Batch 7840  of  27729.    Elapsed: 00:16:18.\n",
            "  Batch 7880  of  27729.    Elapsed: 00:16:23.\n",
            "  Batch 7920  of  27729.    Elapsed: 00:16:28.\n",
            "  Batch 7960  of  27729.    Elapsed: 00:16:33.\n",
            "  Batch 8000  of  27729.    Elapsed: 00:16:38.\n",
            "  Batch 8040  of  27729.    Elapsed: 00:16:43.\n",
            "  Batch 8080  of  27729.    Elapsed: 00:16:48.\n",
            "  Batch 8120  of  27729.    Elapsed: 00:16:53.\n",
            "  Batch 8160  of  27729.    Elapsed: 00:16:58.\n",
            "  Batch 8200  of  27729.    Elapsed: 00:17:03.\n",
            "  Batch 8240  of  27729.    Elapsed: 00:17:08.\n",
            "  Batch 8280  of  27729.    Elapsed: 00:17:13.\n",
            "  Batch 8320  of  27729.    Elapsed: 00:17:18.\n",
            "  Batch 8360  of  27729.    Elapsed: 00:17:23.\n",
            "  Batch 8400  of  27729.    Elapsed: 00:17:28.\n",
            "  Batch 8440  of  27729.    Elapsed: 00:17:33.\n",
            "  Batch 8480  of  27729.    Elapsed: 00:17:38.\n",
            "  Batch 8520  of  27729.    Elapsed: 00:17:43.\n",
            "  Batch 8560  of  27729.    Elapsed: 00:17:48.\n",
            "  Batch 8600  of  27729.    Elapsed: 00:17:53.\n",
            "  Batch 8640  of  27729.    Elapsed: 00:17:58.\n",
            "  Batch 8680  of  27729.    Elapsed: 00:18:03.\n",
            "  Batch 8720  of  27729.    Elapsed: 00:18:08.\n",
            "  Batch 8760  of  27729.    Elapsed: 00:18:13.\n",
            "  Batch 8800  of  27729.    Elapsed: 00:18:18.\n",
            "  Batch 8840  of  27729.    Elapsed: 00:18:23.\n",
            "  Batch 8880  of  27729.    Elapsed: 00:18:28.\n",
            "  Batch 8920  of  27729.    Elapsed: 00:18:33.\n",
            "  Batch 8960  of  27729.    Elapsed: 00:18:38.\n",
            "  Batch 9000  of  27729.    Elapsed: 00:18:43.\n",
            "  Batch 9040  of  27729.    Elapsed: 00:18:48.\n",
            "  Batch 9080  of  27729.    Elapsed: 00:18:53.\n",
            "  Batch 9120  of  27729.    Elapsed: 00:18:58.\n",
            "  Batch 9160  of  27729.    Elapsed: 00:19:03.\n",
            "  Batch 9200  of  27729.    Elapsed: 00:19:08.\n",
            "  Batch 9240  of  27729.    Elapsed: 00:19:13.\n",
            "  Batch 9280  of  27729.    Elapsed: 00:19:18.\n",
            "  Batch 9320  of  27729.    Elapsed: 00:19:23.\n",
            "  Batch 9360  of  27729.    Elapsed: 00:19:28.\n",
            "  Batch 9400  of  27729.    Elapsed: 00:19:33.\n",
            "  Batch 9440  of  27729.    Elapsed: 00:19:38.\n",
            "  Batch 9480  of  27729.    Elapsed: 00:19:43.\n",
            "  Batch 9520  of  27729.    Elapsed: 00:19:48.\n",
            "  Batch 9560  of  27729.    Elapsed: 00:19:53.\n",
            "  Batch 9600  of  27729.    Elapsed: 00:19:58.\n",
            "  Batch 9640  of  27729.    Elapsed: 00:20:02.\n",
            "  Batch 9680  of  27729.    Elapsed: 00:20:07.\n",
            "  Batch 9720  of  27729.    Elapsed: 00:20:12.\n",
            "  Batch 9760  of  27729.    Elapsed: 00:20:17.\n",
            "  Batch 9800  of  27729.    Elapsed: 00:20:22.\n",
            "  Batch 9840  of  27729.    Elapsed: 00:20:27.\n",
            "  Batch 9880  of  27729.    Elapsed: 00:20:32.\n",
            "  Batch 9920  of  27729.    Elapsed: 00:20:37.\n",
            "  Batch 9960  of  27729.    Elapsed: 00:20:42.\n",
            "  Batch 10000  of  27729.    Elapsed: 00:20:47.\n",
            "  Batch 10040  of  27729.    Elapsed: 00:20:52.\n",
            "  Batch 10080  of  27729.    Elapsed: 00:20:57.\n",
            "  Batch 10120  of  27729.    Elapsed: 00:21:02.\n",
            "  Batch 10160  of  27729.    Elapsed: 00:21:07.\n",
            "  Batch 10200  of  27729.    Elapsed: 00:21:12.\n",
            "  Batch 10240  of  27729.    Elapsed: 00:21:17.\n",
            "  Batch 10280  of  27729.    Elapsed: 00:21:22.\n",
            "  Batch 10320  of  27729.    Elapsed: 00:21:27.\n",
            "  Batch 10360  of  27729.    Elapsed: 00:21:32.\n",
            "  Batch 10400  of  27729.    Elapsed: 00:21:37.\n",
            "  Batch 10440  of  27729.    Elapsed: 00:21:42.\n",
            "  Batch 10480  of  27729.    Elapsed: 00:21:47.\n",
            "  Batch 10520  of  27729.    Elapsed: 00:21:52.\n",
            "  Batch 10560  of  27729.    Elapsed: 00:21:57.\n",
            "  Batch 10600  of  27729.    Elapsed: 00:22:02.\n",
            "  Batch 10640  of  27729.    Elapsed: 00:22:07.\n",
            "  Batch 10680  of  27729.    Elapsed: 00:22:12.\n",
            "  Batch 10720  of  27729.    Elapsed: 00:22:17.\n",
            "  Batch 10760  of  27729.    Elapsed: 00:22:22.\n",
            "  Batch 10800  of  27729.    Elapsed: 00:22:27.\n",
            "  Batch 10840  of  27729.    Elapsed: 00:22:32.\n",
            "  Batch 10880  of  27729.    Elapsed: 00:22:37.\n",
            "  Batch 10920  of  27729.    Elapsed: 00:22:42.\n",
            "  Batch 10960  of  27729.    Elapsed: 00:22:47.\n",
            "  Batch 11000  of  27729.    Elapsed: 00:22:52.\n",
            "  Batch 11040  of  27729.    Elapsed: 00:22:57.\n",
            "  Batch 11080  of  27729.    Elapsed: 00:23:02.\n",
            "  Batch 11120  of  27729.    Elapsed: 00:23:07.\n",
            "  Batch 11160  of  27729.    Elapsed: 00:23:12.\n",
            "  Batch 11200  of  27729.    Elapsed: 00:23:17.\n",
            "  Batch 11240  of  27729.    Elapsed: 00:23:22.\n",
            "  Batch 11280  of  27729.    Elapsed: 00:23:27.\n",
            "  Batch 11320  of  27729.    Elapsed: 00:23:32.\n",
            "  Batch 11360  of  27729.    Elapsed: 00:23:37.\n",
            "  Batch 11400  of  27729.    Elapsed: 00:23:42.\n",
            "  Batch 11440  of  27729.    Elapsed: 00:23:47.\n",
            "  Batch 11480  of  27729.    Elapsed: 00:23:52.\n",
            "  Batch 11520  of  27729.    Elapsed: 00:23:57.\n",
            "  Batch 11560  of  27729.    Elapsed: 00:24:02.\n",
            "  Batch 11600  of  27729.    Elapsed: 00:24:07.\n",
            "  Batch 11640  of  27729.    Elapsed: 00:24:12.\n",
            "  Batch 11680  of  27729.    Elapsed: 00:24:17.\n",
            "  Batch 11720  of  27729.    Elapsed: 00:24:22.\n",
            "  Batch 11760  of  27729.    Elapsed: 00:24:27.\n",
            "  Batch 11800  of  27729.    Elapsed: 00:24:32.\n",
            "  Batch 11840  of  27729.    Elapsed: 00:24:37.\n",
            "  Batch 11880  of  27729.    Elapsed: 00:24:42.\n",
            "  Batch 11920  of  27729.    Elapsed: 00:24:47.\n",
            "  Batch 11960  of  27729.    Elapsed: 00:24:52.\n",
            "  Batch 12000  of  27729.    Elapsed: 00:24:57.\n",
            "  Batch 12040  of  27729.    Elapsed: 00:25:02.\n",
            "  Batch 12080  of  27729.    Elapsed: 00:25:07.\n",
            "  Batch 12120  of  27729.    Elapsed: 00:25:12.\n",
            "  Batch 12160  of  27729.    Elapsed: 00:25:17.\n",
            "  Batch 12200  of  27729.    Elapsed: 00:25:22.\n",
            "  Batch 12240  of  27729.    Elapsed: 00:25:27.\n",
            "  Batch 12280  of  27729.    Elapsed: 00:25:32.\n",
            "  Batch 12320  of  27729.    Elapsed: 00:25:37.\n",
            "  Batch 12360  of  27729.    Elapsed: 00:25:42.\n",
            "  Batch 12400  of  27729.    Elapsed: 00:25:47.\n",
            "  Batch 12440  of  27729.    Elapsed: 00:25:52.\n",
            "  Batch 12480  of  27729.    Elapsed: 00:25:57.\n",
            "  Batch 12520  of  27729.    Elapsed: 00:26:02.\n",
            "  Batch 12560  of  27729.    Elapsed: 00:26:07.\n",
            "  Batch 12600  of  27729.    Elapsed: 00:26:12.\n",
            "  Batch 12640  of  27729.    Elapsed: 00:26:17.\n",
            "  Batch 12680  of  27729.    Elapsed: 00:26:22.\n",
            "  Batch 12720  of  27729.    Elapsed: 00:26:27.\n",
            "  Batch 12760  of  27729.    Elapsed: 00:26:31.\n",
            "  Batch 12800  of  27729.    Elapsed: 00:26:36.\n",
            "  Batch 12840  of  27729.    Elapsed: 00:26:41.\n",
            "  Batch 12880  of  27729.    Elapsed: 00:26:46.\n",
            "  Batch 12920  of  27729.    Elapsed: 00:26:51.\n",
            "  Batch 12960  of  27729.    Elapsed: 00:26:56.\n",
            "  Batch 13000  of  27729.    Elapsed: 00:27:01.\n",
            "  Batch 13040  of  27729.    Elapsed: 00:27:06.\n",
            "  Batch 13080  of  27729.    Elapsed: 00:27:11.\n",
            "  Batch 13120  of  27729.    Elapsed: 00:27:16.\n",
            "  Batch 13160  of  27729.    Elapsed: 00:27:21.\n",
            "  Batch 13200  of  27729.    Elapsed: 00:27:26.\n",
            "  Batch 13240  of  27729.    Elapsed: 00:27:31.\n",
            "  Batch 13280  of  27729.    Elapsed: 00:27:36.\n",
            "  Batch 13320  of  27729.    Elapsed: 00:27:41.\n",
            "  Batch 13360  of  27729.    Elapsed: 00:27:46.\n",
            "  Batch 13400  of  27729.    Elapsed: 00:27:51.\n",
            "  Batch 13440  of  27729.    Elapsed: 00:27:56.\n",
            "  Batch 13480  of  27729.    Elapsed: 00:28:01.\n",
            "  Batch 13520  of  27729.    Elapsed: 00:28:06.\n",
            "  Batch 13560  of  27729.    Elapsed: 00:28:11.\n",
            "  Batch 13600  of  27729.    Elapsed: 00:28:16.\n",
            "  Batch 13640  of  27729.    Elapsed: 00:28:21.\n",
            "  Batch 13680  of  27729.    Elapsed: 00:28:26.\n",
            "  Batch 13720  of  27729.    Elapsed: 00:28:31.\n",
            "  Batch 13760  of  27729.    Elapsed: 00:28:36.\n",
            "  Batch 13800  of  27729.    Elapsed: 00:28:41.\n",
            "  Batch 13840  of  27729.    Elapsed: 00:28:46.\n",
            "  Batch 13880  of  27729.    Elapsed: 00:28:51.\n",
            "  Batch 13920  of  27729.    Elapsed: 00:28:56.\n",
            "  Batch 13960  of  27729.    Elapsed: 00:29:01.\n",
            "  Batch 14000  of  27729.    Elapsed: 00:29:06.\n",
            "  Batch 14040  of  27729.    Elapsed: 00:29:11.\n",
            "  Batch 14080  of  27729.    Elapsed: 00:29:16.\n",
            "  Batch 14120  of  27729.    Elapsed: 00:29:21.\n",
            "  Batch 14160  of  27729.    Elapsed: 00:29:26.\n",
            "  Batch 14200  of  27729.    Elapsed: 00:29:31.\n",
            "  Batch 14240  of  27729.    Elapsed: 00:29:36.\n",
            "  Batch 14280  of  27729.    Elapsed: 00:29:41.\n",
            "  Batch 14320  of  27729.    Elapsed: 00:29:46.\n",
            "  Batch 14360  of  27729.    Elapsed: 00:29:51.\n",
            "  Batch 14400  of  27729.    Elapsed: 00:29:56.\n",
            "  Batch 14440  of  27729.    Elapsed: 00:30:01.\n",
            "  Batch 14480  of  27729.    Elapsed: 00:30:06.\n",
            "  Batch 14520  of  27729.    Elapsed: 00:30:11.\n",
            "  Batch 14560  of  27729.    Elapsed: 00:30:16.\n",
            "  Batch 14600  of  27729.    Elapsed: 00:30:21.\n",
            "  Batch 14640  of  27729.    Elapsed: 00:30:26.\n",
            "  Batch 14680  of  27729.    Elapsed: 00:30:31.\n",
            "  Batch 14720  of  27729.    Elapsed: 00:30:36.\n",
            "  Batch 14760  of  27729.    Elapsed: 00:30:41.\n",
            "  Batch 14800  of  27729.    Elapsed: 00:30:46.\n",
            "  Batch 14840  of  27729.    Elapsed: 00:30:51.\n",
            "  Batch 14880  of  27729.    Elapsed: 00:30:56.\n",
            "  Batch 14920  of  27729.    Elapsed: 00:31:01.\n",
            "  Batch 14960  of  27729.    Elapsed: 00:31:06.\n",
            "  Batch 15000  of  27729.    Elapsed: 00:31:11.\n",
            "  Batch 15040  of  27729.    Elapsed: 00:31:16.\n",
            "  Batch 15080  of  27729.    Elapsed: 00:31:21.\n",
            "  Batch 15120  of  27729.    Elapsed: 00:31:26.\n",
            "  Batch 15160  of  27729.    Elapsed: 00:31:31.\n",
            "  Batch 15200  of  27729.    Elapsed: 00:31:36.\n",
            "  Batch 15240  of  27729.    Elapsed: 00:31:41.\n",
            "  Batch 15280  of  27729.    Elapsed: 00:31:46.\n",
            "  Batch 15320  of  27729.    Elapsed: 00:31:51.\n",
            "  Batch 15360  of  27729.    Elapsed: 00:31:56.\n",
            "  Batch 15400  of  27729.    Elapsed: 00:32:01.\n",
            "  Batch 15440  of  27729.    Elapsed: 00:32:06.\n",
            "  Batch 15480  of  27729.    Elapsed: 00:32:11.\n",
            "  Batch 15520  of  27729.    Elapsed: 00:32:16.\n",
            "  Batch 15560  of  27729.    Elapsed: 00:32:21.\n",
            "  Batch 15600  of  27729.    Elapsed: 00:32:26.\n",
            "  Batch 15640  of  27729.    Elapsed: 00:32:31.\n",
            "  Batch 15680  of  27729.    Elapsed: 00:32:36.\n",
            "  Batch 15720  of  27729.    Elapsed: 00:32:41.\n",
            "  Batch 15760  of  27729.    Elapsed: 00:32:46.\n",
            "  Batch 15800  of  27729.    Elapsed: 00:32:51.\n",
            "  Batch 15840  of  27729.    Elapsed: 00:32:56.\n",
            "  Batch 15880  of  27729.    Elapsed: 00:33:01.\n",
            "  Batch 15920  of  27729.    Elapsed: 00:33:06.\n",
            "  Batch 15960  of  27729.    Elapsed: 00:33:11.\n",
            "  Batch 16000  of  27729.    Elapsed: 00:33:15.\n",
            "  Batch 16040  of  27729.    Elapsed: 00:33:20.\n",
            "  Batch 16080  of  27729.    Elapsed: 00:33:25.\n",
            "  Batch 16120  of  27729.    Elapsed: 00:33:30.\n",
            "  Batch 16160  of  27729.    Elapsed: 00:33:35.\n",
            "  Batch 16200  of  27729.    Elapsed: 00:33:40.\n",
            "  Batch 16240  of  27729.    Elapsed: 00:33:45.\n",
            "  Batch 16280  of  27729.    Elapsed: 00:33:50.\n",
            "  Batch 16320  of  27729.    Elapsed: 00:33:55.\n",
            "  Batch 16360  of  27729.    Elapsed: 00:34:00.\n",
            "  Batch 16400  of  27729.    Elapsed: 00:34:05.\n",
            "  Batch 16440  of  27729.    Elapsed: 00:34:10.\n",
            "  Batch 16480  of  27729.    Elapsed: 00:34:15.\n",
            "  Batch 16520  of  27729.    Elapsed: 00:34:20.\n",
            "  Batch 16560  of  27729.    Elapsed: 00:34:25.\n",
            "  Batch 16600  of  27729.    Elapsed: 00:34:30.\n",
            "  Batch 16640  of  27729.    Elapsed: 00:34:35.\n",
            "  Batch 16680  of  27729.    Elapsed: 00:34:40.\n",
            "  Batch 16720  of  27729.    Elapsed: 00:34:45.\n",
            "  Batch 16760  of  27729.    Elapsed: 00:34:50.\n",
            "  Batch 16800  of  27729.    Elapsed: 00:34:55.\n",
            "  Batch 16840  of  27729.    Elapsed: 00:35:00.\n",
            "  Batch 16880  of  27729.    Elapsed: 00:35:05.\n",
            "  Batch 16920  of  27729.    Elapsed: 00:35:10.\n",
            "  Batch 16960  of  27729.    Elapsed: 00:35:15.\n",
            "  Batch 17000  of  27729.    Elapsed: 00:35:20.\n",
            "  Batch 17040  of  27729.    Elapsed: 00:35:25.\n",
            "  Batch 17080  of  27729.    Elapsed: 00:35:30.\n",
            "  Batch 17120  of  27729.    Elapsed: 00:35:35.\n",
            "  Batch 17160  of  27729.    Elapsed: 00:35:40.\n",
            "  Batch 17200  of  27729.    Elapsed: 00:35:45.\n",
            "  Batch 17240  of  27729.    Elapsed: 00:35:50.\n",
            "  Batch 17280  of  27729.    Elapsed: 00:35:55.\n",
            "  Batch 17320  of  27729.    Elapsed: 00:36:00.\n",
            "  Batch 17360  of  27729.    Elapsed: 00:36:05.\n",
            "  Batch 17400  of  27729.    Elapsed: 00:36:10.\n",
            "  Batch 17440  of  27729.    Elapsed: 00:36:15.\n",
            "  Batch 17480  of  27729.    Elapsed: 00:36:20.\n",
            "  Batch 17520  of  27729.    Elapsed: 00:36:25.\n",
            "  Batch 17560  of  27729.    Elapsed: 00:36:30.\n",
            "  Batch 17600  of  27729.    Elapsed: 00:36:35.\n",
            "  Batch 17640  of  27729.    Elapsed: 00:36:40.\n",
            "  Batch 17680  of  27729.    Elapsed: 00:36:45.\n",
            "  Batch 17720  of  27729.    Elapsed: 00:36:50.\n",
            "  Batch 17760  of  27729.    Elapsed: 00:36:55.\n",
            "  Batch 17800  of  27729.    Elapsed: 00:37:00.\n",
            "  Batch 17840  of  27729.    Elapsed: 00:37:05.\n",
            "  Batch 17880  of  27729.    Elapsed: 00:37:10.\n",
            "  Batch 17920  of  27729.    Elapsed: 00:37:15.\n",
            "  Batch 17960  of  27729.    Elapsed: 00:37:20.\n",
            "  Batch 18000  of  27729.    Elapsed: 00:37:25.\n",
            "  Batch 18040  of  27729.    Elapsed: 00:37:30.\n",
            "  Batch 18080  of  27729.    Elapsed: 00:37:35.\n",
            "  Batch 18120  of  27729.    Elapsed: 00:37:40.\n",
            "  Batch 18160  of  27729.    Elapsed: 00:37:45.\n",
            "  Batch 18200  of  27729.    Elapsed: 00:37:50.\n",
            "  Batch 18240  of  27729.    Elapsed: 00:37:55.\n",
            "  Batch 18280  of  27729.    Elapsed: 00:38:00.\n",
            "  Batch 18320  of  27729.    Elapsed: 00:38:05.\n",
            "  Batch 18360  of  27729.    Elapsed: 00:38:10.\n",
            "  Batch 18400  of  27729.    Elapsed: 00:38:15.\n",
            "  Batch 18440  of  27729.    Elapsed: 00:38:20.\n",
            "  Batch 18480  of  27729.    Elapsed: 00:38:25.\n",
            "  Batch 18520  of  27729.    Elapsed: 00:38:30.\n",
            "  Batch 18560  of  27729.    Elapsed: 00:38:35.\n",
            "  Batch 18600  of  27729.    Elapsed: 00:38:40.\n",
            "  Batch 18640  of  27729.    Elapsed: 00:38:45.\n",
            "  Batch 18680  of  27729.    Elapsed: 00:38:50.\n",
            "  Batch 18720  of  27729.    Elapsed: 00:38:55.\n",
            "  Batch 18760  of  27729.    Elapsed: 00:39:00.\n",
            "  Batch 18800  of  27729.    Elapsed: 00:39:05.\n",
            "  Batch 18840  of  27729.    Elapsed: 00:39:10.\n",
            "  Batch 18880  of  27729.    Elapsed: 00:39:15.\n",
            "  Batch 18920  of  27729.    Elapsed: 00:39:19.\n",
            "  Batch 18960  of  27729.    Elapsed: 00:39:24.\n",
            "  Batch 19000  of  27729.    Elapsed: 00:39:29.\n",
            "  Batch 19040  of  27729.    Elapsed: 00:39:34.\n",
            "  Batch 19080  of  27729.    Elapsed: 00:39:39.\n",
            "  Batch 19120  of  27729.    Elapsed: 00:39:44.\n",
            "  Batch 19160  of  27729.    Elapsed: 00:39:49.\n",
            "  Batch 19200  of  27729.    Elapsed: 00:39:54.\n",
            "  Batch 19240  of  27729.    Elapsed: 00:39:59.\n",
            "  Batch 19280  of  27729.    Elapsed: 00:40:04.\n",
            "  Batch 19320  of  27729.    Elapsed: 00:40:09.\n",
            "  Batch 19360  of  27729.    Elapsed: 00:40:14.\n",
            "  Batch 19400  of  27729.    Elapsed: 00:40:19.\n",
            "  Batch 19440  of  27729.    Elapsed: 00:40:24.\n",
            "  Batch 19480  of  27729.    Elapsed: 00:40:29.\n",
            "  Batch 19520  of  27729.    Elapsed: 00:40:34.\n",
            "  Batch 19560  of  27729.    Elapsed: 00:40:39.\n",
            "  Batch 19600  of  27729.    Elapsed: 00:40:44.\n",
            "  Batch 19640  of  27729.    Elapsed: 00:40:49.\n",
            "  Batch 19680  of  27729.    Elapsed: 00:40:54.\n",
            "  Batch 19720  of  27729.    Elapsed: 00:40:59.\n",
            "  Batch 19760  of  27729.    Elapsed: 00:41:04.\n",
            "  Batch 19800  of  27729.    Elapsed: 00:41:09.\n",
            "  Batch 19840  of  27729.    Elapsed: 00:41:14.\n",
            "  Batch 19880  of  27729.    Elapsed: 00:41:19.\n",
            "  Batch 19920  of  27729.    Elapsed: 00:41:24.\n",
            "  Batch 19960  of  27729.    Elapsed: 00:41:29.\n",
            "  Batch 20000  of  27729.    Elapsed: 00:41:34.\n",
            "  Batch 20040  of  27729.    Elapsed: 00:41:39.\n",
            "  Batch 20080  of  27729.    Elapsed: 00:41:44.\n",
            "  Batch 20120  of  27729.    Elapsed: 00:41:49.\n",
            "  Batch 20160  of  27729.    Elapsed: 00:41:54.\n",
            "  Batch 20200  of  27729.    Elapsed: 00:41:59.\n",
            "  Batch 20240  of  27729.    Elapsed: 00:42:04.\n",
            "  Batch 20280  of  27729.    Elapsed: 00:42:09.\n",
            "  Batch 20320  of  27729.    Elapsed: 00:42:14.\n",
            "  Batch 20360  of  27729.    Elapsed: 00:42:19.\n",
            "  Batch 20400  of  27729.    Elapsed: 00:42:24.\n",
            "  Batch 20440  of  27729.    Elapsed: 00:42:29.\n",
            "  Batch 20480  of  27729.    Elapsed: 00:42:34.\n",
            "  Batch 20520  of  27729.    Elapsed: 00:42:39.\n",
            "  Batch 20560  of  27729.    Elapsed: 00:42:44.\n",
            "  Batch 20600  of  27729.    Elapsed: 00:42:49.\n",
            "  Batch 20640  of  27729.    Elapsed: 00:42:54.\n",
            "  Batch 20680  of  27729.    Elapsed: 00:42:59.\n",
            "  Batch 20720  of  27729.    Elapsed: 00:43:04.\n",
            "  Batch 20760  of  27729.    Elapsed: 00:43:09.\n",
            "  Batch 20800  of  27729.    Elapsed: 00:43:14.\n",
            "  Batch 20840  of  27729.    Elapsed: 00:43:19.\n",
            "  Batch 20880  of  27729.    Elapsed: 00:43:24.\n",
            "  Batch 20920  of  27729.    Elapsed: 00:43:29.\n",
            "  Batch 20960  of  27729.    Elapsed: 00:43:34.\n",
            "  Batch 21000  of  27729.    Elapsed: 00:43:39.\n",
            "  Batch 21040  of  27729.    Elapsed: 00:43:44.\n",
            "  Batch 21080  of  27729.    Elapsed: 00:43:49.\n",
            "  Batch 21120  of  27729.    Elapsed: 00:43:54.\n",
            "  Batch 21160  of  27729.    Elapsed: 00:43:59.\n",
            "  Batch 21200  of  27729.    Elapsed: 00:44:04.\n",
            "  Batch 21240  of  27729.    Elapsed: 00:44:09.\n",
            "  Batch 21280  of  27729.    Elapsed: 00:44:14.\n",
            "  Batch 21320  of  27729.    Elapsed: 00:44:19.\n",
            "  Batch 21360  of  27729.    Elapsed: 00:44:24.\n",
            "  Batch 21400  of  27729.    Elapsed: 00:44:29.\n",
            "  Batch 21440  of  27729.    Elapsed: 00:44:34.\n",
            "  Batch 21480  of  27729.    Elapsed: 00:44:39.\n",
            "  Batch 21520  of  27729.    Elapsed: 00:44:44.\n",
            "  Batch 21560  of  27729.    Elapsed: 00:44:49.\n",
            "  Batch 21600  of  27729.    Elapsed: 00:44:54.\n",
            "  Batch 21640  of  27729.    Elapsed: 00:44:59.\n",
            "  Batch 21680  of  27729.    Elapsed: 00:45:04.\n",
            "  Batch 21720  of  27729.    Elapsed: 00:45:09.\n",
            "  Batch 21760  of  27729.    Elapsed: 00:45:14.\n",
            "  Batch 21800  of  27729.    Elapsed: 00:45:19.\n",
            "  Batch 21840  of  27729.    Elapsed: 00:45:24.\n",
            "  Batch 21880  of  27729.    Elapsed: 00:45:29.\n",
            "  Batch 21920  of  27729.    Elapsed: 00:45:34.\n",
            "  Batch 21960  of  27729.    Elapsed: 00:45:39.\n",
            "  Batch 22000  of  27729.    Elapsed: 00:45:44.\n",
            "  Batch 22040  of  27729.    Elapsed: 00:45:48.\n",
            "  Batch 22080  of  27729.    Elapsed: 00:45:53.\n",
            "  Batch 22120  of  27729.    Elapsed: 00:45:58.\n",
            "  Batch 22160  of  27729.    Elapsed: 00:46:03.\n",
            "  Batch 22200  of  27729.    Elapsed: 00:46:08.\n",
            "  Batch 22240  of  27729.    Elapsed: 00:46:13.\n",
            "  Batch 22280  of  27729.    Elapsed: 00:46:18.\n",
            "  Batch 22320  of  27729.    Elapsed: 00:46:23.\n",
            "  Batch 22360  of  27729.    Elapsed: 00:46:28.\n",
            "  Batch 22400  of  27729.    Elapsed: 00:46:33.\n",
            "  Batch 22440  of  27729.    Elapsed: 00:46:38.\n",
            "  Batch 22480  of  27729.    Elapsed: 00:46:43.\n",
            "  Batch 22520  of  27729.    Elapsed: 00:46:48.\n",
            "  Batch 22560  of  27729.    Elapsed: 00:46:53.\n",
            "  Batch 22600  of  27729.    Elapsed: 00:46:58.\n",
            "  Batch 22640  of  27729.    Elapsed: 00:47:03.\n",
            "  Batch 22680  of  27729.    Elapsed: 00:47:08.\n",
            "  Batch 22720  of  27729.    Elapsed: 00:47:13.\n",
            "  Batch 22760  of  27729.    Elapsed: 00:47:18.\n",
            "  Batch 22800  of  27729.    Elapsed: 00:47:23.\n",
            "  Batch 22840  of  27729.    Elapsed: 00:47:28.\n",
            "  Batch 22880  of  27729.    Elapsed: 00:47:33.\n",
            "  Batch 22920  of  27729.    Elapsed: 00:47:38.\n",
            "  Batch 22960  of  27729.    Elapsed: 00:47:43.\n",
            "  Batch 23000  of  27729.    Elapsed: 00:47:48.\n",
            "  Batch 23040  of  27729.    Elapsed: 00:47:53.\n",
            "  Batch 23080  of  27729.    Elapsed: 00:47:58.\n",
            "  Batch 23120  of  27729.    Elapsed: 00:48:03.\n",
            "  Batch 23160  of  27729.    Elapsed: 00:48:08.\n",
            "  Batch 23200  of  27729.    Elapsed: 00:48:13.\n",
            "  Batch 23240  of  27729.    Elapsed: 00:48:18.\n",
            "  Batch 23280  of  27729.    Elapsed: 00:48:23.\n",
            "  Batch 23320  of  27729.    Elapsed: 00:48:28.\n",
            "  Batch 23360  of  27729.    Elapsed: 00:48:33.\n",
            "  Batch 23400  of  27729.    Elapsed: 00:48:38.\n",
            "  Batch 23440  of  27729.    Elapsed: 00:48:43.\n",
            "  Batch 23480  of  27729.    Elapsed: 00:48:48.\n",
            "  Batch 23520  of  27729.    Elapsed: 00:48:53.\n",
            "  Batch 23560  of  27729.    Elapsed: 00:48:58.\n",
            "  Batch 23600  of  27729.    Elapsed: 00:49:03.\n",
            "  Batch 23640  of  27729.    Elapsed: 00:49:08.\n",
            "  Batch 23680  of  27729.    Elapsed: 00:49:13.\n",
            "  Batch 23720  of  27729.    Elapsed: 00:49:18.\n",
            "  Batch 23760  of  27729.    Elapsed: 00:49:23.\n",
            "  Batch 23800  of  27729.    Elapsed: 00:49:28.\n",
            "  Batch 23840  of  27729.    Elapsed: 00:49:33.\n",
            "  Batch 23880  of  27729.    Elapsed: 00:49:38.\n",
            "  Batch 23920  of  27729.    Elapsed: 00:49:43.\n",
            "  Batch 23960  of  27729.    Elapsed: 00:49:48.\n",
            "  Batch 24000  of  27729.    Elapsed: 00:49:53.\n",
            "  Batch 24040  of  27729.    Elapsed: 00:49:58.\n",
            "  Batch 24080  of  27729.    Elapsed: 00:50:03.\n",
            "  Batch 24120  of  27729.    Elapsed: 00:50:08.\n",
            "  Batch 24160  of  27729.    Elapsed: 00:50:13.\n",
            "  Batch 24200  of  27729.    Elapsed: 00:50:18.\n",
            "  Batch 24240  of  27729.    Elapsed: 00:50:23.\n",
            "  Batch 24280  of  27729.    Elapsed: 00:50:28.\n",
            "  Batch 24320  of  27729.    Elapsed: 00:50:33.\n",
            "  Batch 24360  of  27729.    Elapsed: 00:50:38.\n",
            "  Batch 24400  of  27729.    Elapsed: 00:50:43.\n",
            "  Batch 24440  of  27729.    Elapsed: 00:50:48.\n",
            "  Batch 24480  of  27729.    Elapsed: 00:50:53.\n",
            "  Batch 24520  of  27729.    Elapsed: 00:50:58.\n",
            "  Batch 24560  of  27729.    Elapsed: 00:51:03.\n",
            "  Batch 24600  of  27729.    Elapsed: 00:51:08.\n",
            "  Batch 24640  of  27729.    Elapsed: 00:51:13.\n",
            "  Batch 24680  of  27729.    Elapsed: 00:51:18.\n",
            "  Batch 24720  of  27729.    Elapsed: 00:51:23.\n",
            "  Batch 24760  of  27729.    Elapsed: 00:51:28.\n",
            "  Batch 24800  of  27729.    Elapsed: 00:51:33.\n",
            "  Batch 24840  of  27729.    Elapsed: 00:51:38.\n",
            "  Batch 24880  of  27729.    Elapsed: 00:51:43.\n",
            "  Batch 24920  of  27729.    Elapsed: 00:51:48.\n",
            "  Batch 24960  of  27729.    Elapsed: 00:51:53.\n",
            "  Batch 25000  of  27729.    Elapsed: 00:51:58.\n",
            "  Batch 25040  of  27729.    Elapsed: 00:52:03.\n",
            "  Batch 25080  of  27729.    Elapsed: 00:52:08.\n",
            "  Batch 25120  of  27729.    Elapsed: 00:52:13.\n",
            "  Batch 25160  of  27729.    Elapsed: 00:52:17.\n",
            "  Batch 25200  of  27729.    Elapsed: 00:52:22.\n",
            "  Batch 25240  of  27729.    Elapsed: 00:52:27.\n",
            "  Batch 25280  of  27729.    Elapsed: 00:52:32.\n",
            "  Batch 25320  of  27729.    Elapsed: 00:52:37.\n",
            "  Batch 25360  of  27729.    Elapsed: 00:52:42.\n",
            "  Batch 25400  of  27729.    Elapsed: 00:52:47.\n",
            "  Batch 25440  of  27729.    Elapsed: 00:52:52.\n",
            "  Batch 25480  of  27729.    Elapsed: 00:52:57.\n",
            "  Batch 25520  of  27729.    Elapsed: 00:53:02.\n",
            "  Batch 25560  of  27729.    Elapsed: 00:53:07.\n",
            "  Batch 25600  of  27729.    Elapsed: 00:53:12.\n",
            "  Batch 25640  of  27729.    Elapsed: 00:53:17.\n",
            "  Batch 25680  of  27729.    Elapsed: 00:53:22.\n",
            "  Batch 25720  of  27729.    Elapsed: 00:53:27.\n",
            "  Batch 25760  of  27729.    Elapsed: 00:53:32.\n",
            "  Batch 25800  of  27729.    Elapsed: 00:53:37.\n",
            "  Batch 25840  of  27729.    Elapsed: 00:53:42.\n",
            "  Batch 25880  of  27729.    Elapsed: 00:53:47.\n",
            "  Batch 25920  of  27729.    Elapsed: 00:53:52.\n",
            "  Batch 25960  of  27729.    Elapsed: 00:53:57.\n",
            "  Batch 26000  of  27729.    Elapsed: 00:54:02.\n",
            "  Batch 26040  of  27729.    Elapsed: 00:54:07.\n",
            "  Batch 26080  of  27729.    Elapsed: 00:54:12.\n",
            "  Batch 26120  of  27729.    Elapsed: 00:54:17.\n",
            "  Batch 26160  of  27729.    Elapsed: 00:54:22.\n",
            "  Batch 26200  of  27729.    Elapsed: 00:54:27.\n",
            "  Batch 26240  of  27729.    Elapsed: 00:54:32.\n",
            "  Batch 26280  of  27729.    Elapsed: 00:54:37.\n",
            "  Batch 26320  of  27729.    Elapsed: 00:54:42.\n",
            "  Batch 26360  of  27729.    Elapsed: 00:54:47.\n",
            "  Batch 26400  of  27729.    Elapsed: 00:54:52.\n",
            "  Batch 26440  of  27729.    Elapsed: 00:54:57.\n",
            "  Batch 26480  of  27729.    Elapsed: 00:55:02.\n",
            "  Batch 26520  of  27729.    Elapsed: 00:55:07.\n",
            "  Batch 26560  of  27729.    Elapsed: 00:55:12.\n",
            "  Batch 26600  of  27729.    Elapsed: 00:55:17.\n",
            "  Batch 26640  of  27729.    Elapsed: 00:55:22.\n",
            "  Batch 26680  of  27729.    Elapsed: 00:55:27.\n",
            "  Batch 26720  of  27729.    Elapsed: 00:55:32.\n",
            "  Batch 26760  of  27729.    Elapsed: 00:55:37.\n",
            "  Batch 26800  of  27729.    Elapsed: 00:55:42.\n",
            "  Batch 26840  of  27729.    Elapsed: 00:55:47.\n",
            "  Batch 26880  of  27729.    Elapsed: 00:55:52.\n",
            "  Batch 26920  of  27729.    Elapsed: 00:55:57.\n",
            "  Batch 26960  of  27729.    Elapsed: 00:56:02.\n",
            "  Batch 27000  of  27729.    Elapsed: 00:56:07.\n",
            "  Batch 27040  of  27729.    Elapsed: 00:56:12.\n",
            "  Batch 27080  of  27729.    Elapsed: 00:56:17.\n",
            "  Batch 27120  of  27729.    Elapsed: 00:56:22.\n",
            "  Batch 27160  of  27729.    Elapsed: 00:56:27.\n",
            "  Batch 27200  of  27729.    Elapsed: 00:56:32.\n",
            "  Batch 27240  of  27729.    Elapsed: 00:56:37.\n",
            "  Batch 27280  of  27729.    Elapsed: 00:56:42.\n",
            "  Batch 27320  of  27729.    Elapsed: 00:56:47.\n",
            "  Batch 27360  of  27729.    Elapsed: 00:56:52.\n",
            "  Batch 27400  of  27729.    Elapsed: 00:56:57.\n",
            "  Batch 27440  of  27729.    Elapsed: 00:57:02.\n",
            "  Batch 27480  of  27729.    Elapsed: 00:57:07.\n",
            "  Batch 27520  of  27729.    Elapsed: 00:57:12.\n",
            "  Batch 27560  of  27729.    Elapsed: 00:57:17.\n",
            "  Batch 27600  of  27729.    Elapsed: 00:57:22.\n",
            "  Batch 27640  of  27729.    Elapsed: 00:57:27.\n",
            "  Batch 27680  of  27729.    Elapsed: 00:57:32.\n",
            "  Batch 27720  of  27729.    Elapsed: 00:57:37.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 00:57:38\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch 40  of  27729.    Elapsed: 00:00:05.\n",
            "  Batch 80  of  27729.    Elapsed: 00:00:10.\n",
            "  Batch 120  of  27729.    Elapsed: 00:00:15.\n",
            "  Batch 160  of  27729.    Elapsed: 00:00:20.\n",
            "  Batch 200  of  27729.    Elapsed: 00:00:25.\n",
            "  Batch 240  of  27729.    Elapsed: 00:00:30.\n",
            "  Batch 280  of  27729.    Elapsed: 00:00:35.\n",
            "  Batch 320  of  27729.    Elapsed: 00:00:40.\n",
            "  Batch 360  of  27729.    Elapsed: 00:00:45.\n",
            "  Batch 400  of  27729.    Elapsed: 00:00:50.\n",
            "  Batch 440  of  27729.    Elapsed: 00:00:55.\n",
            "  Batch 480  of  27729.    Elapsed: 00:01:00.\n",
            "  Batch 520  of  27729.    Elapsed: 00:01:05.\n",
            "  Batch 560  of  27729.    Elapsed: 00:01:10.\n",
            "  Batch 600  of  27729.    Elapsed: 00:01:15.\n",
            "  Batch 640  of  27729.    Elapsed: 00:01:20.\n",
            "  Batch 680  of  27729.    Elapsed: 00:01:25.\n",
            "  Batch 720  of  27729.    Elapsed: 00:01:30.\n",
            "  Batch 760  of  27729.    Elapsed: 00:01:35.\n",
            "  Batch 800  of  27729.    Elapsed: 00:01:40.\n",
            "  Batch 840  of  27729.    Elapsed: 00:01:45.\n",
            "  Batch 880  of  27729.    Elapsed: 00:01:50.\n",
            "  Batch 920  of  27729.    Elapsed: 00:01:55.\n",
            "  Batch 960  of  27729.    Elapsed: 00:02:00.\n",
            "  Batch 1000  of  27729.    Elapsed: 00:02:05.\n",
            "  Batch 1040  of  27729.    Elapsed: 00:02:10.\n",
            "  Batch 1080  of  27729.    Elapsed: 00:02:15.\n",
            "  Batch 1120  of  27729.    Elapsed: 00:02:20.\n",
            "  Batch 1160  of  27729.    Elapsed: 00:02:25.\n",
            "  Batch 1200  of  27729.    Elapsed: 00:02:30.\n",
            "  Batch 1240  of  27729.    Elapsed: 00:02:35.\n",
            "  Batch 1280  of  27729.    Elapsed: 00:02:40.\n",
            "  Batch 1320  of  27729.    Elapsed: 00:02:45.\n",
            "  Batch 1360  of  27729.    Elapsed: 00:02:50.\n",
            "  Batch 1400  of  27729.    Elapsed: 00:02:55.\n",
            "  Batch 1440  of  27729.    Elapsed: 00:03:00.\n",
            "  Batch 1480  of  27729.    Elapsed: 00:03:04.\n",
            "  Batch 1520  of  27729.    Elapsed: 00:03:09.\n",
            "  Batch 1560  of  27729.    Elapsed: 00:03:14.\n",
            "  Batch 1600  of  27729.    Elapsed: 00:03:19.\n",
            "  Batch 1640  of  27729.    Elapsed: 00:03:24.\n",
            "  Batch 1680  of  27729.    Elapsed: 00:03:29.\n",
            "  Batch 1720  of  27729.    Elapsed: 00:03:34.\n",
            "  Batch 1760  of  27729.    Elapsed: 00:03:39.\n",
            "  Batch 1800  of  27729.    Elapsed: 00:03:44.\n",
            "  Batch 1840  of  27729.    Elapsed: 00:03:49.\n",
            "  Batch 1880  of  27729.    Elapsed: 00:03:54.\n",
            "  Batch 1920  of  27729.    Elapsed: 00:03:59.\n",
            "  Batch 1960  of  27729.    Elapsed: 00:04:04.\n",
            "  Batch 2000  of  27729.    Elapsed: 00:04:09.\n",
            "  Batch 2040  of  27729.    Elapsed: 00:04:14.\n",
            "  Batch 2080  of  27729.    Elapsed: 00:04:19.\n",
            "  Batch 2120  of  27729.    Elapsed: 00:04:24.\n",
            "  Batch 2160  of  27729.    Elapsed: 00:04:29.\n",
            "  Batch 2200  of  27729.    Elapsed: 00:04:34.\n",
            "  Batch 2240  of  27729.    Elapsed: 00:04:39.\n",
            "  Batch 2280  of  27729.    Elapsed: 00:04:44.\n",
            "  Batch 2320  of  27729.    Elapsed: 00:04:49.\n",
            "  Batch 2360  of  27729.    Elapsed: 00:04:54.\n",
            "  Batch 2400  of  27729.    Elapsed: 00:04:59.\n",
            "  Batch 2440  of  27729.    Elapsed: 00:05:04.\n",
            "  Batch 2480  of  27729.    Elapsed: 00:05:09.\n",
            "  Batch 2520  of  27729.    Elapsed: 00:05:14.\n",
            "  Batch 2560  of  27729.    Elapsed: 00:05:19.\n",
            "  Batch 2600  of  27729.    Elapsed: 00:05:24.\n",
            "  Batch 2640  of  27729.    Elapsed: 00:05:29.\n",
            "  Batch 2680  of  27729.    Elapsed: 00:05:34.\n",
            "  Batch 2720  of  27729.    Elapsed: 00:05:39.\n",
            "  Batch 2760  of  27729.    Elapsed: 00:05:44.\n",
            "  Batch 2800  of  27729.    Elapsed: 00:05:49.\n",
            "  Batch 2840  of  27729.    Elapsed: 00:05:54.\n",
            "  Batch 2880  of  27729.    Elapsed: 00:05:59.\n",
            "  Batch 2920  of  27729.    Elapsed: 00:06:04.\n",
            "  Batch 2960  of  27729.    Elapsed: 00:06:09.\n",
            "  Batch 3000  of  27729.    Elapsed: 00:06:14.\n",
            "  Batch 3040  of  27729.    Elapsed: 00:06:19.\n",
            "  Batch 3080  of  27729.    Elapsed: 00:06:24.\n",
            "  Batch 3120  of  27729.    Elapsed: 00:06:29.\n",
            "  Batch 3160  of  27729.    Elapsed: 00:06:34.\n",
            "  Batch 3200  of  27729.    Elapsed: 00:06:39.\n",
            "  Batch 3240  of  27729.    Elapsed: 00:06:44.\n",
            "  Batch 3280  of  27729.    Elapsed: 00:06:49.\n",
            "  Batch 3320  of  27729.    Elapsed: 00:06:54.\n",
            "  Batch 3360  of  27729.    Elapsed: 00:06:59.\n",
            "  Batch 3400  of  27729.    Elapsed: 00:07:04.\n",
            "  Batch 3440  of  27729.    Elapsed: 00:07:09.\n",
            "  Batch 3480  of  27729.    Elapsed: 00:07:14.\n",
            "  Batch 3520  of  27729.    Elapsed: 00:07:19.\n",
            "  Batch 3560  of  27729.    Elapsed: 00:07:24.\n",
            "  Batch 3600  of  27729.    Elapsed: 00:07:29.\n",
            "  Batch 3640  of  27729.    Elapsed: 00:07:34.\n",
            "  Batch 3680  of  27729.    Elapsed: 00:07:39.\n",
            "  Batch 3720  of  27729.    Elapsed: 00:07:44.\n",
            "  Batch 3760  of  27729.    Elapsed: 00:07:49.\n",
            "  Batch 3800  of  27729.    Elapsed: 00:07:54.\n",
            "  Batch 3840  of  27729.    Elapsed: 00:07:59.\n",
            "  Batch 3880  of  27729.    Elapsed: 00:08:04.\n",
            "  Batch 3920  of  27729.    Elapsed: 00:08:09.\n",
            "  Batch 3960  of  27729.    Elapsed: 00:08:14.\n",
            "  Batch 4000  of  27729.    Elapsed: 00:08:19.\n",
            "  Batch 4040  of  27729.    Elapsed: 00:08:24.\n",
            "  Batch 4080  of  27729.    Elapsed: 00:08:28.\n",
            "  Batch 4120  of  27729.    Elapsed: 00:08:33.\n",
            "  Batch 4160  of  27729.    Elapsed: 00:08:38.\n",
            "  Batch 4200  of  27729.    Elapsed: 00:08:43.\n",
            "  Batch 4240  of  27729.    Elapsed: 00:08:48.\n",
            "  Batch 4280  of  27729.    Elapsed: 00:08:53.\n",
            "  Batch 4320  of  27729.    Elapsed: 00:08:58.\n",
            "  Batch 4360  of  27729.    Elapsed: 00:09:03.\n",
            "  Batch 4400  of  27729.    Elapsed: 00:09:08.\n",
            "  Batch 4440  of  27729.    Elapsed: 00:09:13.\n",
            "  Batch 4480  of  27729.    Elapsed: 00:09:18.\n",
            "  Batch 4520  of  27729.    Elapsed: 00:09:23.\n",
            "  Batch 4560  of  27729.    Elapsed: 00:09:28.\n",
            "  Batch 4600  of  27729.    Elapsed: 00:09:33.\n",
            "  Batch 4640  of  27729.    Elapsed: 00:09:38.\n",
            "  Batch 4680  of  27729.    Elapsed: 00:09:43.\n",
            "  Batch 4720  of  27729.    Elapsed: 00:09:48.\n",
            "  Batch 4760  of  27729.    Elapsed: 00:09:53.\n",
            "  Batch 4800  of  27729.    Elapsed: 00:09:58.\n",
            "  Batch 4840  of  27729.    Elapsed: 00:10:03.\n",
            "  Batch 4880  of  27729.    Elapsed: 00:10:08.\n",
            "  Batch 4920  of  27729.    Elapsed: 00:10:13.\n",
            "  Batch 4960  of  27729.    Elapsed: 00:10:18.\n",
            "  Batch 5000  of  27729.    Elapsed: 00:10:23.\n",
            "  Batch 5040  of  27729.    Elapsed: 00:10:28.\n",
            "  Batch 5080  of  27729.    Elapsed: 00:10:33.\n",
            "  Batch 5120  of  27729.    Elapsed: 00:10:38.\n",
            "  Batch 5160  of  27729.    Elapsed: 00:10:43.\n",
            "  Batch 5200  of  27729.    Elapsed: 00:10:48.\n",
            "  Batch 5240  of  27729.    Elapsed: 00:10:53.\n",
            "  Batch 5280  of  27729.    Elapsed: 00:10:58.\n",
            "  Batch 5320  of  27729.    Elapsed: 00:11:03.\n",
            "  Batch 5360  of  27729.    Elapsed: 00:11:08.\n",
            "  Batch 5400  of  27729.    Elapsed: 00:11:13.\n",
            "  Batch 5440  of  27729.    Elapsed: 00:11:18.\n",
            "  Batch 5480  of  27729.    Elapsed: 00:11:23.\n",
            "  Batch 5520  of  27729.    Elapsed: 00:11:28.\n",
            "  Batch 5560  of  27729.    Elapsed: 00:11:33.\n",
            "  Batch 5600  of  27729.    Elapsed: 00:11:38.\n",
            "  Batch 5640  of  27729.    Elapsed: 00:11:43.\n",
            "  Batch 5680  of  27729.    Elapsed: 00:11:48.\n",
            "  Batch 5720  of  27729.    Elapsed: 00:11:53.\n",
            "  Batch 5760  of  27729.    Elapsed: 00:11:58.\n",
            "  Batch 5800  of  27729.    Elapsed: 00:12:03.\n",
            "  Batch 5840  of  27729.    Elapsed: 00:12:08.\n",
            "  Batch 5880  of  27729.    Elapsed: 00:12:13.\n",
            "  Batch 5920  of  27729.    Elapsed: 00:12:18.\n",
            "  Batch 5960  of  27729.    Elapsed: 00:12:23.\n",
            "  Batch 6000  of  27729.    Elapsed: 00:12:28.\n",
            "  Batch 6040  of  27729.    Elapsed: 00:12:33.\n",
            "  Batch 6080  of  27729.    Elapsed: 00:12:38.\n",
            "  Batch 6120  of  27729.    Elapsed: 00:12:43.\n",
            "  Batch 6160  of  27729.    Elapsed: 00:12:48.\n",
            "  Batch 6200  of  27729.    Elapsed: 00:12:53.\n",
            "  Batch 6240  of  27729.    Elapsed: 00:12:58.\n",
            "  Batch 6280  of  27729.    Elapsed: 00:13:03.\n",
            "  Batch 6320  of  27729.    Elapsed: 00:13:08.\n",
            "  Batch 6360  of  27729.    Elapsed: 00:13:13.\n",
            "  Batch 6400  of  27729.    Elapsed: 00:13:18.\n",
            "  Batch 6440  of  27729.    Elapsed: 00:13:23.\n",
            "  Batch 6480  of  27729.    Elapsed: 00:13:28.\n",
            "  Batch 6520  of  27729.    Elapsed: 00:13:33.\n",
            "  Batch 6560  of  27729.    Elapsed: 00:13:38.\n",
            "  Batch 6600  of  27729.    Elapsed: 00:13:43.\n",
            "  Batch 6640  of  27729.    Elapsed: 00:13:48.\n",
            "  Batch 6680  of  27729.    Elapsed: 00:13:53.\n",
            "  Batch 6720  of  27729.    Elapsed: 00:13:58.\n",
            "  Batch 6760  of  27729.    Elapsed: 00:14:03.\n",
            "  Batch 6800  of  27729.    Elapsed: 00:14:08.\n",
            "  Batch 6840  of  27729.    Elapsed: 00:14:13.\n",
            "  Batch 6880  of  27729.    Elapsed: 00:14:18.\n",
            "  Batch 6920  of  27729.    Elapsed: 00:14:23.\n",
            "  Batch 6960  of  27729.    Elapsed: 00:14:27.\n",
            "  Batch 7000  of  27729.    Elapsed: 00:14:32.\n",
            "  Batch 7040  of  27729.    Elapsed: 00:14:37.\n",
            "  Batch 7080  of  27729.    Elapsed: 00:14:42.\n",
            "  Batch 7120  of  27729.    Elapsed: 00:14:47.\n",
            "  Batch 7160  of  27729.    Elapsed: 00:14:52.\n",
            "  Batch 7200  of  27729.    Elapsed: 00:14:57.\n",
            "  Batch 7240  of  27729.    Elapsed: 00:15:02.\n",
            "  Batch 7280  of  27729.    Elapsed: 00:15:07.\n",
            "  Batch 7320  of  27729.    Elapsed: 00:15:12.\n",
            "  Batch 7360  of  27729.    Elapsed: 00:15:17.\n",
            "  Batch 7400  of  27729.    Elapsed: 00:15:22.\n",
            "  Batch 7440  of  27729.    Elapsed: 00:15:27.\n",
            "  Batch 7480  of  27729.    Elapsed: 00:15:32.\n",
            "  Batch 7520  of  27729.    Elapsed: 00:15:37.\n",
            "  Batch 7560  of  27729.    Elapsed: 00:15:42.\n",
            "  Batch 7600  of  27729.    Elapsed: 00:15:47.\n",
            "  Batch 7640  of  27729.    Elapsed: 00:15:52.\n",
            "  Batch 7680  of  27729.    Elapsed: 00:15:57.\n",
            "  Batch 7720  of  27729.    Elapsed: 00:16:02.\n",
            "  Batch 7760  of  27729.    Elapsed: 00:16:07.\n",
            "  Batch 7800  of  27729.    Elapsed: 00:16:12.\n",
            "  Batch 7840  of  27729.    Elapsed: 00:16:17.\n",
            "  Batch 7880  of  27729.    Elapsed: 00:16:22.\n",
            "  Batch 7920  of  27729.    Elapsed: 00:16:27.\n",
            "  Batch 7960  of  27729.    Elapsed: 00:16:32.\n",
            "  Batch 8000  of  27729.    Elapsed: 00:16:37.\n",
            "  Batch 8040  of  27729.    Elapsed: 00:16:42.\n",
            "  Batch 8080  of  27729.    Elapsed: 00:16:47.\n",
            "  Batch 8120  of  27729.    Elapsed: 00:16:52.\n",
            "  Batch 8160  of  27729.    Elapsed: 00:16:57.\n",
            "  Batch 8200  of  27729.    Elapsed: 00:17:02.\n",
            "  Batch 8240  of  27729.    Elapsed: 00:17:07.\n",
            "  Batch 8280  of  27729.    Elapsed: 00:17:12.\n",
            "  Batch 8320  of  27729.    Elapsed: 00:17:17.\n",
            "  Batch 8360  of  27729.    Elapsed: 00:17:22.\n",
            "  Batch 8400  of  27729.    Elapsed: 00:17:27.\n",
            "  Batch 8440  of  27729.    Elapsed: 00:17:32.\n",
            "  Batch 8480  of  27729.    Elapsed: 00:17:37.\n",
            "  Batch 8520  of  27729.    Elapsed: 00:17:42.\n",
            "  Batch 8560  of  27729.    Elapsed: 00:17:47.\n",
            "  Batch 8600  of  27729.    Elapsed: 00:17:52.\n",
            "  Batch 8640  of  27729.    Elapsed: 00:17:57.\n",
            "  Batch 8680  of  27729.    Elapsed: 00:18:02.\n",
            "  Batch 8720  of  27729.    Elapsed: 00:18:07.\n",
            "  Batch 8760  of  27729.    Elapsed: 00:18:12.\n",
            "  Batch 8800  of  27729.    Elapsed: 00:18:17.\n",
            "  Batch 8840  of  27729.    Elapsed: 00:18:22.\n",
            "  Batch 8880  of  27729.    Elapsed: 00:18:27.\n",
            "  Batch 8920  of  27729.    Elapsed: 00:18:32.\n",
            "  Batch 8960  of  27729.    Elapsed: 00:18:37.\n",
            "  Batch 9000  of  27729.    Elapsed: 00:18:42.\n",
            "  Batch 9040  of  27729.    Elapsed: 00:18:47.\n",
            "  Batch 9080  of  27729.    Elapsed: 00:18:52.\n",
            "  Batch 9120  of  27729.    Elapsed: 00:18:57.\n",
            "  Batch 9160  of  27729.    Elapsed: 00:19:02.\n",
            "  Batch 9200  of  27729.    Elapsed: 00:19:07.\n",
            "  Batch 9240  of  27729.    Elapsed: 00:19:12.\n",
            "  Batch 9280  of  27729.    Elapsed: 00:19:17.\n",
            "  Batch 9320  of  27729.    Elapsed: 00:19:22.\n",
            "  Batch 9360  of  27729.    Elapsed: 00:19:27.\n",
            "  Batch 9400  of  27729.    Elapsed: 00:19:32.\n",
            "  Batch 9440  of  27729.    Elapsed: 00:19:37.\n",
            "  Batch 9480  of  27729.    Elapsed: 00:19:42.\n",
            "  Batch 9520  of  27729.    Elapsed: 00:19:47.\n",
            "  Batch 9560  of  27729.    Elapsed: 00:19:52.\n",
            "  Batch 9600  of  27729.    Elapsed: 00:19:57.\n",
            "  Batch 9640  of  27729.    Elapsed: 00:20:02.\n",
            "  Batch 9680  of  27729.    Elapsed: 00:20:07.\n",
            "  Batch 9720  of  27729.    Elapsed: 00:20:11.\n",
            "  Batch 9760  of  27729.    Elapsed: 00:20:16.\n",
            "  Batch 9800  of  27729.    Elapsed: 00:20:21.\n",
            "  Batch 9840  of  27729.    Elapsed: 00:20:26.\n",
            "  Batch 9880  of  27729.    Elapsed: 00:20:31.\n",
            "  Batch 9920  of  27729.    Elapsed: 00:20:36.\n",
            "  Batch 9960  of  27729.    Elapsed: 00:20:41.\n",
            "  Batch 10000  of  27729.    Elapsed: 00:20:46.\n",
            "  Batch 10040  of  27729.    Elapsed: 00:20:51.\n",
            "  Batch 10080  of  27729.    Elapsed: 00:20:56.\n",
            "  Batch 10120  of  27729.    Elapsed: 00:21:01.\n",
            "  Batch 10160  of  27729.    Elapsed: 00:21:06.\n",
            "  Batch 10200  of  27729.    Elapsed: 00:21:11.\n",
            "  Batch 10240  of  27729.    Elapsed: 00:21:16.\n",
            "  Batch 10280  of  27729.    Elapsed: 00:21:21.\n",
            "  Batch 10320  of  27729.    Elapsed: 00:21:26.\n",
            "  Batch 10360  of  27729.    Elapsed: 00:21:31.\n",
            "  Batch 10400  of  27729.    Elapsed: 00:21:36.\n",
            "  Batch 10440  of  27729.    Elapsed: 00:21:41.\n",
            "  Batch 10480  of  27729.    Elapsed: 00:21:46.\n",
            "  Batch 10520  of  27729.    Elapsed: 00:21:51.\n",
            "  Batch 10560  of  27729.    Elapsed: 00:21:56.\n",
            "  Batch 10600  of  27729.    Elapsed: 00:22:01.\n",
            "  Batch 10640  of  27729.    Elapsed: 00:22:06.\n",
            "  Batch 10680  of  27729.    Elapsed: 00:22:11.\n",
            "  Batch 10720  of  27729.    Elapsed: 00:22:16.\n",
            "  Batch 10760  of  27729.    Elapsed: 00:22:21.\n",
            "  Batch 10800  of  27729.    Elapsed: 00:22:26.\n",
            "  Batch 10840  of  27729.    Elapsed: 00:22:31.\n",
            "  Batch 10880  of  27729.    Elapsed: 00:22:36.\n",
            "  Batch 10920  of  27729.    Elapsed: 00:22:41.\n",
            "  Batch 10960  of  27729.    Elapsed: 00:22:46.\n",
            "  Batch 11000  of  27729.    Elapsed: 00:22:51.\n",
            "  Batch 11040  of  27729.    Elapsed: 00:22:56.\n",
            "  Batch 11080  of  27729.    Elapsed: 00:23:01.\n",
            "  Batch 11120  of  27729.    Elapsed: 00:23:06.\n",
            "  Batch 11160  of  27729.    Elapsed: 00:23:11.\n",
            "  Batch 11200  of  27729.    Elapsed: 00:23:16.\n",
            "  Batch 11240  of  27729.    Elapsed: 00:23:21.\n",
            "  Batch 11280  of  27729.    Elapsed: 00:23:26.\n",
            "  Batch 11320  of  27729.    Elapsed: 00:23:31.\n",
            "  Batch 11360  of  27729.    Elapsed: 00:23:36.\n",
            "  Batch 11400  of  27729.    Elapsed: 00:23:41.\n",
            "  Batch 11440  of  27729.    Elapsed: 00:23:46.\n",
            "  Batch 11480  of  27729.    Elapsed: 00:23:51.\n",
            "  Batch 11520  of  27729.    Elapsed: 00:23:56.\n",
            "  Batch 11560  of  27729.    Elapsed: 00:24:01.\n",
            "  Batch 11600  of  27729.    Elapsed: 00:24:06.\n",
            "  Batch 11640  of  27729.    Elapsed: 00:24:11.\n",
            "  Batch 11680  of  27729.    Elapsed: 00:24:16.\n",
            "  Batch 11720  of  27729.    Elapsed: 00:24:21.\n",
            "  Batch 11760  of  27729.    Elapsed: 00:24:26.\n",
            "  Batch 11800  of  27729.    Elapsed: 00:24:31.\n",
            "  Batch 11840  of  27729.    Elapsed: 00:24:36.\n",
            "  Batch 11880  of  27729.    Elapsed: 00:24:41.\n",
            "  Batch 11920  of  27729.    Elapsed: 00:24:46.\n",
            "  Batch 11960  of  27729.    Elapsed: 00:24:51.\n",
            "  Batch 12000  of  27729.    Elapsed: 00:24:56.\n",
            "  Batch 12040  of  27729.    Elapsed: 00:25:01.\n",
            "  Batch 12080  of  27729.    Elapsed: 00:25:06.\n",
            "  Batch 12120  of  27729.    Elapsed: 00:25:11.\n",
            "  Batch 12160  of  27729.    Elapsed: 00:25:16.\n",
            "  Batch 12200  of  27729.    Elapsed: 00:25:21.\n",
            "  Batch 12240  of  27729.    Elapsed: 00:25:26.\n",
            "  Batch 12280  of  27729.    Elapsed: 00:25:31.\n",
            "  Batch 12320  of  27729.    Elapsed: 00:25:36.\n",
            "  Batch 12360  of  27729.    Elapsed: 00:25:41.\n",
            "  Batch 12400  of  27729.    Elapsed: 00:25:46.\n",
            "  Batch 12440  of  27729.    Elapsed: 00:25:50.\n",
            "  Batch 12480  of  27729.    Elapsed: 00:25:55.\n",
            "  Batch 12520  of  27729.    Elapsed: 00:26:00.\n",
            "  Batch 12560  of  27729.    Elapsed: 00:26:05.\n",
            "  Batch 12600  of  27729.    Elapsed: 00:26:10.\n",
            "  Batch 12640  of  27729.    Elapsed: 00:26:15.\n",
            "  Batch 12680  of  27729.    Elapsed: 00:26:20.\n",
            "  Batch 12720  of  27729.    Elapsed: 00:26:25.\n",
            "  Batch 12760  of  27729.    Elapsed: 00:26:30.\n",
            "  Batch 12800  of  27729.    Elapsed: 00:26:35.\n",
            "  Batch 12840  of  27729.    Elapsed: 00:26:40.\n",
            "  Batch 12880  of  27729.    Elapsed: 00:26:45.\n",
            "  Batch 12920  of  27729.    Elapsed: 00:26:50.\n",
            "  Batch 12960  of  27729.    Elapsed: 00:26:55.\n",
            "  Batch 13000  of  27729.    Elapsed: 00:27:00.\n",
            "  Batch 13040  of  27729.    Elapsed: 00:27:05.\n",
            "  Batch 13080  of  27729.    Elapsed: 00:27:10.\n",
            "  Batch 13120  of  27729.    Elapsed: 00:27:15.\n",
            "  Batch 13160  of  27729.    Elapsed: 00:27:20.\n",
            "  Batch 13200  of  27729.    Elapsed: 00:27:25.\n",
            "  Batch 13240  of  27729.    Elapsed: 00:27:30.\n",
            "  Batch 13280  of  27729.    Elapsed: 00:27:35.\n",
            "  Batch 13320  of  27729.    Elapsed: 00:27:40.\n",
            "  Batch 13360  of  27729.    Elapsed: 00:27:45.\n",
            "  Batch 13400  of  27729.    Elapsed: 00:27:50.\n",
            "  Batch 13440  of  27729.    Elapsed: 00:27:55.\n",
            "  Batch 13480  of  27729.    Elapsed: 00:28:00.\n",
            "  Batch 13520  of  27729.    Elapsed: 00:28:05.\n",
            "  Batch 13560  of  27729.    Elapsed: 00:28:10.\n",
            "  Batch 13600  of  27729.    Elapsed: 00:28:15.\n",
            "  Batch 13640  of  27729.    Elapsed: 00:28:20.\n",
            "  Batch 13680  of  27729.    Elapsed: 00:28:25.\n",
            "  Batch 13720  of  27729.    Elapsed: 00:28:30.\n",
            "  Batch 13760  of  27729.    Elapsed: 00:28:35.\n",
            "  Batch 13800  of  27729.    Elapsed: 00:28:40.\n",
            "  Batch 13840  of  27729.    Elapsed: 00:28:45.\n",
            "  Batch 13880  of  27729.    Elapsed: 00:28:50.\n",
            "  Batch 13920  of  27729.    Elapsed: 00:28:55.\n",
            "  Batch 13960  of  27729.    Elapsed: 00:29:00.\n",
            "  Batch 14000  of  27729.    Elapsed: 00:29:05.\n",
            "  Batch 14040  of  27729.    Elapsed: 00:29:10.\n",
            "  Batch 14080  of  27729.    Elapsed: 00:29:15.\n",
            "  Batch 14120  of  27729.    Elapsed: 00:29:20.\n",
            "  Batch 14160  of  27729.    Elapsed: 00:29:25.\n",
            "  Batch 14200  of  27729.    Elapsed: 00:29:30.\n",
            "  Batch 14240  of  27729.    Elapsed: 00:29:35.\n",
            "  Batch 14280  of  27729.    Elapsed: 00:29:40.\n",
            "  Batch 14320  of  27729.    Elapsed: 00:29:45.\n",
            "  Batch 14360  of  27729.    Elapsed: 00:29:50.\n",
            "  Batch 14400  of  27729.    Elapsed: 00:29:55.\n",
            "  Batch 14440  of  27729.    Elapsed: 00:30:00.\n",
            "  Batch 14480  of  27729.    Elapsed: 00:30:05.\n",
            "  Batch 14520  of  27729.    Elapsed: 00:30:10.\n",
            "  Batch 14560  of  27729.    Elapsed: 00:30:15.\n",
            "  Batch 14600  of  27729.    Elapsed: 00:30:20.\n",
            "  Batch 14640  of  27729.    Elapsed: 00:30:25.\n",
            "  Batch 14680  of  27729.    Elapsed: 00:30:30.\n",
            "  Batch 14720  of  27729.    Elapsed: 00:30:35.\n",
            "  Batch 14760  of  27729.    Elapsed: 00:30:40.\n",
            "  Batch 14800  of  27729.    Elapsed: 00:30:45.\n",
            "  Batch 14840  of  27729.    Elapsed: 00:30:50.\n",
            "  Batch 14880  of  27729.    Elapsed: 00:30:55.\n",
            "  Batch 14920  of  27729.    Elapsed: 00:30:59.\n",
            "  Batch 14960  of  27729.    Elapsed: 00:31:04.\n",
            "  Batch 15000  of  27729.    Elapsed: 00:31:09.\n",
            "  Batch 15040  of  27729.    Elapsed: 00:31:14.\n",
            "  Batch 15080  of  27729.    Elapsed: 00:31:19.\n",
            "  Batch 15120  of  27729.    Elapsed: 00:31:24.\n",
            "  Batch 15160  of  27729.    Elapsed: 00:31:29.\n",
            "  Batch 15200  of  27729.    Elapsed: 00:31:34.\n",
            "  Batch 15240  of  27729.    Elapsed: 00:31:39.\n",
            "  Batch 15280  of  27729.    Elapsed: 00:31:44.\n",
            "  Batch 15320  of  27729.    Elapsed: 00:31:49.\n",
            "  Batch 15360  of  27729.    Elapsed: 00:31:54.\n",
            "  Batch 15400  of  27729.    Elapsed: 00:31:59.\n",
            "  Batch 15440  of  27729.    Elapsed: 00:32:04.\n",
            "  Batch 15480  of  27729.    Elapsed: 00:32:09.\n",
            "  Batch 15520  of  27729.    Elapsed: 00:32:14.\n",
            "  Batch 15560  of  27729.    Elapsed: 00:32:19.\n",
            "  Batch 15600  of  27729.    Elapsed: 00:32:24.\n",
            "  Batch 15640  of  27729.    Elapsed: 00:32:29.\n",
            "  Batch 15680  of  27729.    Elapsed: 00:32:34.\n",
            "  Batch 15720  of  27729.    Elapsed: 00:32:39.\n",
            "  Batch 15760  of  27729.    Elapsed: 00:32:44.\n",
            "  Batch 15800  of  27729.    Elapsed: 00:32:49.\n",
            "  Batch 15840  of  27729.    Elapsed: 00:32:54.\n",
            "  Batch 15880  of  27729.    Elapsed: 00:32:59.\n",
            "  Batch 15920  of  27729.    Elapsed: 00:33:04.\n",
            "  Batch 15960  of  27729.    Elapsed: 00:33:09.\n",
            "  Batch 16000  of  27729.    Elapsed: 00:33:14.\n",
            "  Batch 16040  of  27729.    Elapsed: 00:33:19.\n",
            "  Batch 16080  of  27729.    Elapsed: 00:33:24.\n",
            "  Batch 16120  of  27729.    Elapsed: 00:33:29.\n",
            "  Batch 16160  of  27729.    Elapsed: 00:33:34.\n",
            "  Batch 16200  of  27729.    Elapsed: 00:33:39.\n",
            "  Batch 16240  of  27729.    Elapsed: 00:33:44.\n",
            "  Batch 16280  of  27729.    Elapsed: 00:33:49.\n",
            "  Batch 16320  of  27729.    Elapsed: 00:33:54.\n",
            "  Batch 16360  of  27729.    Elapsed: 00:33:59.\n",
            "  Batch 16400  of  27729.    Elapsed: 00:34:04.\n",
            "  Batch 16440  of  27729.    Elapsed: 00:34:09.\n",
            "  Batch 16480  of  27729.    Elapsed: 00:34:14.\n",
            "  Batch 16520  of  27729.    Elapsed: 00:34:19.\n",
            "  Batch 16560  of  27729.    Elapsed: 00:34:24.\n",
            "  Batch 16600  of  27729.    Elapsed: 00:34:29.\n",
            "  Batch 16640  of  27729.    Elapsed: 00:34:34.\n",
            "  Batch 16680  of  27729.    Elapsed: 00:34:39.\n",
            "  Batch 16720  of  27729.    Elapsed: 00:34:44.\n",
            "  Batch 16760  of  27729.    Elapsed: 00:34:49.\n",
            "  Batch 16800  of  27729.    Elapsed: 00:34:54.\n",
            "  Batch 16840  of  27729.    Elapsed: 00:34:59.\n",
            "  Batch 16880  of  27729.    Elapsed: 00:35:04.\n",
            "  Batch 16920  of  27729.    Elapsed: 00:35:09.\n",
            "  Batch 16960  of  27729.    Elapsed: 00:35:14.\n",
            "  Batch 17000  of  27729.    Elapsed: 00:35:19.\n",
            "  Batch 17040  of  27729.    Elapsed: 00:35:24.\n",
            "  Batch 17080  of  27729.    Elapsed: 00:35:29.\n",
            "  Batch 17120  of  27729.    Elapsed: 00:35:34.\n",
            "  Batch 17160  of  27729.    Elapsed: 00:35:39.\n",
            "  Batch 17200  of  27729.    Elapsed: 00:35:44.\n",
            "  Batch 17240  of  27729.    Elapsed: 00:35:49.\n",
            "  Batch 17280  of  27729.    Elapsed: 00:35:54.\n",
            "  Batch 17320  of  27729.    Elapsed: 00:35:59.\n",
            "  Batch 17360  of  27729.    Elapsed: 00:36:04.\n",
            "  Batch 17400  of  27729.    Elapsed: 00:36:09.\n",
            "  Batch 17440  of  27729.    Elapsed: 00:36:14.\n",
            "  Batch 17480  of  27729.    Elapsed: 00:36:19.\n",
            "  Batch 17520  of  27729.    Elapsed: 00:36:24.\n",
            "  Batch 17560  of  27729.    Elapsed: 00:36:29.\n",
            "  Batch 17600  of  27729.    Elapsed: 00:36:34.\n",
            "  Batch 17640  of  27729.    Elapsed: 00:36:38.\n",
            "  Batch 17680  of  27729.    Elapsed: 00:36:43.\n",
            "  Batch 17720  of  27729.    Elapsed: 00:36:48.\n",
            "  Batch 17760  of  27729.    Elapsed: 00:36:53.\n",
            "  Batch 17800  of  27729.    Elapsed: 00:36:58.\n",
            "  Batch 17840  of  27729.    Elapsed: 00:37:03.\n",
            "  Batch 17880  of  27729.    Elapsed: 00:37:08.\n",
            "  Batch 17920  of  27729.    Elapsed: 00:37:13.\n",
            "  Batch 17960  of  27729.    Elapsed: 00:37:18.\n",
            "  Batch 18000  of  27729.    Elapsed: 00:37:23.\n",
            "  Batch 18040  of  27729.    Elapsed: 00:37:28.\n",
            "  Batch 18080  of  27729.    Elapsed: 00:37:33.\n",
            "  Batch 18120  of  27729.    Elapsed: 00:37:38.\n",
            "  Batch 18160  of  27729.    Elapsed: 00:37:43.\n",
            "  Batch 18200  of  27729.    Elapsed: 00:37:48.\n",
            "  Batch 18240  of  27729.    Elapsed: 00:37:53.\n",
            "  Batch 18280  of  27729.    Elapsed: 00:37:58.\n",
            "  Batch 18320  of  27729.    Elapsed: 00:38:03.\n",
            "  Batch 18360  of  27729.    Elapsed: 00:38:08.\n",
            "  Batch 18400  of  27729.    Elapsed: 00:38:13.\n",
            "  Batch 18440  of  27729.    Elapsed: 00:38:18.\n",
            "  Batch 18480  of  27729.    Elapsed: 00:38:23.\n",
            "  Batch 18520  of  27729.    Elapsed: 00:38:28.\n",
            "  Batch 18560  of  27729.    Elapsed: 00:38:33.\n",
            "  Batch 18600  of  27729.    Elapsed: 00:38:38.\n",
            "  Batch 18640  of  27729.    Elapsed: 00:38:43.\n",
            "  Batch 18680  of  27729.    Elapsed: 00:38:48.\n",
            "  Batch 18720  of  27729.    Elapsed: 00:38:53.\n",
            "  Batch 18760  of  27729.    Elapsed: 00:38:58.\n",
            "  Batch 18800  of  27729.    Elapsed: 00:39:03.\n",
            "  Batch 18840  of  27729.    Elapsed: 00:39:08.\n",
            "  Batch 18880  of  27729.    Elapsed: 00:39:13.\n",
            "  Batch 18920  of  27729.    Elapsed: 00:39:18.\n",
            "  Batch 18960  of  27729.    Elapsed: 00:39:23.\n",
            "  Batch 19000  of  27729.    Elapsed: 00:39:28.\n",
            "  Batch 19040  of  27729.    Elapsed: 00:39:33.\n",
            "  Batch 19080  of  27729.    Elapsed: 00:39:38.\n",
            "  Batch 19120  of  27729.    Elapsed: 00:39:43.\n",
            "  Batch 19160  of  27729.    Elapsed: 00:39:48.\n",
            "  Batch 19200  of  27729.    Elapsed: 00:39:53.\n",
            "  Batch 19240  of  27729.    Elapsed: 00:39:58.\n",
            "  Batch 19280  of  27729.    Elapsed: 00:40:03.\n",
            "  Batch 19320  of  27729.    Elapsed: 00:40:08.\n",
            "  Batch 19360  of  27729.    Elapsed: 00:40:13.\n",
            "  Batch 19400  of  27729.    Elapsed: 00:40:18.\n",
            "  Batch 19440  of  27729.    Elapsed: 00:40:23.\n",
            "  Batch 19480  of  27729.    Elapsed: 00:40:28.\n",
            "  Batch 19520  of  27729.    Elapsed: 00:40:33.\n",
            "  Batch 19560  of  27729.    Elapsed: 00:40:38.\n",
            "  Batch 19600  of  27729.    Elapsed: 00:40:43.\n",
            "  Batch 19640  of  27729.    Elapsed: 00:40:48.\n",
            "  Batch 19680  of  27729.    Elapsed: 00:40:53.\n",
            "  Batch 19720  of  27729.    Elapsed: 00:40:58.\n",
            "  Batch 19760  of  27729.    Elapsed: 00:41:03.\n",
            "  Batch 19800  of  27729.    Elapsed: 00:41:08.\n",
            "  Batch 19840  of  27729.    Elapsed: 00:41:13.\n",
            "  Batch 19880  of  27729.    Elapsed: 00:41:18.\n",
            "  Batch 19920  of  27729.    Elapsed: 00:41:23.\n",
            "  Batch 19960  of  27729.    Elapsed: 00:41:28.\n",
            "  Batch 20000  of  27729.    Elapsed: 00:41:33.\n",
            "  Batch 20040  of  27729.    Elapsed: 00:41:38.\n",
            "  Batch 20080  of  27729.    Elapsed: 00:41:43.\n",
            "  Batch 20120  of  27729.    Elapsed: 00:41:48.\n",
            "  Batch 20160  of  27729.    Elapsed: 00:41:53.\n",
            "  Batch 20200  of  27729.    Elapsed: 00:41:58.\n",
            "  Batch 20240  of  27729.    Elapsed: 00:42:03.\n",
            "  Batch 20280  of  27729.    Elapsed: 00:42:08.\n",
            "  Batch 20320  of  27729.    Elapsed: 00:42:13.\n",
            "  Batch 20360  of  27729.    Elapsed: 00:42:17.\n",
            "  Batch 20400  of  27729.    Elapsed: 00:42:22.\n",
            "  Batch 20440  of  27729.    Elapsed: 00:42:27.\n",
            "  Batch 20480  of  27729.    Elapsed: 00:42:32.\n",
            "  Batch 20520  of  27729.    Elapsed: 00:42:37.\n",
            "  Batch 20560  of  27729.    Elapsed: 00:42:42.\n",
            "  Batch 20600  of  27729.    Elapsed: 00:42:47.\n",
            "  Batch 20640  of  27729.    Elapsed: 00:42:52.\n",
            "  Batch 20680  of  27729.    Elapsed: 00:42:57.\n",
            "  Batch 20720  of  27729.    Elapsed: 00:43:02.\n",
            "  Batch 20760  of  27729.    Elapsed: 00:43:07.\n",
            "  Batch 20800  of  27729.    Elapsed: 00:43:12.\n",
            "  Batch 20840  of  27729.    Elapsed: 00:43:17.\n",
            "  Batch 20880  of  27729.    Elapsed: 00:43:22.\n",
            "  Batch 20920  of  27729.    Elapsed: 00:43:27.\n",
            "  Batch 20960  of  27729.    Elapsed: 00:43:32.\n",
            "  Batch 21000  of  27729.    Elapsed: 00:43:37.\n",
            "  Batch 21040  of  27729.    Elapsed: 00:43:42.\n",
            "  Batch 21080  of  27729.    Elapsed: 00:43:47.\n",
            "  Batch 21120  of  27729.    Elapsed: 00:43:52.\n",
            "  Batch 21160  of  27729.    Elapsed: 00:43:57.\n",
            "  Batch 21200  of  27729.    Elapsed: 00:44:02.\n",
            "  Batch 21240  of  27729.    Elapsed: 00:44:07.\n",
            "  Batch 21280  of  27729.    Elapsed: 00:44:12.\n",
            "  Batch 21320  of  27729.    Elapsed: 00:44:17.\n",
            "  Batch 21360  of  27729.    Elapsed: 00:44:22.\n",
            "  Batch 21400  of  27729.    Elapsed: 00:44:27.\n",
            "  Batch 21440  of  27729.    Elapsed: 00:44:32.\n",
            "  Batch 21480  of  27729.    Elapsed: 00:44:37.\n",
            "  Batch 21520  of  27729.    Elapsed: 00:44:42.\n",
            "  Batch 21560  of  27729.    Elapsed: 00:44:47.\n",
            "  Batch 21600  of  27729.    Elapsed: 00:44:52.\n",
            "  Batch 21640  of  27729.    Elapsed: 00:44:57.\n",
            "  Batch 21680  of  27729.    Elapsed: 00:45:02.\n",
            "  Batch 21720  of  27729.    Elapsed: 00:45:07.\n",
            "  Batch 21760  of  27729.    Elapsed: 00:45:12.\n",
            "  Batch 21800  of  27729.    Elapsed: 00:45:17.\n",
            "  Batch 21840  of  27729.    Elapsed: 00:45:22.\n",
            "  Batch 21880  of  27729.    Elapsed: 00:45:27.\n",
            "  Batch 21920  of  27729.    Elapsed: 00:45:32.\n",
            "  Batch 21960  of  27729.    Elapsed: 00:45:37.\n",
            "  Batch 22000  of  27729.    Elapsed: 00:45:42.\n",
            "  Batch 22040  of  27729.    Elapsed: 00:45:47.\n",
            "  Batch 22080  of  27729.    Elapsed: 00:45:52.\n",
            "  Batch 22120  of  27729.    Elapsed: 00:45:57.\n",
            "  Batch 22160  of  27729.    Elapsed: 00:46:02.\n",
            "  Batch 22200  of  27729.    Elapsed: 00:46:07.\n",
            "  Batch 22240  of  27729.    Elapsed: 00:46:12.\n",
            "  Batch 22280  of  27729.    Elapsed: 00:46:17.\n",
            "  Batch 22320  of  27729.    Elapsed: 00:46:22.\n",
            "  Batch 22360  of  27729.    Elapsed: 00:46:27.\n",
            "  Batch 22400  of  27729.    Elapsed: 00:46:32.\n",
            "  Batch 22440  of  27729.    Elapsed: 00:46:37.\n",
            "  Batch 22480  of  27729.    Elapsed: 00:46:42.\n",
            "  Batch 22520  of  27729.    Elapsed: 00:46:47.\n",
            "  Batch 22560  of  27729.    Elapsed: 00:46:52.\n",
            "  Batch 22600  of  27729.    Elapsed: 00:46:57.\n",
            "  Batch 22640  of  27729.    Elapsed: 00:47:02.\n",
            "  Batch 22680  of  27729.    Elapsed: 00:47:07.\n",
            "  Batch 22720  of  27729.    Elapsed: 00:47:12.\n",
            "  Batch 22760  of  27729.    Elapsed: 00:47:17.\n",
            "  Batch 22800  of  27729.    Elapsed: 00:47:22.\n",
            "  Batch 22840  of  27729.    Elapsed: 00:47:27.\n",
            "  Batch 22880  of  27729.    Elapsed: 00:47:32.\n",
            "  Batch 22920  of  27729.    Elapsed: 00:47:37.\n",
            "  Batch 22960  of  27729.    Elapsed: 00:47:42.\n",
            "  Batch 23000  of  27729.    Elapsed: 00:47:47.\n",
            "  Batch 23040  of  27729.    Elapsed: 00:47:52.\n",
            "  Batch 23080  of  27729.    Elapsed: 00:47:57.\n",
            "  Batch 23120  of  27729.    Elapsed: 00:48:02.\n",
            "  Batch 23160  of  27729.    Elapsed: 00:48:06.\n",
            "  Batch 23200  of  27729.    Elapsed: 00:48:11.\n",
            "  Batch 23240  of  27729.    Elapsed: 00:48:16.\n",
            "  Batch 23280  of  27729.    Elapsed: 00:48:21.\n",
            "  Batch 23320  of  27729.    Elapsed: 00:48:26.\n",
            "  Batch 23360  of  27729.    Elapsed: 00:48:31.\n",
            "  Batch 23400  of  27729.    Elapsed: 00:48:36.\n",
            "  Batch 23440  of  27729.    Elapsed: 00:48:41.\n",
            "  Batch 23480  of  27729.    Elapsed: 00:48:46.\n",
            "  Batch 23520  of  27729.    Elapsed: 00:48:51.\n",
            "  Batch 23560  of  27729.    Elapsed: 00:48:56.\n",
            "  Batch 23600  of  27729.    Elapsed: 00:49:01.\n",
            "  Batch 23640  of  27729.    Elapsed: 00:49:06.\n",
            "  Batch 23680  of  27729.    Elapsed: 00:49:11.\n",
            "  Batch 23720  of  27729.    Elapsed: 00:49:16.\n",
            "  Batch 23760  of  27729.    Elapsed: 00:49:21.\n",
            "  Batch 23800  of  27729.    Elapsed: 00:49:26.\n",
            "  Batch 23840  of  27729.    Elapsed: 00:49:31.\n",
            "  Batch 23880  of  27729.    Elapsed: 00:49:36.\n",
            "  Batch 23920  of  27729.    Elapsed: 00:49:41.\n",
            "  Batch 23960  of  27729.    Elapsed: 00:49:46.\n",
            "  Batch 24000  of  27729.    Elapsed: 00:49:51.\n",
            "  Batch 24040  of  27729.    Elapsed: 00:49:56.\n",
            "  Batch 24080  of  27729.    Elapsed: 00:50:01.\n",
            "  Batch 24120  of  27729.    Elapsed: 00:50:06.\n",
            "  Batch 24160  of  27729.    Elapsed: 00:50:11.\n",
            "  Batch 24200  of  27729.    Elapsed: 00:50:16.\n",
            "  Batch 24240  of  27729.    Elapsed: 00:50:21.\n",
            "  Batch 24280  of  27729.    Elapsed: 00:50:26.\n",
            "  Batch 24320  of  27729.    Elapsed: 00:50:31.\n",
            "  Batch 24360  of  27729.    Elapsed: 00:50:36.\n",
            "  Batch 24400  of  27729.    Elapsed: 00:50:41.\n",
            "  Batch 24440  of  27729.    Elapsed: 00:50:46.\n",
            "  Batch 24480  of  27729.    Elapsed: 00:50:51.\n",
            "  Batch 24520  of  27729.    Elapsed: 00:50:56.\n",
            "  Batch 24560  of  27729.    Elapsed: 00:51:01.\n",
            "  Batch 24600  of  27729.    Elapsed: 00:51:06.\n",
            "  Batch 24640  of  27729.    Elapsed: 00:51:11.\n",
            "  Batch 24680  of  27729.    Elapsed: 00:51:16.\n",
            "  Batch 24720  of  27729.    Elapsed: 00:51:21.\n",
            "  Batch 24760  of  27729.    Elapsed: 00:51:26.\n",
            "  Batch 24800  of  27729.    Elapsed: 00:51:31.\n",
            "  Batch 24840  of  27729.    Elapsed: 00:51:36.\n",
            "  Batch 24880  of  27729.    Elapsed: 00:51:41.\n",
            "  Batch 24920  of  27729.    Elapsed: 00:51:46.\n",
            "  Batch 24960  of  27729.    Elapsed: 00:51:51.\n",
            "  Batch 25000  of  27729.    Elapsed: 00:51:56.\n",
            "  Batch 25040  of  27729.    Elapsed: 00:52:01.\n",
            "  Batch 25080  of  27729.    Elapsed: 00:52:06.\n",
            "  Batch 25120  of  27729.    Elapsed: 00:52:11.\n",
            "  Batch 25160  of  27729.    Elapsed: 00:52:16.\n",
            "  Batch 25200  of  27729.    Elapsed: 00:52:21.\n",
            "  Batch 25240  of  27729.    Elapsed: 00:52:26.\n",
            "  Batch 25280  of  27729.    Elapsed: 00:52:31.\n",
            "  Batch 25320  of  27729.    Elapsed: 00:52:36.\n",
            "  Batch 25360  of  27729.    Elapsed: 00:52:41.\n",
            "  Batch 25400  of  27729.    Elapsed: 00:52:46.\n",
            "  Batch 25440  of  27729.    Elapsed: 00:52:51.\n",
            "  Batch 25480  of  27729.    Elapsed: 00:52:56.\n",
            "  Batch 25520  of  27729.    Elapsed: 00:53:01.\n",
            "  Batch 25560  of  27729.    Elapsed: 00:53:06.\n",
            "  Batch 25600  of  27729.    Elapsed: 00:53:11.\n",
            "  Batch 25640  of  27729.    Elapsed: 00:53:16.\n",
            "  Batch 25680  of  27729.    Elapsed: 00:53:21.\n",
            "  Batch 25720  of  27729.    Elapsed: 00:53:26.\n",
            "  Batch 25760  of  27729.    Elapsed: 00:53:31.\n",
            "  Batch 25800  of  27729.    Elapsed: 00:53:36.\n",
            "  Batch 25840  of  27729.    Elapsed: 00:53:41.\n",
            "  Batch 25880  of  27729.    Elapsed: 00:53:46.\n",
            "  Batch 25920  of  27729.    Elapsed: 00:53:50.\n",
            "  Batch 25960  of  27729.    Elapsed: 00:53:55.\n",
            "  Batch 26000  of  27729.    Elapsed: 00:54:00.\n",
            "  Batch 26040  of  27729.    Elapsed: 00:54:05.\n",
            "  Batch 26080  of  27729.    Elapsed: 00:54:10.\n",
            "  Batch 26120  of  27729.    Elapsed: 00:54:15.\n",
            "  Batch 26160  of  27729.    Elapsed: 00:54:20.\n",
            "  Batch 26200  of  27729.    Elapsed: 00:54:25.\n",
            "  Batch 26240  of  27729.    Elapsed: 00:54:30.\n",
            "  Batch 26280  of  27729.    Elapsed: 00:54:35.\n",
            "  Batch 26320  of  27729.    Elapsed: 00:54:40.\n",
            "  Batch 26360  of  27729.    Elapsed: 00:54:45.\n",
            "  Batch 26400  of  27729.    Elapsed: 00:54:50.\n",
            "  Batch 26440  of  27729.    Elapsed: 00:54:55.\n",
            "  Batch 26480  of  27729.    Elapsed: 00:55:00.\n",
            "  Batch 26520  of  27729.    Elapsed: 00:55:05.\n",
            "  Batch 26560  of  27729.    Elapsed: 00:55:10.\n",
            "  Batch 26600  of  27729.    Elapsed: 00:55:15.\n",
            "  Batch 26640  of  27729.    Elapsed: 00:55:20.\n",
            "  Batch 26680  of  27729.    Elapsed: 00:55:25.\n",
            "  Batch 26720  of  27729.    Elapsed: 00:55:30.\n",
            "  Batch 26760  of  27729.    Elapsed: 00:55:35.\n",
            "  Batch 26800  of  27729.    Elapsed: 00:55:40.\n",
            "  Batch 26840  of  27729.    Elapsed: 00:55:45.\n",
            "  Batch 26880  of  27729.    Elapsed: 00:55:50.\n",
            "  Batch 26920  of  27729.    Elapsed: 00:55:55.\n",
            "  Batch 26960  of  27729.    Elapsed: 00:56:00.\n",
            "  Batch 27000  of  27729.    Elapsed: 00:56:05.\n",
            "  Batch 27040  of  27729.    Elapsed: 00:56:10.\n",
            "  Batch 27080  of  27729.    Elapsed: 00:56:15.\n",
            "  Batch 27120  of  27729.    Elapsed: 00:56:20.\n",
            "  Batch 27160  of  27729.    Elapsed: 00:56:25.\n",
            "  Batch 27200  of  27729.    Elapsed: 00:56:30.\n",
            "  Batch 27240  of  27729.    Elapsed: 00:56:35.\n",
            "  Batch 27280  of  27729.    Elapsed: 00:56:40.\n",
            "  Batch 27320  of  27729.    Elapsed: 00:56:45.\n",
            "  Batch 27360  of  27729.    Elapsed: 00:56:50.\n",
            "  Batch 27400  of  27729.    Elapsed: 00:56:55.\n",
            "  Batch 27440  of  27729.    Elapsed: 00:57:00.\n",
            "  Batch 27480  of  27729.    Elapsed: 00:57:05.\n",
            "  Batch 27520  of  27729.    Elapsed: 00:57:10.\n",
            "  Batch 27560  of  27729.    Elapsed: 00:57:15.\n",
            "  Batch 27600  of  27729.    Elapsed: 00:57:20.\n",
            "  Batch 27640  of  27729.    Elapsed: 00:57:25.\n",
            "  Batch 27680  of  27729.    Elapsed: 00:57:30.\n",
            "  Batch 27720  of  27729.    Elapsed: 00:57:35.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 00:57:36\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch 40  of  27729.    Elapsed: 00:00:05.\n",
            "  Batch 80  of  27729.    Elapsed: 00:00:10.\n",
            "  Batch 120  of  27729.    Elapsed: 00:00:15.\n",
            "  Batch 160  of  27729.    Elapsed: 00:00:20.\n",
            "  Batch 200  of  27729.    Elapsed: 00:00:25.\n",
            "  Batch 240  of  27729.    Elapsed: 00:00:30.\n",
            "  Batch 280  of  27729.    Elapsed: 00:00:35.\n",
            "  Batch 320  of  27729.    Elapsed: 00:00:40.\n",
            "  Batch 360  of  27729.    Elapsed: 00:00:45.\n",
            "  Batch 400  of  27729.    Elapsed: 00:00:50.\n",
            "  Batch 440  of  27729.    Elapsed: 00:00:55.\n",
            "  Batch 480  of  27729.    Elapsed: 00:01:00.\n",
            "  Batch 520  of  27729.    Elapsed: 00:01:05.\n",
            "  Batch 560  of  27729.    Elapsed: 00:01:10.\n",
            "  Batch 600  of  27729.    Elapsed: 00:01:15.\n",
            "  Batch 640  of  27729.    Elapsed: 00:01:20.\n",
            "  Batch 680  of  27729.    Elapsed: 00:01:25.\n",
            "  Batch 720  of  27729.    Elapsed: 00:01:30.\n",
            "  Batch 760  of  27729.    Elapsed: 00:01:35.\n",
            "  Batch 800  of  27729.    Elapsed: 00:01:40.\n",
            "  Batch 840  of  27729.    Elapsed: 00:01:45.\n",
            "  Batch 880  of  27729.    Elapsed: 00:01:50.\n",
            "  Batch 920  of  27729.    Elapsed: 00:01:55.\n",
            "  Batch 960  of  27729.    Elapsed: 00:02:00.\n",
            "  Batch 1000  of  27729.    Elapsed: 00:02:05.\n",
            "  Batch 1040  of  27729.    Elapsed: 00:02:10.\n",
            "  Batch 1080  of  27729.    Elapsed: 00:02:15.\n",
            "  Batch 1120  of  27729.    Elapsed: 00:02:20.\n",
            "  Batch 1160  of  27729.    Elapsed: 00:02:25.\n",
            "  Batch 1200  of  27729.    Elapsed: 00:02:30.\n",
            "  Batch 1240  of  27729.    Elapsed: 00:02:35.\n",
            "  Batch 1280  of  27729.    Elapsed: 00:02:40.\n",
            "  Batch 1320  of  27729.    Elapsed: 00:02:45.\n",
            "  Batch 1360  of  27729.    Elapsed: 00:02:49.\n",
            "  Batch 1400  of  27729.    Elapsed: 00:02:54.\n",
            "  Batch 1440  of  27729.    Elapsed: 00:02:59.\n",
            "  Batch 1480  of  27729.    Elapsed: 00:03:04.\n",
            "  Batch 1520  of  27729.    Elapsed: 00:03:09.\n",
            "  Batch 1560  of  27729.    Elapsed: 00:03:14.\n",
            "  Batch 1600  of  27729.    Elapsed: 00:03:19.\n",
            "  Batch 1640  of  27729.    Elapsed: 00:03:24.\n",
            "  Batch 1680  of  27729.    Elapsed: 00:03:29.\n",
            "  Batch 1720  of  27729.    Elapsed: 00:03:34.\n",
            "  Batch 1760  of  27729.    Elapsed: 00:03:39.\n",
            "  Batch 1800  of  27729.    Elapsed: 00:03:44.\n",
            "  Batch 1840  of  27729.    Elapsed: 00:03:49.\n",
            "  Batch 1880  of  27729.    Elapsed: 00:03:54.\n",
            "  Batch 1920  of  27729.    Elapsed: 00:03:59.\n",
            "  Batch 1960  of  27729.    Elapsed: 00:04:04.\n",
            "  Batch 2000  of  27729.    Elapsed: 00:04:09.\n",
            "  Batch 2040  of  27729.    Elapsed: 00:04:14.\n",
            "  Batch 2080  of  27729.    Elapsed: 00:04:19.\n",
            "  Batch 2120  of  27729.    Elapsed: 00:04:24.\n",
            "  Batch 2160  of  27729.    Elapsed: 00:04:29.\n",
            "  Batch 2200  of  27729.    Elapsed: 00:04:34.\n",
            "  Batch 2240  of  27729.    Elapsed: 00:04:39.\n",
            "  Batch 2280  of  27729.    Elapsed: 00:04:44.\n",
            "  Batch 2320  of  27729.    Elapsed: 00:04:49.\n",
            "  Batch 2360  of  27729.    Elapsed: 00:04:54.\n",
            "  Batch 2400  of  27729.    Elapsed: 00:04:59.\n",
            "  Batch 2440  of  27729.    Elapsed: 00:05:04.\n",
            "  Batch 2480  of  27729.    Elapsed: 00:05:09.\n",
            "  Batch 2520  of  27729.    Elapsed: 00:05:14.\n",
            "  Batch 2560  of  27729.    Elapsed: 00:05:19.\n",
            "  Batch 2600  of  27729.    Elapsed: 00:05:24.\n",
            "  Batch 2640  of  27729.    Elapsed: 00:05:29.\n",
            "  Batch 2680  of  27729.    Elapsed: 00:05:34.\n",
            "  Batch 2720  of  27729.    Elapsed: 00:05:39.\n",
            "  Batch 2760  of  27729.    Elapsed: 00:05:44.\n",
            "  Batch 2800  of  27729.    Elapsed: 00:05:49.\n",
            "  Batch 2840  of  27729.    Elapsed: 00:05:54.\n",
            "  Batch 2880  of  27729.    Elapsed: 00:05:59.\n",
            "  Batch 2920  of  27729.    Elapsed: 00:06:04.\n",
            "  Batch 2960  of  27729.    Elapsed: 00:06:09.\n",
            "  Batch 3000  of  27729.    Elapsed: 00:06:14.\n",
            "  Batch 3040  of  27729.    Elapsed: 00:06:19.\n",
            "  Batch 3080  of  27729.    Elapsed: 00:06:24.\n",
            "  Batch 3120  of  27729.    Elapsed: 00:06:29.\n",
            "  Batch 3160  of  27729.    Elapsed: 00:06:34.\n",
            "  Batch 3200  of  27729.    Elapsed: 00:06:39.\n",
            "  Batch 3240  of  27729.    Elapsed: 00:06:44.\n",
            "  Batch 3280  of  27729.    Elapsed: 00:06:49.\n",
            "  Batch 3320  of  27729.    Elapsed: 00:06:54.\n",
            "  Batch 3360  of  27729.    Elapsed: 00:06:59.\n",
            "  Batch 3400  of  27729.    Elapsed: 00:07:04.\n",
            "  Batch 3440  of  27729.    Elapsed: 00:07:09.\n",
            "  Batch 3480  of  27729.    Elapsed: 00:07:14.\n",
            "  Batch 3520  of  27729.    Elapsed: 00:07:19.\n",
            "  Batch 3560  of  27729.    Elapsed: 00:07:24.\n",
            "  Batch 3600  of  27729.    Elapsed: 00:07:29.\n",
            "  Batch 3640  of  27729.    Elapsed: 00:07:34.\n",
            "  Batch 3680  of  27729.    Elapsed: 00:07:39.\n",
            "  Batch 3720  of  27729.    Elapsed: 00:07:44.\n",
            "  Batch 3760  of  27729.    Elapsed: 00:07:49.\n",
            "  Batch 3800  of  27729.    Elapsed: 00:07:54.\n",
            "  Batch 3840  of  27729.    Elapsed: 00:07:59.\n",
            "  Batch 3880  of  27729.    Elapsed: 00:08:04.\n",
            "  Batch 3920  of  27729.    Elapsed: 00:08:09.\n",
            "  Batch 3960  of  27729.    Elapsed: 00:08:14.\n",
            "  Batch 4000  of  27729.    Elapsed: 00:08:19.\n",
            "  Batch 4040  of  27729.    Elapsed: 00:08:24.\n",
            "  Batch 4080  of  27729.    Elapsed: 00:08:29.\n",
            "  Batch 4120  of  27729.    Elapsed: 00:08:34.\n",
            "  Batch 4160  of  27729.    Elapsed: 00:08:39.\n",
            "  Batch 4200  of  27729.    Elapsed: 00:08:44.\n",
            "  Batch 4240  of  27729.    Elapsed: 00:08:49.\n",
            "  Batch 4280  of  27729.    Elapsed: 00:08:54.\n",
            "  Batch 4320  of  27729.    Elapsed: 00:08:59.\n",
            "  Batch 4360  of  27729.    Elapsed: 00:09:04.\n",
            "  Batch 4400  of  27729.    Elapsed: 00:09:09.\n",
            "  Batch 4440  of  27729.    Elapsed: 00:09:14.\n",
            "  Batch 4480  of  27729.    Elapsed: 00:09:18.\n",
            "  Batch 4520  of  27729.    Elapsed: 00:09:23.\n",
            "  Batch 4560  of  27729.    Elapsed: 00:09:28.\n",
            "  Batch 4600  of  27729.    Elapsed: 00:09:33.\n",
            "  Batch 4640  of  27729.    Elapsed: 00:09:38.\n",
            "  Batch 4680  of  27729.    Elapsed: 00:09:43.\n",
            "  Batch 4720  of  27729.    Elapsed: 00:09:48.\n",
            "  Batch 4760  of  27729.    Elapsed: 00:09:53.\n",
            "  Batch 4800  of  27729.    Elapsed: 00:09:58.\n",
            "  Batch 4840  of  27729.    Elapsed: 00:10:03.\n",
            "  Batch 4880  of  27729.    Elapsed: 00:10:08.\n",
            "  Batch 4920  of  27729.    Elapsed: 00:10:13.\n",
            "  Batch 4960  of  27729.    Elapsed: 00:10:18.\n",
            "  Batch 5000  of  27729.    Elapsed: 00:10:23.\n",
            "  Batch 5040  of  27729.    Elapsed: 00:10:28.\n",
            "  Batch 5080  of  27729.    Elapsed: 00:10:33.\n",
            "  Batch 5120  of  27729.    Elapsed: 00:10:38.\n",
            "  Batch 5160  of  27729.    Elapsed: 00:10:43.\n",
            "  Batch 5200  of  27729.    Elapsed: 00:10:48.\n",
            "  Batch 5240  of  27729.    Elapsed: 00:10:53.\n",
            "  Batch 5280  of  27729.    Elapsed: 00:10:58.\n",
            "  Batch 5320  of  27729.    Elapsed: 00:11:03.\n",
            "  Batch 5360  of  27729.    Elapsed: 00:11:08.\n",
            "  Batch 5400  of  27729.    Elapsed: 00:11:13.\n",
            "  Batch 5440  of  27729.    Elapsed: 00:11:18.\n",
            "  Batch 5480  of  27729.    Elapsed: 00:11:23.\n",
            "  Batch 5520  of  27729.    Elapsed: 00:11:28.\n",
            "  Batch 5560  of  27729.    Elapsed: 00:11:33.\n",
            "  Batch 5600  of  27729.    Elapsed: 00:11:38.\n",
            "  Batch 5640  of  27729.    Elapsed: 00:11:43.\n",
            "  Batch 5680  of  27729.    Elapsed: 00:11:48.\n",
            "  Batch 5720  of  27729.    Elapsed: 00:11:53.\n",
            "  Batch 5760  of  27729.    Elapsed: 00:11:58.\n",
            "  Batch 5800  of  27729.    Elapsed: 00:12:03.\n",
            "  Batch 5840  of  27729.    Elapsed: 00:12:08.\n",
            "  Batch 5880  of  27729.    Elapsed: 00:12:13.\n",
            "  Batch 5920  of  27729.    Elapsed: 00:12:18.\n",
            "  Batch 5960  of  27729.    Elapsed: 00:12:23.\n",
            "  Batch 6000  of  27729.    Elapsed: 00:12:28.\n",
            "  Batch 6040  of  27729.    Elapsed: 00:12:33.\n",
            "  Batch 6080  of  27729.    Elapsed: 00:12:38.\n",
            "  Batch 6120  of  27729.    Elapsed: 00:12:43.\n",
            "  Batch 6160  of  27729.    Elapsed: 00:12:48.\n",
            "  Batch 6200  of  27729.    Elapsed: 00:12:53.\n",
            "  Batch 6240  of  27729.    Elapsed: 00:12:58.\n",
            "  Batch 6280  of  27729.    Elapsed: 00:13:03.\n",
            "  Batch 6320  of  27729.    Elapsed: 00:13:08.\n",
            "  Batch 6360  of  27729.    Elapsed: 00:13:13.\n",
            "  Batch 6400  of  27729.    Elapsed: 00:13:18.\n",
            "  Batch 6440  of  27729.    Elapsed: 00:13:23.\n",
            "  Batch 6480  of  27729.    Elapsed: 00:13:28.\n",
            "  Batch 6520  of  27729.    Elapsed: 00:13:33.\n",
            "  Batch 6560  of  27729.    Elapsed: 00:13:38.\n",
            "  Batch 6600  of  27729.    Elapsed: 00:13:43.\n",
            "  Batch 6640  of  27729.    Elapsed: 00:13:48.\n",
            "  Batch 6680  of  27729.    Elapsed: 00:13:53.\n",
            "  Batch 6720  of  27729.    Elapsed: 00:13:58.\n",
            "  Batch 6760  of  27729.    Elapsed: 00:14:03.\n",
            "  Batch 6800  of  27729.    Elapsed: 00:14:08.\n",
            "  Batch 6840  of  27729.    Elapsed: 00:14:13.\n",
            "  Batch 6880  of  27729.    Elapsed: 00:14:18.\n",
            "  Batch 6920  of  27729.    Elapsed: 00:14:23.\n",
            "  Batch 6960  of  27729.    Elapsed: 00:14:28.\n",
            "  Batch 7000  of  27729.    Elapsed: 00:14:33.\n",
            "  Batch 7040  of  27729.    Elapsed: 00:14:38.\n",
            "  Batch 7080  of  27729.    Elapsed: 00:14:43.\n",
            "  Batch 7120  of  27729.    Elapsed: 00:14:48.\n",
            "  Batch 7160  of  27729.    Elapsed: 00:14:53.\n",
            "  Batch 7200  of  27729.    Elapsed: 00:14:58.\n",
            "  Batch 7240  of  27729.    Elapsed: 00:15:03.\n",
            "  Batch 7280  of  27729.    Elapsed: 00:15:08.\n",
            "  Batch 7320  of  27729.    Elapsed: 00:15:13.\n",
            "  Batch 7360  of  27729.    Elapsed: 00:15:18.\n",
            "  Batch 7400  of  27729.    Elapsed: 00:15:23.\n",
            "  Batch 7440  of  27729.    Elapsed: 00:15:28.\n",
            "  Batch 7480  of  27729.    Elapsed: 00:15:33.\n",
            "  Batch 7520  of  27729.    Elapsed: 00:15:38.\n",
            "  Batch 7560  of  27729.    Elapsed: 00:15:42.\n",
            "  Batch 7600  of  27729.    Elapsed: 00:15:47.\n",
            "  Batch 7640  of  27729.    Elapsed: 00:15:52.\n",
            "  Batch 7680  of  27729.    Elapsed: 00:15:57.\n",
            "  Batch 7720  of  27729.    Elapsed: 00:16:02.\n",
            "  Batch 7760  of  27729.    Elapsed: 00:16:07.\n",
            "  Batch 7800  of  27729.    Elapsed: 00:16:12.\n",
            "  Batch 7840  of  27729.    Elapsed: 00:16:17.\n",
            "  Batch 7880  of  27729.    Elapsed: 00:16:22.\n",
            "  Batch 7920  of  27729.    Elapsed: 00:16:27.\n",
            "  Batch 7960  of  27729.    Elapsed: 00:16:32.\n",
            "  Batch 8000  of  27729.    Elapsed: 00:16:37.\n",
            "  Batch 8040  of  27729.    Elapsed: 00:16:42.\n",
            "  Batch 8080  of  27729.    Elapsed: 00:16:47.\n",
            "  Batch 8120  of  27729.    Elapsed: 00:16:52.\n",
            "  Batch 8160  of  27729.    Elapsed: 00:16:57.\n",
            "  Batch 8200  of  27729.    Elapsed: 00:17:02.\n",
            "  Batch 8240  of  27729.    Elapsed: 00:17:07.\n",
            "  Batch 8280  of  27729.    Elapsed: 00:17:12.\n",
            "  Batch 8320  of  27729.    Elapsed: 00:17:17.\n",
            "  Batch 8360  of  27729.    Elapsed: 00:17:22.\n",
            "  Batch 8400  of  27729.    Elapsed: 00:17:27.\n",
            "  Batch 8440  of  27729.    Elapsed: 00:17:32.\n",
            "  Batch 8480  of  27729.    Elapsed: 00:17:37.\n",
            "  Batch 8520  of  27729.    Elapsed: 00:17:42.\n",
            "  Batch 8560  of  27729.    Elapsed: 00:17:47.\n",
            "  Batch 8600  of  27729.    Elapsed: 00:17:52.\n",
            "  Batch 8640  of  27729.    Elapsed: 00:17:57.\n",
            "  Batch 8680  of  27729.    Elapsed: 00:18:02.\n",
            "  Batch 8720  of  27729.    Elapsed: 00:18:07.\n",
            "  Batch 8760  of  27729.    Elapsed: 00:18:12.\n",
            "  Batch 8800  of  27729.    Elapsed: 00:18:17.\n",
            "  Batch 8840  of  27729.    Elapsed: 00:18:22.\n",
            "  Batch 8880  of  27729.    Elapsed: 00:18:27.\n",
            "  Batch 8920  of  27729.    Elapsed: 00:18:32.\n",
            "  Batch 8960  of  27729.    Elapsed: 00:18:37.\n",
            "  Batch 9000  of  27729.    Elapsed: 00:18:42.\n",
            "  Batch 9040  of  27729.    Elapsed: 00:18:47.\n",
            "  Batch 9080  of  27729.    Elapsed: 00:18:52.\n",
            "  Batch 9120  of  27729.    Elapsed: 00:18:57.\n",
            "  Batch 9160  of  27729.    Elapsed: 00:19:02.\n",
            "  Batch 9200  of  27729.    Elapsed: 00:19:07.\n",
            "  Batch 9240  of  27729.    Elapsed: 00:19:12.\n",
            "  Batch 9280  of  27729.    Elapsed: 00:19:17.\n",
            "  Batch 9320  of  27729.    Elapsed: 00:19:22.\n",
            "  Batch 9360  of  27729.    Elapsed: 00:19:27.\n",
            "  Batch 9400  of  27729.    Elapsed: 00:19:32.\n",
            "  Batch 9440  of  27729.    Elapsed: 00:19:37.\n",
            "  Batch 9480  of  27729.    Elapsed: 00:19:42.\n",
            "  Batch 9520  of  27729.    Elapsed: 00:19:47.\n",
            "  Batch 9560  of  27729.    Elapsed: 00:19:52.\n",
            "  Batch 9600  of  27729.    Elapsed: 00:19:57.\n",
            "  Batch 9640  of  27729.    Elapsed: 00:20:02.\n",
            "  Batch 9680  of  27729.    Elapsed: 00:20:07.\n",
            "  Batch 9720  of  27729.    Elapsed: 00:20:12.\n",
            "  Batch 9760  of  27729.    Elapsed: 00:20:17.\n",
            "  Batch 9800  of  27729.    Elapsed: 00:20:22.\n",
            "  Batch 9840  of  27729.    Elapsed: 00:20:27.\n",
            "  Batch 9880  of  27729.    Elapsed: 00:20:32.\n",
            "  Batch 9920  of  27729.    Elapsed: 00:20:37.\n",
            "  Batch 9960  of  27729.    Elapsed: 00:20:42.\n",
            "  Batch 10000  of  27729.    Elapsed: 00:20:47.\n",
            "  Batch 10040  of  27729.    Elapsed: 00:20:52.\n",
            "  Batch 10080  of  27729.    Elapsed: 00:20:57.\n",
            "  Batch 10120  of  27729.    Elapsed: 00:21:02.\n",
            "  Batch 10160  of  27729.    Elapsed: 00:21:06.\n",
            "  Batch 10200  of  27729.    Elapsed: 00:21:11.\n",
            "  Batch 10240  of  27729.    Elapsed: 00:21:16.\n",
            "  Batch 10280  of  27729.    Elapsed: 00:21:21.\n",
            "  Batch 10320  of  27729.    Elapsed: 00:21:26.\n",
            "  Batch 10360  of  27729.    Elapsed: 00:21:31.\n",
            "  Batch 10400  of  27729.    Elapsed: 00:21:36.\n",
            "  Batch 10440  of  27729.    Elapsed: 00:21:41.\n",
            "  Batch 10480  of  27729.    Elapsed: 00:21:46.\n",
            "  Batch 10520  of  27729.    Elapsed: 00:21:51.\n",
            "  Batch 10560  of  27729.    Elapsed: 00:21:56.\n",
            "  Batch 10600  of  27729.    Elapsed: 00:22:01.\n",
            "  Batch 10640  of  27729.    Elapsed: 00:22:06.\n",
            "  Batch 10680  of  27729.    Elapsed: 00:22:11.\n",
            "  Batch 10720  of  27729.    Elapsed: 00:22:16.\n",
            "  Batch 10760  of  27729.    Elapsed: 00:22:21.\n",
            "  Batch 10800  of  27729.    Elapsed: 00:22:26.\n",
            "  Batch 10840  of  27729.    Elapsed: 00:22:31.\n",
            "  Batch 10880  of  27729.    Elapsed: 00:22:36.\n",
            "  Batch 10920  of  27729.    Elapsed: 00:22:41.\n",
            "  Batch 10960  of  27729.    Elapsed: 00:22:46.\n",
            "  Batch 11000  of  27729.    Elapsed: 00:22:51.\n",
            "  Batch 11040  of  27729.    Elapsed: 00:22:56.\n",
            "  Batch 11080  of  27729.    Elapsed: 00:23:01.\n",
            "  Batch 11120  of  27729.    Elapsed: 00:23:06.\n",
            "  Batch 11160  of  27729.    Elapsed: 00:23:11.\n",
            "  Batch 11200  of  27729.    Elapsed: 00:23:16.\n",
            "  Batch 11240  of  27729.    Elapsed: 00:23:21.\n",
            "  Batch 11280  of  27729.    Elapsed: 00:23:26.\n",
            "  Batch 11320  of  27729.    Elapsed: 00:23:31.\n",
            "  Batch 11360  of  27729.    Elapsed: 00:23:36.\n",
            "  Batch 11400  of  27729.    Elapsed: 00:23:41.\n",
            "  Batch 11440  of  27729.    Elapsed: 00:23:46.\n",
            "  Batch 11480  of  27729.    Elapsed: 00:23:51.\n",
            "  Batch 11520  of  27729.    Elapsed: 00:23:56.\n",
            "  Batch 11560  of  27729.    Elapsed: 00:24:01.\n",
            "  Batch 11600  of  27729.    Elapsed: 00:24:06.\n",
            "  Batch 11640  of  27729.    Elapsed: 00:24:11.\n",
            "  Batch 11680  of  27729.    Elapsed: 00:24:16.\n",
            "  Batch 11720  of  27729.    Elapsed: 00:24:21.\n",
            "  Batch 11760  of  27729.    Elapsed: 00:24:26.\n",
            "  Batch 11800  of  27729.    Elapsed: 00:24:31.\n",
            "  Batch 11840  of  27729.    Elapsed: 00:24:36.\n",
            "  Batch 11880  of  27729.    Elapsed: 00:24:41.\n",
            "  Batch 11920  of  27729.    Elapsed: 00:24:46.\n",
            "  Batch 11960  of  27729.    Elapsed: 00:24:51.\n",
            "  Batch 12000  of  27729.    Elapsed: 00:24:56.\n",
            "  Batch 12040  of  27729.    Elapsed: 00:25:01.\n",
            "  Batch 12080  of  27729.    Elapsed: 00:25:06.\n",
            "  Batch 12120  of  27729.    Elapsed: 00:25:11.\n",
            "  Batch 12160  of  27729.    Elapsed: 00:25:16.\n",
            "  Batch 12200  of  27729.    Elapsed: 00:25:21.\n",
            "  Batch 12240  of  27729.    Elapsed: 00:25:26.\n",
            "  Batch 12280  of  27729.    Elapsed: 00:25:31.\n",
            "  Batch 12320  of  27729.    Elapsed: 00:25:36.\n",
            "  Batch 12360  of  27729.    Elapsed: 00:25:41.\n",
            "  Batch 12400  of  27729.    Elapsed: 00:25:46.\n",
            "  Batch 12440  of  27729.    Elapsed: 00:25:51.\n",
            "  Batch 12480  of  27729.    Elapsed: 00:25:56.\n",
            "  Batch 12520  of  27729.    Elapsed: 00:26:01.\n",
            "  Batch 12560  of  27729.    Elapsed: 00:26:06.\n",
            "  Batch 12600  of  27729.    Elapsed: 00:26:11.\n",
            "  Batch 12640  of  27729.    Elapsed: 00:26:16.\n",
            "  Batch 12680  of  27729.    Elapsed: 00:26:21.\n",
            "  Batch 12720  of  27729.    Elapsed: 00:26:26.\n",
            "  Batch 12760  of  27729.    Elapsed: 00:26:31.\n",
            "  Batch 12800  of  27729.    Elapsed: 00:26:36.\n",
            "  Batch 12840  of  27729.    Elapsed: 00:26:41.\n",
            "  Batch 12880  of  27729.    Elapsed: 00:26:46.\n",
            "  Batch 12920  of  27729.    Elapsed: 00:26:51.\n",
            "  Batch 12960  of  27729.    Elapsed: 00:26:55.\n",
            "  Batch 13000  of  27729.    Elapsed: 00:27:00.\n",
            "  Batch 13040  of  27729.    Elapsed: 00:27:05.\n",
            "  Batch 13080  of  27729.    Elapsed: 00:27:10.\n",
            "  Batch 13120  of  27729.    Elapsed: 00:27:15.\n",
            "  Batch 13160  of  27729.    Elapsed: 00:27:20.\n",
            "  Batch 13200  of  27729.    Elapsed: 00:27:25.\n",
            "  Batch 13240  of  27729.    Elapsed: 00:27:30.\n",
            "  Batch 13280  of  27729.    Elapsed: 00:27:35.\n",
            "  Batch 13320  of  27729.    Elapsed: 00:27:40.\n",
            "  Batch 13360  of  27729.    Elapsed: 00:27:45.\n",
            "  Batch 13400  of  27729.    Elapsed: 00:27:50.\n",
            "  Batch 13440  of  27729.    Elapsed: 00:27:55.\n",
            "  Batch 13480  of  27729.    Elapsed: 00:28:00.\n",
            "  Batch 13520  of  27729.    Elapsed: 00:28:05.\n",
            "  Batch 13560  of  27729.    Elapsed: 00:28:10.\n",
            "  Batch 13600  of  27729.    Elapsed: 00:28:15.\n",
            "  Batch 13640  of  27729.    Elapsed: 00:28:20.\n",
            "  Batch 13680  of  27729.    Elapsed: 00:28:25.\n",
            "  Batch 13720  of  27729.    Elapsed: 00:28:30.\n",
            "  Batch 13760  of  27729.    Elapsed: 00:28:35.\n",
            "  Batch 13800  of  27729.    Elapsed: 00:28:40.\n",
            "  Batch 13840  of  27729.    Elapsed: 00:28:45.\n",
            "  Batch 13880  of  27729.    Elapsed: 00:28:50.\n",
            "  Batch 13920  of  27729.    Elapsed: 00:28:55.\n",
            "  Batch 13960  of  27729.    Elapsed: 00:29:00.\n",
            "  Batch 14000  of  27729.    Elapsed: 00:29:05.\n",
            "  Batch 14040  of  27729.    Elapsed: 00:29:10.\n",
            "  Batch 14080  of  27729.    Elapsed: 00:29:15.\n",
            "  Batch 14120  of  27729.    Elapsed: 00:29:20.\n",
            "  Batch 14160  of  27729.    Elapsed: 00:29:25.\n",
            "  Batch 14200  of  27729.    Elapsed: 00:29:30.\n",
            "  Batch 14240  of  27729.    Elapsed: 00:29:35.\n",
            "  Batch 14280  of  27729.    Elapsed: 00:29:40.\n",
            "  Batch 14320  of  27729.    Elapsed: 00:29:45.\n",
            "  Batch 14360  of  27729.    Elapsed: 00:29:50.\n",
            "  Batch 14400  of  27729.    Elapsed: 00:29:55.\n",
            "  Batch 14440  of  27729.    Elapsed: 00:30:00.\n",
            "  Batch 14480  of  27729.    Elapsed: 00:30:05.\n",
            "  Batch 14520  of  27729.    Elapsed: 00:30:10.\n",
            "  Batch 14560  of  27729.    Elapsed: 00:30:15.\n",
            "  Batch 14600  of  27729.    Elapsed: 00:30:20.\n",
            "  Batch 14640  of  27729.    Elapsed: 00:30:25.\n",
            "  Batch 14680  of  27729.    Elapsed: 00:30:30.\n",
            "  Batch 14720  of  27729.    Elapsed: 00:30:35.\n",
            "  Batch 14760  of  27729.    Elapsed: 00:30:40.\n",
            "  Batch 14800  of  27729.    Elapsed: 00:30:45.\n",
            "  Batch 14840  of  27729.    Elapsed: 00:30:50.\n",
            "  Batch 14880  of  27729.    Elapsed: 00:30:55.\n",
            "  Batch 14920  of  27729.    Elapsed: 00:31:00.\n",
            "  Batch 14960  of  27729.    Elapsed: 00:31:05.\n",
            "  Batch 15000  of  27729.    Elapsed: 00:31:10.\n",
            "  Batch 15040  of  27729.    Elapsed: 00:31:15.\n",
            "  Batch 15080  of  27729.    Elapsed: 00:31:20.\n",
            "  Batch 15120  of  27729.    Elapsed: 00:31:25.\n",
            "  Batch 15160  of  27729.    Elapsed: 00:31:30.\n",
            "  Batch 15200  of  27729.    Elapsed: 00:31:35.\n",
            "  Batch 15240  of  27729.    Elapsed: 00:31:40.\n",
            "  Batch 15280  of  27729.    Elapsed: 00:31:45.\n",
            "  Batch 15320  of  27729.    Elapsed: 00:31:50.\n",
            "  Batch 15360  of  27729.    Elapsed: 00:31:55.\n",
            "  Batch 15400  of  27729.    Elapsed: 00:32:00.\n",
            "  Batch 15440  of  27729.    Elapsed: 00:32:05.\n",
            "  Batch 15480  of  27729.    Elapsed: 00:32:10.\n",
            "  Batch 15520  of  27729.    Elapsed: 00:32:15.\n",
            "  Batch 15560  of  27729.    Elapsed: 00:32:20.\n",
            "  Batch 15600  of  27729.    Elapsed: 00:32:25.\n",
            "  Batch 15640  of  27729.    Elapsed: 00:32:30.\n",
            "  Batch 15680  of  27729.    Elapsed: 00:32:34.\n",
            "  Batch 15720  of  27729.    Elapsed: 00:32:39.\n",
            "  Batch 15760  of  27729.    Elapsed: 00:32:44.\n",
            "  Batch 15800  of  27729.    Elapsed: 00:32:49.\n",
            "  Batch 15840  of  27729.    Elapsed: 00:32:54.\n",
            "  Batch 15880  of  27729.    Elapsed: 00:32:59.\n",
            "  Batch 15920  of  27729.    Elapsed: 00:33:04.\n",
            "  Batch 15960  of  27729.    Elapsed: 00:33:09.\n",
            "  Batch 16000  of  27729.    Elapsed: 00:33:14.\n",
            "  Batch 16040  of  27729.    Elapsed: 00:33:19.\n",
            "  Batch 16080  of  27729.    Elapsed: 00:33:24.\n",
            "  Batch 16120  of  27729.    Elapsed: 00:33:29.\n",
            "  Batch 16160  of  27729.    Elapsed: 00:33:34.\n",
            "  Batch 16200  of  27729.    Elapsed: 00:33:39.\n",
            "  Batch 16240  of  27729.    Elapsed: 00:33:44.\n",
            "  Batch 16280  of  27729.    Elapsed: 00:33:49.\n",
            "  Batch 16320  of  27729.    Elapsed: 00:33:54.\n",
            "  Batch 16360  of  27729.    Elapsed: 00:33:59.\n",
            "  Batch 16400  of  27729.    Elapsed: 00:34:04.\n",
            "  Batch 16440  of  27729.    Elapsed: 00:34:09.\n",
            "  Batch 16480  of  27729.    Elapsed: 00:34:14.\n",
            "  Batch 16520  of  27729.    Elapsed: 00:34:19.\n",
            "  Batch 16560  of  27729.    Elapsed: 00:34:24.\n",
            "  Batch 16600  of  27729.    Elapsed: 00:34:29.\n",
            "  Batch 16640  of  27729.    Elapsed: 00:34:34.\n",
            "  Batch 16680  of  27729.    Elapsed: 00:34:39.\n",
            "  Batch 16720  of  27729.    Elapsed: 00:34:44.\n",
            "  Batch 16760  of  27729.    Elapsed: 00:34:49.\n",
            "  Batch 16800  of  27729.    Elapsed: 00:34:54.\n",
            "  Batch 16840  of  27729.    Elapsed: 00:34:59.\n",
            "  Batch 16880  of  27729.    Elapsed: 00:35:04.\n",
            "  Batch 16920  of  27729.    Elapsed: 00:35:09.\n",
            "  Batch 16960  of  27729.    Elapsed: 00:35:14.\n",
            "  Batch 17000  of  27729.    Elapsed: 00:35:19.\n",
            "  Batch 17040  of  27729.    Elapsed: 00:35:24.\n",
            "  Batch 17080  of  27729.    Elapsed: 00:35:29.\n",
            "  Batch 17120  of  27729.    Elapsed: 00:35:34.\n",
            "  Batch 17160  of  27729.    Elapsed: 00:35:39.\n",
            "  Batch 17200  of  27729.    Elapsed: 00:35:44.\n",
            "  Batch 17240  of  27729.    Elapsed: 00:35:49.\n",
            "  Batch 17280  of  27729.    Elapsed: 00:35:54.\n",
            "  Batch 17320  of  27729.    Elapsed: 00:35:59.\n",
            "  Batch 17360  of  27729.    Elapsed: 00:36:04.\n",
            "  Batch 17400  of  27729.    Elapsed: 00:36:09.\n",
            "  Batch 17440  of  27729.    Elapsed: 00:36:14.\n",
            "  Batch 17480  of  27729.    Elapsed: 00:36:19.\n",
            "  Batch 17520  of  27729.    Elapsed: 00:36:24.\n",
            "  Batch 17560  of  27729.    Elapsed: 00:36:29.\n",
            "  Batch 17600  of  27729.    Elapsed: 00:36:34.\n",
            "  Batch 17640  of  27729.    Elapsed: 00:36:39.\n",
            "  Batch 17680  of  27729.    Elapsed: 00:36:44.\n",
            "  Batch 17720  of  27729.    Elapsed: 00:36:49.\n",
            "  Batch 17760  of  27729.    Elapsed: 00:36:54.\n",
            "  Batch 17800  of  27729.    Elapsed: 00:36:59.\n",
            "  Batch 17840  of  27729.    Elapsed: 00:37:04.\n",
            "  Batch 17880  of  27729.    Elapsed: 00:37:09.\n",
            "  Batch 17920  of  27729.    Elapsed: 00:37:14.\n",
            "  Batch 17960  of  27729.    Elapsed: 00:37:19.\n",
            "  Batch 18000  of  27729.    Elapsed: 00:37:24.\n",
            "  Batch 18040  of  27729.    Elapsed: 00:37:29.\n",
            "  Batch 18080  of  27729.    Elapsed: 00:37:34.\n",
            "  Batch 18120  of  27729.    Elapsed: 00:37:39.\n",
            "  Batch 18160  of  27729.    Elapsed: 00:37:44.\n",
            "  Batch 18200  of  27729.    Elapsed: 00:37:49.\n",
            "  Batch 18240  of  27729.    Elapsed: 00:37:54.\n",
            "  Batch 18280  of  27729.    Elapsed: 00:37:59.\n",
            "  Batch 18320  of  27729.    Elapsed: 00:38:04.\n",
            "  Batch 18360  of  27729.    Elapsed: 00:38:09.\n",
            "  Batch 18400  of  27729.    Elapsed: 00:38:14.\n",
            "  Batch 18440  of  27729.    Elapsed: 00:38:19.\n",
            "  Batch 18480  of  27729.    Elapsed: 00:38:24.\n",
            "  Batch 18520  of  27729.    Elapsed: 00:38:29.\n",
            "  Batch 18560  of  27729.    Elapsed: 00:38:34.\n",
            "  Batch 18600  of  27729.    Elapsed: 00:38:38.\n",
            "  Batch 18640  of  27729.    Elapsed: 00:38:43.\n",
            "  Batch 18680  of  27729.    Elapsed: 00:38:48.\n",
            "  Batch 18720  of  27729.    Elapsed: 00:38:53.\n",
            "  Batch 18760  of  27729.    Elapsed: 00:38:58.\n",
            "  Batch 18800  of  27729.    Elapsed: 00:39:03.\n",
            "  Batch 18840  of  27729.    Elapsed: 00:39:08.\n",
            "  Batch 18880  of  27729.    Elapsed: 00:39:13.\n",
            "  Batch 18920  of  27729.    Elapsed: 00:39:18.\n",
            "  Batch 18960  of  27729.    Elapsed: 00:39:23.\n",
            "  Batch 19000  of  27729.    Elapsed: 00:39:28.\n",
            "  Batch 19040  of  27729.    Elapsed: 00:39:33.\n",
            "  Batch 19080  of  27729.    Elapsed: 00:39:38.\n",
            "  Batch 19120  of  27729.    Elapsed: 00:39:43.\n",
            "  Batch 19160  of  27729.    Elapsed: 00:39:48.\n",
            "  Batch 19200  of  27729.    Elapsed: 00:39:53.\n",
            "  Batch 19240  of  27729.    Elapsed: 00:39:58.\n",
            "  Batch 19280  of  27729.    Elapsed: 00:40:03.\n",
            "  Batch 19320  of  27729.    Elapsed: 00:40:08.\n",
            "  Batch 19360  of  27729.    Elapsed: 00:40:13.\n",
            "  Batch 19400  of  27729.    Elapsed: 00:40:18.\n",
            "  Batch 19440  of  27729.    Elapsed: 00:40:23.\n",
            "  Batch 19480  of  27729.    Elapsed: 00:40:28.\n",
            "  Batch 19520  of  27729.    Elapsed: 00:40:33.\n",
            "  Batch 19560  of  27729.    Elapsed: 00:40:38.\n",
            "  Batch 19600  of  27729.    Elapsed: 00:40:43.\n",
            "  Batch 19640  of  27729.    Elapsed: 00:40:48.\n",
            "  Batch 19680  of  27729.    Elapsed: 00:40:53.\n",
            "  Batch 19720  of  27729.    Elapsed: 00:40:58.\n",
            "  Batch 19760  of  27729.    Elapsed: 00:41:03.\n",
            "  Batch 19800  of  27729.    Elapsed: 00:41:08.\n",
            "  Batch 19840  of  27729.    Elapsed: 00:41:13.\n",
            "  Batch 19880  of  27729.    Elapsed: 00:41:18.\n",
            "  Batch 19920  of  27729.    Elapsed: 00:41:23.\n",
            "  Batch 19960  of  27729.    Elapsed: 00:41:28.\n",
            "  Batch 20000  of  27729.    Elapsed: 00:41:33.\n",
            "  Batch 20040  of  27729.    Elapsed: 00:41:38.\n",
            "  Batch 20080  of  27729.    Elapsed: 00:41:43.\n",
            "  Batch 20120  of  27729.    Elapsed: 00:41:48.\n",
            "  Batch 20160  of  27729.    Elapsed: 00:41:53.\n",
            "  Batch 20200  of  27729.    Elapsed: 00:41:58.\n",
            "  Batch 20240  of  27729.    Elapsed: 00:42:03.\n",
            "  Batch 20280  of  27729.    Elapsed: 00:42:08.\n",
            "  Batch 20320  of  27729.    Elapsed: 00:42:13.\n",
            "  Batch 20360  of  27729.    Elapsed: 00:42:18.\n",
            "  Batch 20400  of  27729.    Elapsed: 00:42:23.\n",
            "  Batch 20440  of  27729.    Elapsed: 00:42:28.\n",
            "  Batch 20480  of  27729.    Elapsed: 00:42:33.\n",
            "  Batch 20520  of  27729.    Elapsed: 00:42:38.\n",
            "  Batch 20560  of  27729.    Elapsed: 00:42:43.\n",
            "  Batch 20600  of  27729.    Elapsed: 00:42:48.\n",
            "  Batch 20640  of  27729.    Elapsed: 00:42:53.\n",
            "  Batch 20680  of  27729.    Elapsed: 00:42:58.\n",
            "  Batch 20720  of  27729.    Elapsed: 00:43:03.\n",
            "  Batch 20760  of  27729.    Elapsed: 00:43:08.\n",
            "  Batch 20800  of  27729.    Elapsed: 00:43:13.\n",
            "  Batch 20840  of  27729.    Elapsed: 00:43:18.\n",
            "  Batch 20880  of  27729.    Elapsed: 00:43:23.\n",
            "  Batch 20920  of  27729.    Elapsed: 00:43:28.\n",
            "  Batch 20960  of  27729.    Elapsed: 00:43:33.\n",
            "  Batch 21000  of  27729.    Elapsed: 00:43:38.\n",
            "  Batch 21040  of  27729.    Elapsed: 00:43:43.\n",
            "  Batch 21080  of  27729.    Elapsed: 00:43:48.\n",
            "  Batch 21120  of  27729.    Elapsed: 00:43:53.\n",
            "  Batch 21160  of  27729.    Elapsed: 00:43:58.\n",
            "  Batch 21200  of  27729.    Elapsed: 00:44:03.\n",
            "  Batch 21240  of  27729.    Elapsed: 00:44:08.\n",
            "  Batch 21280  of  27729.    Elapsed: 00:44:13.\n",
            "  Batch 21320  of  27729.    Elapsed: 00:44:18.\n",
            "  Batch 21360  of  27729.    Elapsed: 00:44:22.\n",
            "  Batch 21400  of  27729.    Elapsed: 00:44:27.\n",
            "  Batch 21440  of  27729.    Elapsed: 00:44:32.\n",
            "  Batch 21480  of  27729.    Elapsed: 00:44:37.\n",
            "  Batch 21520  of  27729.    Elapsed: 00:44:42.\n",
            "  Batch 21560  of  27729.    Elapsed: 00:44:47.\n",
            "  Batch 21600  of  27729.    Elapsed: 00:44:52.\n",
            "  Batch 21640  of  27729.    Elapsed: 00:44:57.\n",
            "  Batch 21680  of  27729.    Elapsed: 00:45:02.\n",
            "  Batch 21720  of  27729.    Elapsed: 00:45:07.\n",
            "  Batch 21760  of  27729.    Elapsed: 00:45:12.\n",
            "  Batch 21800  of  27729.    Elapsed: 00:45:17.\n",
            "  Batch 21840  of  27729.    Elapsed: 00:45:22.\n",
            "  Batch 21880  of  27729.    Elapsed: 00:45:27.\n",
            "  Batch 21920  of  27729.    Elapsed: 00:45:32.\n",
            "  Batch 21960  of  27729.    Elapsed: 00:45:37.\n",
            "  Batch 22000  of  27729.    Elapsed: 00:45:42.\n",
            "  Batch 22040  of  27729.    Elapsed: 00:45:47.\n",
            "  Batch 22080  of  27729.    Elapsed: 00:45:52.\n",
            "  Batch 22120  of  27729.    Elapsed: 00:45:57.\n",
            "  Batch 22160  of  27729.    Elapsed: 00:46:02.\n",
            "  Batch 22200  of  27729.    Elapsed: 00:46:07.\n",
            "  Batch 22240  of  27729.    Elapsed: 00:46:12.\n",
            "  Batch 22280  of  27729.    Elapsed: 00:46:17.\n",
            "  Batch 22320  of  27729.    Elapsed: 00:46:22.\n",
            "  Batch 22360  of  27729.    Elapsed: 00:46:27.\n",
            "  Batch 22400  of  27729.    Elapsed: 00:46:32.\n",
            "  Batch 22440  of  27729.    Elapsed: 00:46:37.\n",
            "  Batch 22480  of  27729.    Elapsed: 00:46:42.\n",
            "  Batch 22520  of  27729.    Elapsed: 00:46:47.\n",
            "  Batch 22560  of  27729.    Elapsed: 00:46:52.\n",
            "  Batch 22600  of  27729.    Elapsed: 00:46:57.\n",
            "  Batch 22640  of  27729.    Elapsed: 00:47:02.\n",
            "  Batch 22680  of  27729.    Elapsed: 00:47:07.\n",
            "  Batch 22720  of  27729.    Elapsed: 00:47:12.\n",
            "  Batch 22760  of  27729.    Elapsed: 00:47:17.\n",
            "  Batch 22800  of  27729.    Elapsed: 00:47:22.\n",
            "  Batch 22840  of  27729.    Elapsed: 00:47:27.\n",
            "  Batch 22880  of  27729.    Elapsed: 00:47:32.\n",
            "  Batch 22920  of  27729.    Elapsed: 00:47:37.\n",
            "  Batch 22960  of  27729.    Elapsed: 00:47:42.\n",
            "  Batch 23000  of  27729.    Elapsed: 00:47:47.\n",
            "  Batch 23040  of  27729.    Elapsed: 00:47:52.\n",
            "  Batch 23080  of  27729.    Elapsed: 00:47:57.\n",
            "  Batch 23120  of  27729.    Elapsed: 00:48:02.\n",
            "  Batch 23160  of  27729.    Elapsed: 00:48:07.\n",
            "  Batch 23200  of  27729.    Elapsed: 00:48:12.\n",
            "  Batch 23240  of  27729.    Elapsed: 00:48:17.\n",
            "  Batch 23280  of  27729.    Elapsed: 00:48:22.\n",
            "  Batch 23320  of  27729.    Elapsed: 00:48:27.\n",
            "  Batch 23360  of  27729.    Elapsed: 00:48:32.\n",
            "  Batch 23400  of  27729.    Elapsed: 00:48:37.\n",
            "  Batch 23440  of  27729.    Elapsed: 00:48:42.\n",
            "  Batch 23480  of  27729.    Elapsed: 00:48:47.\n",
            "  Batch 23520  of  27729.    Elapsed: 00:48:52.\n",
            "  Batch 23560  of  27729.    Elapsed: 00:48:57.\n",
            "  Batch 23600  of  27729.    Elapsed: 00:49:02.\n",
            "  Batch 23640  of  27729.    Elapsed: 00:49:07.\n",
            "  Batch 23680  of  27729.    Elapsed: 00:49:12.\n",
            "  Batch 23720  of  27729.    Elapsed: 00:49:17.\n",
            "  Batch 23760  of  27729.    Elapsed: 00:49:22.\n",
            "  Batch 23800  of  27729.    Elapsed: 00:49:27.\n",
            "  Batch 23840  of  27729.    Elapsed: 00:49:31.\n",
            "  Batch 23880  of  27729.    Elapsed: 00:49:36.\n",
            "  Batch 23920  of  27729.    Elapsed: 00:49:41.\n",
            "  Batch 23960  of  27729.    Elapsed: 00:49:46.\n",
            "  Batch 24000  of  27729.    Elapsed: 00:49:51.\n",
            "  Batch 24040  of  27729.    Elapsed: 00:49:56.\n",
            "  Batch 24080  of  27729.    Elapsed: 00:50:01.\n",
            "  Batch 24120  of  27729.    Elapsed: 00:50:06.\n",
            "  Batch 24160  of  27729.    Elapsed: 00:50:11.\n",
            "  Batch 24200  of  27729.    Elapsed: 00:50:16.\n",
            "  Batch 24240  of  27729.    Elapsed: 00:50:21.\n",
            "  Batch 24280  of  27729.    Elapsed: 00:50:26.\n",
            "  Batch 24320  of  27729.    Elapsed: 00:50:31.\n",
            "  Batch 24360  of  27729.    Elapsed: 00:50:36.\n",
            "  Batch 24400  of  27729.    Elapsed: 00:50:41.\n",
            "  Batch 24440  of  27729.    Elapsed: 00:50:46.\n",
            "  Batch 24480  of  27729.    Elapsed: 00:50:51.\n",
            "  Batch 24520  of  27729.    Elapsed: 00:50:56.\n",
            "  Batch 24560  of  27729.    Elapsed: 00:51:01.\n",
            "  Batch 24600  of  27729.    Elapsed: 00:51:06.\n",
            "  Batch 24640  of  27729.    Elapsed: 00:51:11.\n",
            "  Batch 24680  of  27729.    Elapsed: 00:51:16.\n",
            "  Batch 24720  of  27729.    Elapsed: 00:51:21.\n",
            "  Batch 24760  of  27729.    Elapsed: 00:51:26.\n",
            "  Batch 24800  of  27729.    Elapsed: 00:51:31.\n",
            "  Batch 24840  of  27729.    Elapsed: 00:51:36.\n",
            "  Batch 24880  of  27729.    Elapsed: 00:51:41.\n",
            "  Batch 24920  of  27729.    Elapsed: 00:51:46.\n",
            "  Batch 24960  of  27729.    Elapsed: 00:51:51.\n",
            "  Batch 25000  of  27729.    Elapsed: 00:51:56.\n",
            "  Batch 25040  of  27729.    Elapsed: 00:52:01.\n",
            "  Batch 25080  of  27729.    Elapsed: 00:52:06.\n",
            "  Batch 25120  of  27729.    Elapsed: 00:52:11.\n",
            "  Batch 25160  of  27729.    Elapsed: 00:52:16.\n",
            "  Batch 25200  of  27729.    Elapsed: 00:52:21.\n",
            "  Batch 25240  of  27729.    Elapsed: 00:52:26.\n",
            "  Batch 25280  of  27729.    Elapsed: 00:52:31.\n",
            "  Batch 25320  of  27729.    Elapsed: 00:52:36.\n",
            "  Batch 25360  of  27729.    Elapsed: 00:52:41.\n",
            "  Batch 25400  of  27729.    Elapsed: 00:52:46.\n",
            "  Batch 25440  of  27729.    Elapsed: 00:52:51.\n",
            "  Batch 25480  of  27729.    Elapsed: 00:52:56.\n",
            "  Batch 25520  of  27729.    Elapsed: 00:53:01.\n",
            "  Batch 25560  of  27729.    Elapsed: 00:53:06.\n",
            "  Batch 25600  of  27729.    Elapsed: 00:53:11.\n",
            "  Batch 25640  of  27729.    Elapsed: 00:53:16.\n",
            "  Batch 25680  of  27729.    Elapsed: 00:53:21.\n",
            "  Batch 25720  of  27729.    Elapsed: 00:53:26.\n",
            "  Batch 25760  of  27729.    Elapsed: 00:53:31.\n",
            "  Batch 25800  of  27729.    Elapsed: 00:53:36.\n",
            "  Batch 25840  of  27729.    Elapsed: 00:53:41.\n",
            "  Batch 25880  of  27729.    Elapsed: 00:53:46.\n",
            "  Batch 25920  of  27729.    Elapsed: 00:53:51.\n",
            "  Batch 25960  of  27729.    Elapsed: 00:53:56.\n",
            "  Batch 26000  of  27729.    Elapsed: 00:54:01.\n",
            "  Batch 26040  of  27729.    Elapsed: 00:54:06.\n",
            "  Batch 26080  of  27729.    Elapsed: 00:54:11.\n",
            "  Batch 26120  of  27729.    Elapsed: 00:54:16.\n",
            "  Batch 26160  of  27729.    Elapsed: 00:54:21.\n",
            "  Batch 26200  of  27729.    Elapsed: 00:54:26.\n",
            "  Batch 26240  of  27729.    Elapsed: 00:54:31.\n",
            "  Batch 26280  of  27729.    Elapsed: 00:54:36.\n",
            "  Batch 26320  of  27729.    Elapsed: 00:54:41.\n",
            "  Batch 26360  of  27729.    Elapsed: 00:54:46.\n",
            "  Batch 26400  of  27729.    Elapsed: 00:54:51.\n",
            "  Batch 26440  of  27729.    Elapsed: 00:54:55.\n",
            "  Batch 26480  of  27729.    Elapsed: 00:55:00.\n",
            "  Batch 26520  of  27729.    Elapsed: 00:55:05.\n",
            "  Batch 26560  of  27729.    Elapsed: 00:55:10.\n",
            "  Batch 26600  of  27729.    Elapsed: 00:55:15.\n",
            "  Batch 26640  of  27729.    Elapsed: 00:55:20.\n",
            "  Batch 26680  of  27729.    Elapsed: 00:55:25.\n",
            "  Batch 26720  of  27729.    Elapsed: 00:55:30.\n",
            "  Batch 26760  of  27729.    Elapsed: 00:55:35.\n",
            "  Batch 26800  of  27729.    Elapsed: 00:55:40.\n",
            "  Batch 26840  of  27729.    Elapsed: 00:55:45.\n",
            "  Batch 26880  of  27729.    Elapsed: 00:55:50.\n",
            "  Batch 26920  of  27729.    Elapsed: 00:55:55.\n",
            "  Batch 26960  of  27729.    Elapsed: 00:56:00.\n",
            "  Batch 27000  of  27729.    Elapsed: 00:56:05.\n",
            "  Batch 27040  of  27729.    Elapsed: 00:56:10.\n",
            "  Batch 27080  of  27729.    Elapsed: 00:56:15.\n",
            "  Batch 27120  of  27729.    Elapsed: 00:56:20.\n",
            "  Batch 27160  of  27729.    Elapsed: 00:56:25.\n",
            "  Batch 27200  of  27729.    Elapsed: 00:56:30.\n",
            "  Batch 27240  of  27729.    Elapsed: 00:56:35.\n",
            "  Batch 27280  of  27729.    Elapsed: 00:56:40.\n",
            "  Batch 27320  of  27729.    Elapsed: 00:56:45.\n",
            "  Batch 27360  of  27729.    Elapsed: 00:56:50.\n",
            "  Batch 27400  of  27729.    Elapsed: 00:56:55.\n",
            "  Batch 27440  of  27729.    Elapsed: 00:57:00.\n",
            "  Batch 27480  of  27729.    Elapsed: 00:57:05.\n",
            "  Batch 27520  of  27729.    Elapsed: 00:57:10.\n",
            "  Batch 27560  of  27729.    Elapsed: 00:57:15.\n",
            "  Batch 27600  of  27729.    Elapsed: 00:57:20.\n",
            "  Batch 27640  of  27729.    Elapsed: 00:57:25.\n",
            "  Batch 27680  of  27729.    Elapsed: 00:57:30.\n",
            "  Batch 27720  of  27729.    Elapsed: 00:57:35.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 00:57:36\n",
            "\n",
            "Training completed\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print(f'======== Epoch {epoch_i+1} / {epochs} ========')\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the loss\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_valid_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and step != 0:\n",
        "            # Elapsed time\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress\n",
        "            print(f'  Batch {step}  of  {len(train_valid_dataloader)}.    Elapsed: {elapsed}.')\n",
        "\n",
        "        # Unpack the training batch and copy each tensor to the GPU. \n",
        "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Clear gradients\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # Get the loss value\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss\n",
        "    avg_train_loss = total_loss / len(train_valid_dataloader)            \n",
        "    \n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(f\"  Training epcoh took: {format_time(time.time() - t0)}\")\n",
        "    \n",
        "# Save the model\n",
        "torch.save(model.state_dict(), '/content/gdrive/MyDrive/SaveModels/BERT_model.pt')      \n",
        "\n",
        "print(\"\")\n",
        "print(\"Training completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7fz7OqY8tXL"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "XwnOC2I1s2JS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cde8b9c-9cd2-4b90-cf84-5d84491c884f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Validation...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82        22\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.75      0.75      0.75         4\n",
            "           3       0.50      0.50      0.50         2\n",
            "           4       0.50      0.33      0.40         3\n",
            "\n",
            "    accuracy                           0.72        32\n",
            "   macro avg       0.51      0.48      0.49        32\n",
            "weighted avg       0.73      0.72      0.72        32\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82        41\n",
            "           1       0.33      0.50      0.40         2\n",
            "           2       0.70      0.58      0.64        12\n",
            "           3       0.50      0.25      0.33         4\n",
            "           4       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.72        64\n",
            "   macro avg       0.55      0.52      0.52        64\n",
            "weighted avg       0.71      0.72      0.71        64\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81        56\n",
            "           1       0.33      0.67      0.44         3\n",
            "           2       0.64      0.47      0.55        19\n",
            "           3       0.50      0.25      0.33         4\n",
            "           4       0.58      0.54      0.56        13\n",
            "           5       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.70        96\n",
            "   macro avg       0.47      0.46      0.45        96\n",
            "weighted avg       0.69      0.70      0.69        96\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82        72\n",
            "           1       0.50      0.57      0.53         7\n",
            "           2       0.62      0.57      0.59        23\n",
            "           3       0.50      0.20      0.29         5\n",
            "           4       0.67      0.63      0.65        19\n",
            "           5       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.72       128\n",
            "   macro avg       0.51      0.47      0.48       128\n",
            "weighted avg       0.70      0.72      0.70       128\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "           3       0.63      0.39      0.48      2109\n",
            "           4       0.76      0.79      0.78     14957\n",
            "           5       0.76      0.68      0.72      2437\n",
            "\n",
            "    accuracy                           0.78     72224\n",
            "   macro avg       0.73      0.66      0.69     72224\n",
            "weighted avg       0.78      0.78      0.78     72224\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36191\n",
            "           1       0.67      0.54      0.60      3827\n",
            "           2       0.69      0.67      0.68     12728\n",
            "           3       0.63      0.39      0.48      2109\n",
            "           4       0.76      0.79      0.78     14963\n",
            "           5       0.76      0.68      0.72      2438\n",
            "\n",
            "    accuracy                           0.78     72256\n",
            "   macro avg       0.73      0.66      0.69     72256\n",
            "weighted avg       0.78      0.78      0.78     72256\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36210\n",
            "           1       0.67      0.54      0.60      3828\n",
            "           2       0.69      0.67      0.68     12730\n",
            "           3       0.62      0.39      0.48      2110\n",
            "           4       0.76      0.79      0.78     14971\n",
            "           5       0.76      0.68      0.72      2439\n",
            "\n",
            "    accuracy                           0.78     72288\n",
            "   macro avg       0.73      0.66      0.69     72288\n",
            "weighted avg       0.78      0.78      0.78     72288\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36225\n",
            "           1       0.67      0.54      0.60      3829\n",
            "           2       0.69      0.67      0.68     12735\n",
            "           3       0.62      0.39      0.48      2111\n",
            "           4       0.76      0.79      0.78     14979\n",
            "           5       0.76      0.68      0.72      2441\n",
            "\n",
            "    accuracy                           0.78     72320\n",
            "   macro avg       0.73      0.66      0.69     72320\n",
            "weighted avg       0.78      0.78      0.78     72320\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36239\n",
            "           1       0.67      0.54      0.60      3830\n",
            "           2       0.69      0.67      0.68     12741\n",
            "           3       0.62      0.39      0.48      2112\n",
            "           4       0.76      0.79      0.78     14987\n",
            "           5       0.76      0.68      0.72      2443\n",
            "\n",
            "    accuracy                           0.78     72352\n",
            "   macro avg       0.73      0.66      0.69     72352\n",
            "weighted avg       0.78      0.78      0.78     72352\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36256\n",
            "           1       0.67      0.54      0.60      3830\n",
            "           2       0.69      0.67      0.68     12748\n",
            "           3       0.62      0.39      0.48      2113\n",
            "           4       0.76      0.79      0.78     14993\n",
            "           5       0.76      0.68      0.72      2444\n",
            "\n",
            "    accuracy                           0.78     72384\n",
            "   macro avg       0.72      0.66      0.69     72384\n",
            "weighted avg       0.78      0.78      0.78     72384\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36275\n",
            "           1       0.67      0.54      0.60      3831\n",
            "           2       0.69      0.67      0.68     12749\n",
            "           3       0.62      0.39      0.48      2114\n",
            "           4       0.76      0.79      0.78     15002\n",
            "           5       0.76      0.68      0.72      2445\n",
            "\n",
            "    accuracy                           0.78     72416\n",
            "   macro avg       0.72      0.66      0.69     72416\n",
            "weighted avg       0.78      0.78      0.78     72416\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36291\n",
            "           1       0.67      0.54      0.60      3832\n",
            "           2       0.69      0.67      0.68     12753\n",
            "           3       0.62      0.39      0.48      2114\n",
            "           4       0.76      0.79      0.78     15011\n",
            "           5       0.76      0.68      0.72      2447\n",
            "\n",
            "    accuracy                           0.78     72448\n",
            "   macro avg       0.73      0.66      0.69     72448\n",
            "weighted avg       0.78      0.78      0.78     72448\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36308\n",
            "           1       0.67      0.54      0.60      3834\n",
            "           2       0.69      0.67      0.68     12760\n",
            "           3       0.62      0.39      0.48      2114\n",
            "           4       0.76      0.79      0.78     15015\n",
            "           5       0.76      0.68      0.72      2449\n",
            "\n",
            "    accuracy                           0.78     72480\n",
            "   macro avg       0.73      0.66      0.69     72480\n",
            "weighted avg       0.78      0.78      0.78     72480\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36320\n",
            "           1       0.67      0.54      0.60      3834\n",
            "           2       0.69      0.67      0.68     12766\n",
            "           3       0.62      0.39      0.48      2116\n",
            "           4       0.76      0.79      0.78     15023\n",
            "           5       0.76      0.68      0.72      2453\n",
            "\n",
            "    accuracy                           0.78     72512\n",
            "   macro avg       0.73      0.66      0.69     72512\n",
            "weighted avg       0.78      0.78      0.78     72512\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36336\n",
            "           1       0.67      0.54      0.60      3834\n",
            "           2       0.69      0.67      0.68     12772\n",
            "           3       0.62      0.39      0.48      2116\n",
            "           4       0.76      0.79      0.78     15031\n",
            "           5       0.76      0.68      0.72      2455\n",
            "\n",
            "    accuracy                           0.78     72544\n",
            "   macro avg       0.73      0.66      0.69     72544\n",
            "weighted avg       0.78      0.78      0.78     72544\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36351\n",
            "           1       0.67      0.54      0.60      3836\n",
            "           2       0.69      0.67      0.68     12775\n",
            "           3       0.62      0.39      0.48      2116\n",
            "           4       0.76      0.79      0.78     15041\n",
            "           5       0.76      0.68      0.72      2457\n",
            "\n",
            "    accuracy                           0.78     72576\n",
            "   macro avg       0.73      0.66      0.69     72576\n",
            "weighted avg       0.78      0.78      0.78     72576\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36371\n",
            "           1       0.67      0.54      0.60      3836\n",
            "           2       0.69      0.67      0.68     12782\n",
            "           3       0.63      0.39      0.48      2117\n",
            "           4       0.76      0.79      0.78     15044\n",
            "           5       0.76      0.68      0.72      2458\n",
            "\n",
            "    accuracy                           0.78     72608\n",
            "   macro avg       0.73      0.66      0.69     72608\n",
            "weighted avg       0.78      0.78      0.78     72608\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36388\n",
            "           1       0.67      0.54      0.60      3838\n",
            "           2       0.69      0.67      0.68     12787\n",
            "           3       0.63      0.39      0.48      2117\n",
            "           4       0.76      0.79      0.78     15052\n",
            "           5       0.76      0.68      0.72      2458\n",
            "\n",
            "    accuracy                           0.78     72640\n",
            "   macro avg       0.73      0.66      0.69     72640\n",
            "weighted avg       0.78      0.78      0.78     72640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36404\n",
            "           1       0.67      0.54      0.60      3840\n",
            "           2       0.69      0.67      0.68     12792\n",
            "           3       0.63      0.39      0.48      2117\n",
            "           4       0.76      0.79      0.78     15060\n",
            "           5       0.76      0.68      0.72      2459\n",
            "\n",
            "    accuracy                           0.78     72672\n",
            "   macro avg       0.73      0.66      0.69     72672\n",
            "weighted avg       0.78      0.78      0.78     72672\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36423\n",
            "           1       0.67      0.54      0.60      3842\n",
            "           2       0.69      0.67      0.68     12799\n",
            "           3       0.63      0.39      0.48      2117\n",
            "           4       0.76      0.79      0.78     15064\n",
            "           5       0.76      0.68      0.72      2459\n",
            "\n",
            "    accuracy                           0.78     72704\n",
            "   macro avg       0.73      0.66      0.69     72704\n",
            "weighted avg       0.78      0.78      0.78     72704\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36438\n",
            "           1       0.67      0.54      0.60      3844\n",
            "           2       0.69      0.67      0.68     12801\n",
            "           3       0.62      0.39      0.48      2120\n",
            "           4       0.76      0.79      0.78     15072\n",
            "           5       0.76      0.68      0.72      2461\n",
            "\n",
            "    accuracy                           0.78     72736\n",
            "   macro avg       0.73      0.66      0.69     72736\n",
            "weighted avg       0.78      0.78      0.78     72736\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36455\n",
            "           1       0.67      0.54      0.60      3847\n",
            "           2       0.69      0.67      0.68     12807\n",
            "           3       0.62      0.39      0.48      2121\n",
            "           4       0.76      0.79      0.78     15075\n",
            "           5       0.76      0.68      0.72      2463\n",
            "\n",
            "    accuracy                           0.78     72768\n",
            "   macro avg       0.73      0.66      0.69     72768\n",
            "weighted avg       0.78      0.78      0.78     72768\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36474\n",
            "           1       0.67      0.54      0.60      3848\n",
            "           2       0.69      0.67      0.68     12810\n",
            "           3       0.62      0.39      0.48      2121\n",
            "           4       0.76      0.79      0.78     15083\n",
            "           5       0.76      0.68      0.72      2464\n",
            "\n",
            "    accuracy                           0.78     72800\n",
            "   macro avg       0.73      0.66      0.69     72800\n",
            "weighted avg       0.78      0.78      0.78     72800\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36491\n",
            "           1       0.67      0.54      0.60      3850\n",
            "           2       0.69      0.67      0.68     12818\n",
            "           3       0.62      0.39      0.48      2121\n",
            "           4       0.76      0.79      0.78     15088\n",
            "           5       0.76      0.68      0.72      2464\n",
            "\n",
            "    accuracy                           0.78     72832\n",
            "   macro avg       0.73      0.66      0.69     72832\n",
            "weighted avg       0.78      0.78      0.78     72832\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36508\n",
            "           1       0.67      0.54      0.60      3851\n",
            "           2       0.69      0.67      0.68     12824\n",
            "           3       0.62      0.39      0.48      2121\n",
            "           4       0.76      0.79      0.78     15095\n",
            "           5       0.76      0.68      0.72      2465\n",
            "\n",
            "    accuracy                           0.78     72864\n",
            "   macro avg       0.73      0.66      0.69     72864\n",
            "weighted avg       0.78      0.78      0.78     72864\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36531\n",
            "           1       0.67      0.54      0.60      3851\n",
            "           2       0.69      0.67      0.68     12826\n",
            "           3       0.62      0.39      0.48      2122\n",
            "           4       0.76      0.79      0.78     15099\n",
            "           5       0.76      0.68      0.72      2467\n",
            "\n",
            "    accuracy                           0.78     72896\n",
            "   macro avg       0.73      0.66      0.69     72896\n",
            "weighted avg       0.78      0.78      0.78     72896\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36545\n",
            "           1       0.67      0.54      0.60      3852\n",
            "           2       0.69      0.67      0.68     12834\n",
            "           3       0.62      0.39      0.48      2123\n",
            "           4       0.76      0.79      0.78     15104\n",
            "           5       0.76      0.68      0.72      2470\n",
            "\n",
            "    accuracy                           0.78     72928\n",
            "   macro avg       0.73      0.66      0.69     72928\n",
            "weighted avg       0.78      0.78      0.78     72928\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36559\n",
            "           1       0.67      0.54      0.60      3852\n",
            "           2       0.69      0.67      0.68     12840\n",
            "           3       0.62      0.39      0.48      2125\n",
            "           4       0.76      0.79      0.78     15113\n",
            "           5       0.76      0.68      0.72      2471\n",
            "\n",
            "    accuracy                           0.78     72960\n",
            "   macro avg       0.73      0.66      0.69     72960\n",
            "weighted avg       0.78      0.78      0.78     72960\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36573\n",
            "           1       0.67      0.54      0.60      3854\n",
            "           2       0.69      0.67      0.68     12844\n",
            "           3       0.62      0.39      0.48      2126\n",
            "           4       0.76      0.79      0.78     15124\n",
            "           5       0.76      0.68      0.72      2471\n",
            "\n",
            "    accuracy                           0.78     72992\n",
            "   macro avg       0.73      0.66      0.69     72992\n",
            "weighted avg       0.78      0.78      0.78     72992\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36591\n",
            "           1       0.67      0.54      0.60      3855\n",
            "           2       0.69      0.67      0.68     12846\n",
            "           3       0.62      0.39      0.48      2128\n",
            "           4       0.76      0.79      0.78     15132\n",
            "           5       0.76      0.68      0.72      2472\n",
            "\n",
            "    accuracy                           0.78     73024\n",
            "   macro avg       0.73      0.66      0.69     73024\n",
            "weighted avg       0.78      0.78      0.78     73024\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36604\n",
            "           1       0.67      0.54      0.60      3859\n",
            "           2       0.69      0.67      0.68     12850\n",
            "           3       0.62      0.39      0.48      2129\n",
            "           4       0.76      0.79      0.78     15140\n",
            "           5       0.76      0.68      0.72      2474\n",
            "\n",
            "    accuracy                           0.78     73056\n",
            "   macro avg       0.73      0.66      0.69     73056\n",
            "weighted avg       0.78      0.78      0.78     73056\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36620\n",
            "           1       0.67      0.54      0.60      3861\n",
            "           2       0.69      0.67      0.68     12856\n",
            "           3       0.62      0.39      0.48      2130\n",
            "           4       0.76      0.79      0.78     15146\n",
            "           5       0.76      0.68      0.72      2475\n",
            "\n",
            "    accuracy                           0.78     73088\n",
            "   macro avg       0.73      0.66      0.69     73088\n",
            "weighted avg       0.78      0.78      0.78     73088\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36637\n",
            "           1       0.67      0.54      0.60      3862\n",
            "           2       0.69      0.67      0.68     12860\n",
            "           3       0.62      0.39      0.48      2131\n",
            "           4       0.76      0.79      0.78     15152\n",
            "           5       0.76      0.68      0.72      2478\n",
            "\n",
            "    accuracy                           0.78     73120\n",
            "   macro avg       0.73      0.66      0.69     73120\n",
            "weighted avg       0.78      0.78      0.78     73120\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36654\n",
            "           1       0.67      0.54      0.60      3862\n",
            "           2       0.69      0.67      0.68     12868\n",
            "           3       0.62      0.39      0.48      2132\n",
            "           4       0.76      0.79      0.78     15158\n",
            "           5       0.76      0.68      0.72      2478\n",
            "\n",
            "    accuracy                           0.78     73152\n",
            "   macro avg       0.73      0.66      0.69     73152\n",
            "weighted avg       0.78      0.78      0.78     73152\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36671\n",
            "           1       0.67      0.54      0.60      3867\n",
            "           2       0.69      0.67      0.68     12872\n",
            "           3       0.62      0.39      0.48      2132\n",
            "           4       0.76      0.79      0.78     15163\n",
            "           5       0.76      0.68      0.72      2479\n",
            "\n",
            "    accuracy                           0.78     73184\n",
            "   macro avg       0.73      0.66      0.69     73184\n",
            "weighted avg       0.78      0.78      0.78     73184\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36691\n",
            "           1       0.67      0.54      0.60      3867\n",
            "           2       0.69      0.67      0.68     12874\n",
            "           3       0.62      0.39      0.48      2134\n",
            "           4       0.76      0.79      0.78     15170\n",
            "           5       0.76      0.68      0.72      2480\n",
            "\n",
            "    accuracy                           0.79     73216\n",
            "   macro avg       0.73      0.66      0.69     73216\n",
            "weighted avg       0.78      0.79      0.78     73216\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36709\n",
            "           1       0.67      0.54      0.60      3867\n",
            "           2       0.69      0.67      0.68     12879\n",
            "           3       0.62      0.39      0.48      2135\n",
            "           4       0.76      0.79      0.78     15178\n",
            "           5       0.76      0.68      0.72      2480\n",
            "\n",
            "    accuracy                           0.79     73248\n",
            "   macro avg       0.73      0.66      0.69     73248\n",
            "weighted avg       0.78      0.79      0.78     73248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36725\n",
            "           1       0.67      0.54      0.60      3870\n",
            "           2       0.69      0.67      0.68     12884\n",
            "           3       0.62      0.39      0.48      2136\n",
            "           4       0.76      0.79      0.78     15185\n",
            "           5       0.76      0.68      0.72      2480\n",
            "\n",
            "    accuracy                           0.79     73280\n",
            "   macro avg       0.73      0.66      0.69     73280\n",
            "weighted avg       0.78      0.79      0.78     73280\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36740\n",
            "           1       0.67      0.54      0.60      3873\n",
            "           2       0.69      0.67      0.68     12892\n",
            "           3       0.62      0.39      0.48      2136\n",
            "           4       0.76      0.79      0.78     15191\n",
            "           5       0.76      0.68      0.72      2480\n",
            "\n",
            "    accuracy                           0.79     73312\n",
            "   macro avg       0.73      0.66      0.69     73312\n",
            "weighted avg       0.78      0.79      0.78     73312\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36757\n",
            "           1       0.67      0.54      0.60      3875\n",
            "           2       0.69      0.67      0.68     12898\n",
            "           3       0.62      0.39      0.48      2136\n",
            "           4       0.76      0.79      0.78     15197\n",
            "           5       0.76      0.68      0.72      2481\n",
            "\n",
            "    accuracy                           0.79     73344\n",
            "   macro avg       0.73      0.66      0.69     73344\n",
            "weighted avg       0.78      0.79      0.78     73344\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36773\n",
            "           1       0.67      0.54      0.60      3879\n",
            "           2       0.69      0.67      0.68     12905\n",
            "           3       0.62      0.39      0.48      2136\n",
            "           4       0.76      0.79      0.78     15201\n",
            "           5       0.76      0.68      0.72      2482\n",
            "\n",
            "    accuracy                           0.79     73376\n",
            "   macro avg       0.73      0.66      0.69     73376\n",
            "weighted avg       0.78      0.79      0.78     73376\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36787\n",
            "           1       0.67      0.54      0.60      3882\n",
            "           2       0.69      0.67      0.68     12913\n",
            "           3       0.62      0.39      0.48      2137\n",
            "           4       0.76      0.79      0.78     15205\n",
            "           5       0.76      0.68      0.72      2484\n",
            "\n",
            "    accuracy                           0.79     73408\n",
            "   macro avg       0.73      0.66      0.69     73408\n",
            "weighted avg       0.78      0.79      0.78     73408\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36803\n",
            "           1       0.67      0.54      0.60      3883\n",
            "           2       0.69      0.67      0.68     12919\n",
            "           3       0.62      0.39      0.48      2138\n",
            "           4       0.76      0.79      0.78     15212\n",
            "           5       0.76      0.68      0.72      2485\n",
            "\n",
            "    accuracy                           0.79     73440\n",
            "   macro avg       0.73      0.66      0.69     73440\n",
            "weighted avg       0.78      0.79      0.78     73440\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36820\n",
            "           1       0.67      0.54      0.60      3885\n",
            "           2       0.69      0.67      0.68     12926\n",
            "           3       0.62      0.39      0.48      2141\n",
            "           4       0.76      0.79      0.78     15215\n",
            "           5       0.76      0.68      0.72      2485\n",
            "\n",
            "    accuracy                           0.79     73472\n",
            "   macro avg       0.73      0.66      0.69     73472\n",
            "weighted avg       0.78      0.79      0.78     73472\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36841\n",
            "           1       0.67      0.54      0.60      3885\n",
            "           2       0.69      0.67      0.68     12931\n",
            "           3       0.62      0.39      0.48      2141\n",
            "           4       0.76      0.79      0.78     15221\n",
            "           5       0.76      0.68      0.72      2485\n",
            "\n",
            "    accuracy                           0.79     73504\n",
            "   macro avg       0.73      0.66      0.69     73504\n",
            "weighted avg       0.78      0.79      0.78     73504\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36857\n",
            "           1       0.67      0.54      0.60      3887\n",
            "           2       0.69      0.67      0.68     12935\n",
            "           3       0.63      0.39      0.48      2143\n",
            "           4       0.76      0.79      0.78     15228\n",
            "           5       0.76      0.68      0.72      2486\n",
            "\n",
            "    accuracy                           0.79     73536\n",
            "   macro avg       0.73      0.66      0.69     73536\n",
            "weighted avg       0.78      0.79      0.78     73536\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36872\n",
            "           1       0.67      0.54      0.60      3892\n",
            "           2       0.69      0.67      0.68     12941\n",
            "           3       0.62      0.39      0.48      2144\n",
            "           4       0.76      0.79      0.78     15233\n",
            "           5       0.76      0.68      0.72      2486\n",
            "\n",
            "    accuracy                           0.79     73568\n",
            "   macro avg       0.73      0.66      0.69     73568\n",
            "weighted avg       0.78      0.79      0.78     73568\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36890\n",
            "           1       0.67      0.54      0.60      3895\n",
            "           2       0.69      0.67      0.68     12945\n",
            "           3       0.62      0.39      0.48      2144\n",
            "           4       0.76      0.79      0.78     15239\n",
            "           5       0.76      0.68      0.72      2487\n",
            "\n",
            "    accuracy                           0.79     73600\n",
            "   macro avg       0.73      0.66      0.69     73600\n",
            "weighted avg       0.78      0.79      0.78     73600\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36905\n",
            "           1       0.67      0.54      0.60      3898\n",
            "           2       0.69      0.67      0.68     12954\n",
            "           3       0.62      0.39      0.48      2146\n",
            "           4       0.76      0.79      0.78     15242\n",
            "           5       0.76      0.68      0.72      2487\n",
            "\n",
            "    accuracy                           0.79     73632\n",
            "   macro avg       0.73      0.66      0.69     73632\n",
            "weighted avg       0.78      0.79      0.78     73632\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36919\n",
            "           1       0.67      0.54      0.60      3901\n",
            "           2       0.69      0.67      0.68     12963\n",
            "           3       0.62      0.39      0.48      2147\n",
            "           4       0.76      0.79      0.78     15247\n",
            "           5       0.76      0.68      0.72      2487\n",
            "\n",
            "    accuracy                           0.79     73664\n",
            "   macro avg       0.73      0.66      0.69     73664\n",
            "weighted avg       0.78      0.79      0.78     73664\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36938\n",
            "           1       0.67      0.54      0.60      3901\n",
            "           2       0.69      0.67      0.68     12966\n",
            "           3       0.62      0.39      0.48      2148\n",
            "           4       0.76      0.79      0.78     15254\n",
            "           5       0.76      0.68      0.72      2489\n",
            "\n",
            "    accuracy                           0.79     73696\n",
            "   macro avg       0.73      0.66      0.69     73696\n",
            "weighted avg       0.78      0.79      0.78     73696\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36951\n",
            "           1       0.67      0.54      0.60      3903\n",
            "           2       0.69      0.67      0.68     12973\n",
            "           3       0.62      0.39      0.48      2148\n",
            "           4       0.76      0.79      0.78     15262\n",
            "           5       0.76      0.68      0.72      2491\n",
            "\n",
            "    accuracy                           0.79     73728\n",
            "   macro avg       0.73      0.66      0.69     73728\n",
            "weighted avg       0.78      0.79      0.78     73728\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36971\n",
            "           1       0.67      0.54      0.60      3904\n",
            "           2       0.69      0.67      0.68     12977\n",
            "           3       0.62      0.39      0.48      2148\n",
            "           4       0.76      0.79      0.78     15268\n",
            "           5       0.76      0.68      0.72      2492\n",
            "\n",
            "    accuracy                           0.79     73760\n",
            "   macro avg       0.73      0.66      0.69     73760\n",
            "weighted avg       0.78      0.79      0.78     73760\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36984\n",
            "           1       0.67      0.54      0.60      3905\n",
            "           2       0.69      0.67      0.68     12984\n",
            "           3       0.62      0.39      0.48      2150\n",
            "           4       0.76      0.79      0.78     15276\n",
            "           5       0.76      0.68      0.72      2493\n",
            "\n",
            "    accuracy                           0.79     73792\n",
            "   macro avg       0.73      0.66      0.69     73792\n",
            "weighted avg       0.78      0.79      0.78     73792\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     36997\n",
            "           1       0.67      0.54      0.60      3908\n",
            "           2       0.69      0.67      0.68     12988\n",
            "           3       0.62      0.39      0.48      2153\n",
            "           4       0.76      0.79      0.78     15284\n",
            "           5       0.76      0.68      0.72      2494\n",
            "\n",
            "    accuracy                           0.79     73824\n",
            "   macro avg       0.73      0.66      0.69     73824\n",
            "weighted avg       0.78      0.79      0.78     73824\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37012\n",
            "           1       0.67      0.54      0.60      3909\n",
            "           2       0.69      0.67      0.68     12993\n",
            "           3       0.62      0.39      0.48      2153\n",
            "           4       0.76      0.79      0.78     15295\n",
            "           5       0.76      0.68      0.72      2494\n",
            "\n",
            "    accuracy                           0.79     73856\n",
            "   macro avg       0.73      0.66      0.69     73856\n",
            "weighted avg       0.78      0.79      0.78     73856\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37026\n",
            "           1       0.67      0.54      0.60      3914\n",
            "           2       0.69      0.67      0.68     13000\n",
            "           3       0.62      0.39      0.48      2153\n",
            "           4       0.76      0.79      0.78     15301\n",
            "           5       0.76      0.68      0.72      2494\n",
            "\n",
            "    accuracy                           0.79     73888\n",
            "   macro avg       0.73      0.66      0.69     73888\n",
            "weighted avg       0.78      0.79      0.78     73888\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37045\n",
            "           1       0.67      0.54      0.60      3917\n",
            "           2       0.69      0.67      0.68     13003\n",
            "           3       0.62      0.39      0.48      2154\n",
            "           4       0.76      0.79      0.78     15305\n",
            "           5       0.76      0.68      0.72      2496\n",
            "\n",
            "    accuracy                           0.79     73920\n",
            "   macro avg       0.73      0.66      0.69     73920\n",
            "weighted avg       0.78      0.79      0.78     73920\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37062\n",
            "           1       0.67      0.54      0.60      3918\n",
            "           2       0.69      0.67      0.68     13008\n",
            "           3       0.62      0.39      0.48      2154\n",
            "           4       0.76      0.79      0.78     15313\n",
            "           5       0.76      0.68      0.72      2497\n",
            "\n",
            "    accuracy                           0.79     73952\n",
            "   macro avg       0.73      0.66      0.69     73952\n",
            "weighted avg       0.78      0.79      0.78     73952\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37079\n",
            "           1       0.67      0.54      0.60      3918\n",
            "           2       0.69      0.67      0.68     13014\n",
            "           3       0.62      0.39      0.48      2154\n",
            "           4       0.76      0.79      0.78     15320\n",
            "           5       0.76      0.68      0.72      2499\n",
            "\n",
            "    accuracy                           0.79     73984\n",
            "   macro avg       0.73      0.66      0.69     73984\n",
            "weighted avg       0.78      0.79      0.78     73984\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37099\n",
            "           1       0.67      0.54      0.60      3921\n",
            "           2       0.69      0.67      0.68     13018\n",
            "           3       0.62      0.39      0.48      2154\n",
            "           4       0.76      0.79      0.78     15325\n",
            "           5       0.76      0.68      0.72      2499\n",
            "\n",
            "    accuracy                           0.79     74016\n",
            "   macro avg       0.73      0.66      0.69     74016\n",
            "weighted avg       0.78      0.79      0.78     74016\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37116\n",
            "           1       0.67      0.54      0.60      3922\n",
            "           2       0.69      0.67      0.68     13024\n",
            "           3       0.62      0.39      0.48      2154\n",
            "           4       0.76      0.79      0.78     15332\n",
            "           5       0.76      0.68      0.72      2500\n",
            "\n",
            "    accuracy                           0.79     74048\n",
            "   macro avg       0.73      0.66      0.69     74048\n",
            "weighted avg       0.78      0.79      0.78     74048\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37134\n",
            "           1       0.67      0.54      0.60      3923\n",
            "           2       0.69      0.67      0.68     13029\n",
            "           3       0.62      0.39      0.48      2154\n",
            "           4       0.76      0.79      0.78     15339\n",
            "           5       0.76      0.68      0.72      2501\n",
            "\n",
            "    accuracy                           0.79     74080\n",
            "   macro avg       0.73      0.66      0.69     74080\n",
            "weighted avg       0.78      0.79      0.78     74080\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37153\n",
            "           1       0.67      0.54      0.60      3926\n",
            "           2       0.69      0.67      0.68     13031\n",
            "           3       0.62      0.39      0.48      2157\n",
            "           4       0.76      0.79      0.78     15344\n",
            "           5       0.76      0.68      0.72      2501\n",
            "\n",
            "    accuracy                           0.79     74112\n",
            "   macro avg       0.73      0.66      0.69     74112\n",
            "weighted avg       0.78      0.79      0.78     74112\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37163\n",
            "           1       0.67      0.54      0.60      3928\n",
            "           2       0.69      0.67      0.68     13040\n",
            "           3       0.62      0.39      0.48      2159\n",
            "           4       0.76      0.79      0.78     15350\n",
            "           5       0.76      0.68      0.72      2504\n",
            "\n",
            "    accuracy                           0.79     74144\n",
            "   macro avg       0.73      0.66      0.69     74144\n",
            "weighted avg       0.78      0.79      0.78     74144\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37178\n",
            "           1       0.67      0.54      0.60      3930\n",
            "           2       0.69      0.67      0.68     13047\n",
            "           3       0.62      0.39      0.48      2163\n",
            "           4       0.76      0.79      0.78     15354\n",
            "           5       0.76      0.68      0.72      2504\n",
            "\n",
            "    accuracy                           0.79     74176\n",
            "   macro avg       0.73      0.66      0.69     74176\n",
            "weighted avg       0.78      0.79      0.78     74176\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37193\n",
            "           1       0.67      0.54      0.60      3930\n",
            "           2       0.69      0.67      0.68     13057\n",
            "           3       0.62      0.39      0.48      2165\n",
            "           4       0.76      0.79      0.78     15358\n",
            "           5       0.76      0.68      0.72      2505\n",
            "\n",
            "    accuracy                           0.79     74208\n",
            "   macro avg       0.73      0.66      0.69     74208\n",
            "weighted avg       0.78      0.79      0.78     74208\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37209\n",
            "           1       0.67      0.54      0.60      3932\n",
            "           2       0.69      0.67      0.68     13064\n",
            "           3       0.62      0.39      0.48      2167\n",
            "           4       0.76      0.79      0.78     15363\n",
            "           5       0.76      0.68      0.72      2505\n",
            "\n",
            "    accuracy                           0.79     74240\n",
            "   macro avg       0.73      0.66      0.69     74240\n",
            "weighted avg       0.78      0.79      0.78     74240\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37223\n",
            "           1       0.67      0.54      0.60      3939\n",
            "           2       0.69      0.67      0.68     13069\n",
            "           3       0.62      0.39      0.48      2169\n",
            "           4       0.76      0.79      0.78     15367\n",
            "           5       0.76      0.68      0.72      2505\n",
            "\n",
            "    accuracy                           0.79     74272\n",
            "   macro avg       0.73      0.66      0.69     74272\n",
            "weighted avg       0.78      0.79      0.78     74272\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37239\n",
            "           1       0.67      0.54      0.60      3940\n",
            "           2       0.69      0.67      0.68     13079\n",
            "           3       0.62      0.39      0.48      2169\n",
            "           4       0.76      0.79      0.78     15372\n",
            "           5       0.76      0.68      0.72      2505\n",
            "\n",
            "    accuracy                           0.79     74304\n",
            "   macro avg       0.73      0.66      0.69     74304\n",
            "weighted avg       0.78      0.79      0.78     74304\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37255\n",
            "           1       0.67      0.54      0.60      3943\n",
            "           2       0.69      0.67      0.68     13083\n",
            "           3       0.62      0.39      0.48      2170\n",
            "           4       0.76      0.79      0.78     15379\n",
            "           5       0.76      0.68      0.72      2506\n",
            "\n",
            "    accuracy                           0.79     74336\n",
            "   macro avg       0.73      0.66      0.69     74336\n",
            "weighted avg       0.78      0.79      0.78     74336\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37271\n",
            "           1       0.67      0.54      0.60      3945\n",
            "           2       0.69      0.67      0.68     13090\n",
            "           3       0.62      0.39      0.48      2171\n",
            "           4       0.76      0.79      0.78     15383\n",
            "           5       0.76      0.68      0.72      2508\n",
            "\n",
            "    accuracy                           0.79     74368\n",
            "   macro avg       0.73      0.66      0.69     74368\n",
            "weighted avg       0.78      0.79      0.78     74368\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37284\n",
            "           1       0.67      0.54      0.60      3947\n",
            "           2       0.69      0.67      0.68     13099\n",
            "           3       0.62      0.39      0.48      2173\n",
            "           4       0.76      0.79      0.78     15388\n",
            "           5       0.76      0.68      0.72      2509\n",
            "\n",
            "    accuracy                           0.79     74400\n",
            "   macro avg       0.73      0.66      0.69     74400\n",
            "weighted avg       0.78      0.79      0.78     74400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37297\n",
            "           1       0.67      0.54      0.60      3950\n",
            "           2       0.69      0.67      0.68     13104\n",
            "           3       0.62      0.39      0.48      2175\n",
            "           4       0.76      0.79      0.78     15396\n",
            "           5       0.76      0.68      0.72      2510\n",
            "\n",
            "    accuracy                           0.79     74432\n",
            "   macro avg       0.73      0.66      0.69     74432\n",
            "weighted avg       0.78      0.79      0.78     74432\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37312\n",
            "           1       0.67      0.54      0.60      3953\n",
            "           2       0.69      0.67      0.68     13113\n",
            "           3       0.62      0.39      0.48      2175\n",
            "           4       0.76      0.79      0.78     15401\n",
            "           5       0.76      0.68      0.72      2510\n",
            "\n",
            "    accuracy                           0.79     74464\n",
            "   macro avg       0.73      0.66      0.69     74464\n",
            "weighted avg       0.78      0.79      0.78     74464\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37326\n",
            "           1       0.67      0.54      0.60      3953\n",
            "           2       0.69      0.67      0.68     13122\n",
            "           3       0.62      0.39      0.48      2177\n",
            "           4       0.76      0.79      0.78     15408\n",
            "           5       0.76      0.68      0.72      2510\n",
            "\n",
            "    accuracy                           0.79     74496\n",
            "   macro avg       0.73      0.66      0.69     74496\n",
            "weighted avg       0.78      0.79      0.78     74496\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37343\n",
            "           1       0.67      0.54      0.60      3953\n",
            "           2       0.69      0.67      0.68     13128\n",
            "           3       0.62      0.39      0.48      2177\n",
            "           4       0.76      0.79      0.78     15416\n",
            "           5       0.76      0.68      0.72      2511\n",
            "\n",
            "    accuracy                           0.79     74528\n",
            "   macro avg       0.73      0.66      0.69     74528\n",
            "weighted avg       0.78      0.79      0.78     74528\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37358\n",
            "           1       0.67      0.54      0.60      3955\n",
            "           2       0.69      0.67      0.68     13135\n",
            "           3       0.62      0.39      0.48      2177\n",
            "           4       0.76      0.79      0.78     15424\n",
            "           5       0.76      0.68      0.72      2511\n",
            "\n",
            "    accuracy                           0.79     74560\n",
            "   macro avg       0.73      0.66      0.69     74560\n",
            "weighted avg       0.78      0.79      0.78     74560\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37373\n",
            "           1       0.67      0.54      0.60      3956\n",
            "           2       0.69      0.67      0.68     13138\n",
            "           3       0.62      0.39      0.48      2178\n",
            "           4       0.76      0.79      0.78     15435\n",
            "           5       0.76      0.68      0.72      2512\n",
            "\n",
            "    accuracy                           0.79     74592\n",
            "   macro avg       0.73      0.66      0.69     74592\n",
            "weighted avg       0.78      0.79      0.78     74592\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37388\n",
            "           1       0.67      0.54      0.60      3956\n",
            "           2       0.69      0.67      0.68     13141\n",
            "           3       0.62      0.39      0.48      2180\n",
            "           4       0.76      0.79      0.78     15446\n",
            "           5       0.76      0.68      0.72      2513\n",
            "\n",
            "    accuracy                           0.79     74624\n",
            "   macro avg       0.73      0.66      0.69     74624\n",
            "weighted avg       0.78      0.79      0.78     74624\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37407\n",
            "           1       0.67      0.54      0.60      3959\n",
            "           2       0.69      0.67      0.68     13147\n",
            "           3       0.62      0.39      0.48      2180\n",
            "           4       0.76      0.79      0.78     15450\n",
            "           5       0.76      0.68      0.72      2513\n",
            "\n",
            "    accuracy                           0.79     74656\n",
            "   macro avg       0.73      0.66      0.69     74656\n",
            "weighted avg       0.78      0.79      0.78     74656\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37421\n",
            "           1       0.67      0.54      0.60      3960\n",
            "           2       0.69      0.67      0.68     13154\n",
            "           3       0.62      0.39      0.48      2182\n",
            "           4       0.76      0.79      0.78     15456\n",
            "           5       0.76      0.68      0.72      2515\n",
            "\n",
            "    accuracy                           0.79     74688\n",
            "   macro avg       0.73      0.66      0.69     74688\n",
            "weighted avg       0.78      0.79      0.78     74688\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37439\n",
            "           1       0.67      0.54      0.60      3963\n",
            "           2       0.69      0.67      0.68     13157\n",
            "           3       0.62      0.39      0.48      2184\n",
            "           4       0.76      0.79      0.78     15461\n",
            "           5       0.76      0.68      0.72      2516\n",
            "\n",
            "    accuracy                           0.79     74720\n",
            "   macro avg       0.73      0.66      0.69     74720\n",
            "weighted avg       0.78      0.79      0.78     74720\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37455\n",
            "           1       0.67      0.54      0.60      3966\n",
            "           2       0.69      0.67      0.68     13162\n",
            "           3       0.63      0.39      0.48      2185\n",
            "           4       0.76      0.79      0.78     15467\n",
            "           5       0.76      0.68      0.72      2517\n",
            "\n",
            "    accuracy                           0.79     74752\n",
            "   macro avg       0.73      0.66      0.69     74752\n",
            "weighted avg       0.78      0.79      0.78     74752\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37473\n",
            "           1       0.67      0.54      0.60      3966\n",
            "           2       0.69      0.67      0.68     13169\n",
            "           3       0.63      0.39      0.48      2185\n",
            "           4       0.76      0.79      0.78     15473\n",
            "           5       0.76      0.68      0.72      2518\n",
            "\n",
            "    accuracy                           0.79     74784\n",
            "   macro avg       0.73      0.66      0.69     74784\n",
            "weighted avg       0.78      0.79      0.78     74784\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37494\n",
            "           1       0.67      0.54      0.60      3968\n",
            "           2       0.69      0.67      0.68     13172\n",
            "           3       0.63      0.39      0.48      2185\n",
            "           4       0.76      0.79      0.78     15479\n",
            "           5       0.76      0.68      0.72      2518\n",
            "\n",
            "    accuracy                           0.79     74816\n",
            "   macro avg       0.73      0.66      0.69     74816\n",
            "weighted avg       0.78      0.79      0.78     74816\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37512\n",
            "           1       0.67      0.54      0.60      3969\n",
            "           2       0.69      0.67      0.68     13175\n",
            "           3       0.63      0.39      0.48      2188\n",
            "           4       0.76      0.79      0.78     15486\n",
            "           5       0.76      0.68      0.72      2518\n",
            "\n",
            "    accuracy                           0.79     74848\n",
            "   macro avg       0.73      0.66      0.69     74848\n",
            "weighted avg       0.78      0.79      0.78     74848\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37525\n",
            "           1       0.67      0.54      0.60      3970\n",
            "           2       0.69      0.67      0.68     13181\n",
            "           3       0.63      0.39      0.48      2189\n",
            "           4       0.76      0.79      0.78     15497\n",
            "           5       0.76      0.68      0.72      2518\n",
            "\n",
            "    accuracy                           0.79     74880\n",
            "   macro avg       0.73      0.66      0.69     74880\n",
            "weighted avg       0.78      0.79      0.78     74880\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37539\n",
            "           1       0.67      0.54      0.60      3972\n",
            "           2       0.69      0.67      0.68     13189\n",
            "           3       0.63      0.39      0.48      2190\n",
            "           4       0.76      0.79      0.78     15504\n",
            "           5       0.76      0.68      0.72      2518\n",
            "\n",
            "    accuracy                           0.79     74912\n",
            "   macro avg       0.73      0.66      0.69     74912\n",
            "weighted avg       0.78      0.79      0.78     74912\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37554\n",
            "           1       0.67      0.54      0.60      3975\n",
            "           2       0.69      0.67      0.68     13196\n",
            "           3       0.62      0.39      0.48      2190\n",
            "           4       0.76      0.79      0.78     15510\n",
            "           5       0.76      0.68      0.72      2519\n",
            "\n",
            "    accuracy                           0.79     74944\n",
            "   macro avg       0.73      0.66      0.69     74944\n",
            "weighted avg       0.78      0.79      0.78     74944\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37575\n",
            "           1       0.67      0.54      0.60      3977\n",
            "           2       0.69      0.67      0.68     13201\n",
            "           3       0.62      0.39      0.48      2192\n",
            "           4       0.76      0.79      0.78     15512\n",
            "           5       0.76      0.68      0.72      2519\n",
            "\n",
            "    accuracy                           0.79     74976\n",
            "   macro avg       0.73      0.66      0.69     74976\n",
            "weighted avg       0.78      0.79      0.78     74976\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37588\n",
            "           1       0.67      0.54      0.60      3979\n",
            "           2       0.69      0.67      0.68     13208\n",
            "           3       0.62      0.39      0.48      2193\n",
            "           4       0.76      0.79      0.78     15518\n",
            "           5       0.76      0.68      0.72      2522\n",
            "\n",
            "    accuracy                           0.78     75008\n",
            "   macro avg       0.73      0.66      0.69     75008\n",
            "weighted avg       0.78      0.78      0.78     75008\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37606\n",
            "           1       0.67      0.54      0.60      3980\n",
            "           2       0.69      0.67      0.68     13213\n",
            "           3       0.62      0.39      0.48      2194\n",
            "           4       0.76      0.79      0.78     15525\n",
            "           5       0.76      0.68      0.72      2522\n",
            "\n",
            "    accuracy                           0.78     75040\n",
            "   macro avg       0.72      0.66      0.69     75040\n",
            "weighted avg       0.78      0.78      0.78     75040\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37625\n",
            "           1       0.67      0.54      0.60      3981\n",
            "           2       0.69      0.67      0.68     13213\n",
            "           3       0.62      0.39      0.48      2194\n",
            "           4       0.76      0.79      0.78     15534\n",
            "           5       0.76      0.68      0.72      2525\n",
            "\n",
            "    accuracy                           0.78     75072\n",
            "   macro avg       0.72      0.66      0.69     75072\n",
            "weighted avg       0.78      0.78      0.78     75072\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37638\n",
            "           1       0.67      0.54      0.60      3982\n",
            "           2       0.69      0.67      0.68     13220\n",
            "           3       0.62      0.39      0.48      2196\n",
            "           4       0.76      0.79      0.78     15542\n",
            "           5       0.76      0.68      0.72      2526\n",
            "\n",
            "    accuracy                           0.78     75104\n",
            "   macro avg       0.72      0.66      0.69     75104\n",
            "weighted avg       0.78      0.78      0.78     75104\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37658\n",
            "           1       0.67      0.54      0.60      3984\n",
            "           2       0.69      0.67      0.68     13224\n",
            "           3       0.62      0.39      0.48      2196\n",
            "           4       0.76      0.79      0.78     15546\n",
            "           5       0.76      0.68      0.72      2528\n",
            "\n",
            "    accuracy                           0.78     75136\n",
            "   macro avg       0.72      0.66      0.69     75136\n",
            "weighted avg       0.78      0.78      0.78     75136\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37672\n",
            "           1       0.67      0.54      0.60      3985\n",
            "           2       0.69      0.67      0.68     13231\n",
            "           3       0.62      0.39      0.48      2198\n",
            "           4       0.76      0.79      0.78     15554\n",
            "           5       0.76      0.68      0.72      2528\n",
            "\n",
            "    accuracy                           0.78     75168\n",
            "   macro avg       0.72      0.66      0.69     75168\n",
            "weighted avg       0.78      0.78      0.78     75168\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37689\n",
            "           1       0.67      0.54      0.60      3985\n",
            "           2       0.69      0.67      0.68     13237\n",
            "           3       0.62      0.39      0.48      2198\n",
            "           4       0.76      0.79      0.78     15562\n",
            "           5       0.76      0.68      0.72      2529\n",
            "\n",
            "    accuracy                           0.78     75200\n",
            "   macro avg       0.72      0.66      0.69     75200\n",
            "weighted avg       0.78      0.78      0.78     75200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37707\n",
            "           1       0.67      0.54      0.60      3986\n",
            "           2       0.69      0.67      0.68     13241\n",
            "           3       0.62      0.39      0.48      2199\n",
            "           4       0.76      0.79      0.78     15568\n",
            "           5       0.76      0.68      0.72      2531\n",
            "\n",
            "    accuracy                           0.78     75232\n",
            "   macro avg       0.72      0.66      0.69     75232\n",
            "weighted avg       0.78      0.78      0.78     75232\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37723\n",
            "           1       0.67      0.54      0.60      3986\n",
            "           2       0.69      0.67      0.68     13244\n",
            "           3       0.62      0.39      0.48      2202\n",
            "           4       0.76      0.79      0.78     15577\n",
            "           5       0.76      0.68      0.72      2532\n",
            "\n",
            "    accuracy                           0.78     75264\n",
            "   macro avg       0.72      0.66      0.69     75264\n",
            "weighted avg       0.78      0.78      0.78     75264\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37741\n",
            "           1       0.67      0.54      0.60      3986\n",
            "           2       0.69      0.67      0.68     13247\n",
            "           3       0.63      0.39      0.48      2203\n",
            "           4       0.76      0.79      0.78     15586\n",
            "           5       0.76      0.68      0.72      2533\n",
            "\n",
            "    accuracy                           0.78     75296\n",
            "   macro avg       0.72      0.66      0.69     75296\n",
            "weighted avg       0.78      0.78      0.78     75296\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37759\n",
            "           1       0.67      0.54      0.60      3989\n",
            "           2       0.69      0.67      0.68     13252\n",
            "           3       0.62      0.39      0.48      2203\n",
            "           4       0.76      0.79      0.78     15591\n",
            "           5       0.76      0.68      0.72      2534\n",
            "\n",
            "    accuracy                           0.78     75328\n",
            "   macro avg       0.72      0.66      0.69     75328\n",
            "weighted avg       0.78      0.78      0.78     75328\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37777\n",
            "           1       0.67      0.54      0.60      3989\n",
            "           2       0.69      0.67      0.68     13258\n",
            "           3       0.62      0.39      0.48      2205\n",
            "           4       0.76      0.79      0.78     15596\n",
            "           5       0.76      0.68      0.72      2535\n",
            "\n",
            "    accuracy                           0.78     75360\n",
            "   macro avg       0.72      0.66      0.69     75360\n",
            "weighted avg       0.78      0.78      0.78     75360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37795\n",
            "           1       0.67      0.54      0.60      3991\n",
            "           2       0.69      0.67      0.68     13264\n",
            "           3       0.63      0.39      0.48      2206\n",
            "           4       0.76      0.79      0.78     15600\n",
            "           5       0.76      0.68      0.72      2536\n",
            "\n",
            "    accuracy                           0.78     75392\n",
            "   macro avg       0.72      0.66      0.69     75392\n",
            "weighted avg       0.78      0.78      0.78     75392\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37811\n",
            "           1       0.67      0.54      0.60      3991\n",
            "           2       0.69      0.67      0.68     13272\n",
            "           3       0.63      0.39      0.48      2207\n",
            "           4       0.76      0.79      0.78     15605\n",
            "           5       0.76      0.68      0.72      2538\n",
            "\n",
            "    accuracy                           0.78     75424\n",
            "   macro avg       0.72      0.66      0.69     75424\n",
            "weighted avg       0.78      0.78      0.78     75424\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37832\n",
            "           1       0.67      0.54      0.60      3994\n",
            "           2       0.69      0.67      0.68     13276\n",
            "           3       0.63      0.39      0.48      2208\n",
            "           4       0.76      0.79      0.78     15607\n",
            "           5       0.76      0.68      0.72      2539\n",
            "\n",
            "    accuracy                           0.78     75456\n",
            "   macro avg       0.72      0.66      0.69     75456\n",
            "weighted avg       0.78      0.78      0.78     75456\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37851\n",
            "           1       0.67      0.54      0.60      3995\n",
            "           2       0.69      0.67      0.68     13280\n",
            "           3       0.63      0.39      0.48      2209\n",
            "           4       0.76      0.79      0.78     15613\n",
            "           5       0.76      0.68      0.72      2540\n",
            "\n",
            "    accuracy                           0.78     75488\n",
            "   macro avg       0.72      0.66      0.69     75488\n",
            "weighted avg       0.78      0.78      0.78     75488\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37866\n",
            "           1       0.67      0.54      0.60      3998\n",
            "           2       0.69      0.67      0.68     13283\n",
            "           3       0.63      0.39      0.48      2210\n",
            "           4       0.76      0.79      0.78     15621\n",
            "           5       0.76      0.68      0.72      2542\n",
            "\n",
            "    accuracy                           0.78     75520\n",
            "   macro avg       0.72      0.66      0.69     75520\n",
            "weighted avg       0.78      0.78      0.78     75520\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37881\n",
            "           1       0.67      0.54      0.60      3999\n",
            "           2       0.69      0.67      0.68     13291\n",
            "           3       0.62      0.39      0.48      2210\n",
            "           4       0.76      0.79      0.78     15628\n",
            "           5       0.76      0.68      0.72      2543\n",
            "\n",
            "    accuracy                           0.78     75552\n",
            "   macro avg       0.72      0.66      0.69     75552\n",
            "weighted avg       0.78      0.78      0.78     75552\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37896\n",
            "           1       0.67      0.54      0.60      4000\n",
            "           2       0.69      0.67      0.68     13298\n",
            "           3       0.63      0.39      0.48      2213\n",
            "           4       0.76      0.79      0.78     15632\n",
            "           5       0.76      0.68      0.72      2545\n",
            "\n",
            "    accuracy                           0.78     75584\n",
            "   macro avg       0.72      0.66      0.69     75584\n",
            "weighted avg       0.78      0.78      0.78     75584\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37908\n",
            "           1       0.67      0.54      0.60      4000\n",
            "           2       0.69      0.67      0.68     13305\n",
            "           3       0.63      0.39      0.48      2217\n",
            "           4       0.76      0.79      0.78     15641\n",
            "           5       0.76      0.68      0.72      2545\n",
            "\n",
            "    accuracy                           0.78     75616\n",
            "   macro avg       0.72      0.66      0.69     75616\n",
            "weighted avg       0.78      0.78      0.78     75616\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37926\n",
            "           1       0.67      0.54      0.60      4000\n",
            "           2       0.69      0.67      0.68     13312\n",
            "           3       0.63      0.39      0.48      2221\n",
            "           4       0.76      0.79      0.78     15644\n",
            "           5       0.76      0.68      0.72      2545\n",
            "\n",
            "    accuracy                           0.78     75648\n",
            "   macro avg       0.72      0.66      0.69     75648\n",
            "weighted avg       0.78      0.78      0.78     75648\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37947\n",
            "           1       0.67      0.54      0.60      4000\n",
            "           2       0.69      0.67      0.68     13316\n",
            "           3       0.63      0.39      0.48      2221\n",
            "           4       0.76      0.79      0.78     15650\n",
            "           5       0.76      0.68      0.72      2546\n",
            "\n",
            "    accuracy                           0.78     75680\n",
            "   macro avg       0.72      0.66      0.69     75680\n",
            "weighted avg       0.78      0.78      0.78     75680\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37963\n",
            "           1       0.67      0.54      0.60      4001\n",
            "           2       0.69      0.67      0.68     13320\n",
            "           3       0.63      0.39      0.48      2223\n",
            "           4       0.76      0.79      0.78     15659\n",
            "           5       0.76      0.68      0.72      2546\n",
            "\n",
            "    accuracy                           0.78     75712\n",
            "   macro avg       0.72      0.66      0.69     75712\n",
            "weighted avg       0.78      0.78      0.78     75712\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     37981\n",
            "           1       0.67      0.54      0.60      4003\n",
            "           2       0.69      0.67      0.68     13328\n",
            "           3       0.63      0.39      0.48      2223\n",
            "           4       0.76      0.79      0.78     15663\n",
            "           5       0.76      0.68      0.72      2546\n",
            "\n",
            "    accuracy                           0.78     75744\n",
            "   macro avg       0.72      0.66      0.69     75744\n",
            "weighted avg       0.78      0.78      0.78     75744\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38002\n",
            "           1       0.67      0.54      0.60      4004\n",
            "           2       0.69      0.67      0.68     13330\n",
            "           3       0.62      0.39      0.48      2224\n",
            "           4       0.76      0.79      0.78     15670\n",
            "           5       0.76      0.68      0.72      2546\n",
            "\n",
            "    accuracy                           0.78     75776\n",
            "   macro avg       0.72      0.66      0.69     75776\n",
            "weighted avg       0.78      0.78      0.78     75776\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38024\n",
            "           1       0.67      0.54      0.60      4004\n",
            "           2       0.69      0.67      0.68     13333\n",
            "           3       0.62      0.39      0.48      2226\n",
            "           4       0.76      0.79      0.78     15675\n",
            "           5       0.76      0.68      0.72      2546\n",
            "\n",
            "    accuracy                           0.78     75808\n",
            "   macro avg       0.72      0.66      0.69     75808\n",
            "weighted avg       0.78      0.78      0.78     75808\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38039\n",
            "           1       0.67      0.54      0.60      4006\n",
            "           2       0.69      0.67      0.68     13339\n",
            "           3       0.62      0.39      0.48      2228\n",
            "           4       0.76      0.79      0.78     15680\n",
            "           5       0.76      0.68      0.72      2548\n",
            "\n",
            "    accuracy                           0.78     75840\n",
            "   macro avg       0.72      0.66      0.69     75840\n",
            "weighted avg       0.78      0.78      0.78     75840\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38055\n",
            "           1       0.67      0.54      0.60      4006\n",
            "           2       0.69      0.67      0.68     13347\n",
            "           3       0.63      0.39      0.48      2229\n",
            "           4       0.76      0.79      0.78     15685\n",
            "           5       0.76      0.68      0.72      2550\n",
            "\n",
            "    accuracy                           0.78     75872\n",
            "   macro avg       0.72      0.66      0.69     75872\n",
            "weighted avg       0.78      0.78      0.78     75872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38073\n",
            "           1       0.67      0.54      0.60      4008\n",
            "           2       0.69      0.67      0.68     13350\n",
            "           3       0.62      0.39      0.48      2229\n",
            "           4       0.76      0.79      0.78     15694\n",
            "           5       0.76      0.68      0.72      2550\n",
            "\n",
            "    accuracy                           0.78     75904\n",
            "   macro avg       0.72      0.66      0.69     75904\n",
            "weighted avg       0.78      0.78      0.78     75904\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38089\n",
            "           1       0.67      0.54      0.60      4009\n",
            "           2       0.69      0.67      0.68     13355\n",
            "           3       0.62      0.39      0.48      2230\n",
            "           4       0.76      0.79      0.78     15702\n",
            "           5       0.76      0.68      0.72      2551\n",
            "\n",
            "    accuracy                           0.78     75936\n",
            "   macro avg       0.72      0.66      0.69     75936\n",
            "weighted avg       0.78      0.78      0.78     75936\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38106\n",
            "           1       0.67      0.54      0.60      4010\n",
            "           2       0.69      0.67      0.68     13361\n",
            "           3       0.62      0.39      0.48      2230\n",
            "           4       0.76      0.79      0.78     15709\n",
            "           5       0.76      0.68      0.72      2552\n",
            "\n",
            "    accuracy                           0.78     75968\n",
            "   macro avg       0.72      0.66      0.69     75968\n",
            "weighted avg       0.78      0.78      0.78     75968\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38120\n",
            "           1       0.67      0.54      0.60      4010\n",
            "           2       0.69      0.67      0.68     13374\n",
            "           3       0.62      0.39      0.48      2230\n",
            "           4       0.76      0.79      0.78     15713\n",
            "           5       0.76      0.68      0.72      2553\n",
            "\n",
            "    accuracy                           0.78     76000\n",
            "   macro avg       0.72      0.66      0.69     76000\n",
            "weighted avg       0.78      0.78      0.78     76000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38138\n",
            "           1       0.67      0.54      0.60      4012\n",
            "           2       0.69      0.67      0.68     13379\n",
            "           3       0.63      0.39      0.48      2231\n",
            "           4       0.76      0.79      0.78     15719\n",
            "           5       0.76      0.68      0.72      2553\n",
            "\n",
            "    accuracy                           0.78     76032\n",
            "   macro avg       0.72      0.66      0.69     76032\n",
            "weighted avg       0.78      0.78      0.78     76032\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38156\n",
            "           1       0.67      0.54      0.60      4016\n",
            "           2       0.69      0.67      0.68     13383\n",
            "           3       0.63      0.39      0.48      2232\n",
            "           4       0.76      0.79      0.78     15723\n",
            "           5       0.76      0.68      0.72      2554\n",
            "\n",
            "    accuracy                           0.78     76064\n",
            "   macro avg       0.72      0.66      0.69     76064\n",
            "weighted avg       0.78      0.78      0.78     76064\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38173\n",
            "           1       0.67      0.54      0.60      4017\n",
            "           2       0.69      0.67      0.68     13386\n",
            "           3       0.63      0.39      0.48      2234\n",
            "           4       0.76      0.79      0.78     15731\n",
            "           5       0.76      0.68      0.72      2555\n",
            "\n",
            "    accuracy                           0.78     76096\n",
            "   macro avg       0.72      0.66      0.69     76096\n",
            "weighted avg       0.78      0.78      0.78     76096\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38192\n",
            "           1       0.67      0.54      0.60      4017\n",
            "           2       0.69      0.67      0.68     13391\n",
            "           3       0.63      0.39      0.48      2234\n",
            "           4       0.76      0.79      0.78     15738\n",
            "           5       0.76      0.68      0.72      2556\n",
            "\n",
            "    accuracy                           0.78     76128\n",
            "   macro avg       0.72      0.66      0.69     76128\n",
            "weighted avg       0.78      0.78      0.78     76128\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38211\n",
            "           1       0.67      0.54      0.60      4018\n",
            "           2       0.69      0.67      0.68     13396\n",
            "           3       0.63      0.39      0.48      2234\n",
            "           4       0.76      0.79      0.78     15745\n",
            "           5       0.76      0.68      0.72      2556\n",
            "\n",
            "    accuracy                           0.78     76160\n",
            "   macro avg       0.72      0.66      0.69     76160\n",
            "weighted avg       0.78      0.78      0.78     76160\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38225\n",
            "           1       0.67      0.54      0.60      4020\n",
            "           2       0.69      0.67      0.68     13401\n",
            "           3       0.63      0.39      0.48      2235\n",
            "           4       0.76      0.79      0.78     15754\n",
            "           5       0.76      0.68      0.72      2557\n",
            "\n",
            "    accuracy                           0.78     76192\n",
            "   macro avg       0.72      0.66      0.69     76192\n",
            "weighted avg       0.78      0.78      0.78     76192\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38246\n",
            "           1       0.67      0.54      0.60      4021\n",
            "           2       0.69      0.67      0.68     13404\n",
            "           3       0.63      0.39      0.48      2235\n",
            "           4       0.76      0.79      0.78     15760\n",
            "           5       0.76      0.68      0.72      2558\n",
            "\n",
            "    accuracy                           0.78     76224\n",
            "   macro avg       0.72      0.66      0.69     76224\n",
            "weighted avg       0.78      0.78      0.78     76224\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38260\n",
            "           1       0.67      0.54      0.60      4024\n",
            "           2       0.69      0.67      0.68     13406\n",
            "           3       0.63      0.39      0.48      2237\n",
            "           4       0.76      0.79      0.78     15769\n",
            "           5       0.76      0.68      0.72      2560\n",
            "\n",
            "    accuracy                           0.78     76256\n",
            "   macro avg       0.72      0.66      0.69     76256\n",
            "weighted avg       0.78      0.78      0.78     76256\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38276\n",
            "           1       0.67      0.54      0.60      4027\n",
            "           2       0.69      0.67      0.68     13411\n",
            "           3       0.63      0.39      0.48      2237\n",
            "           4       0.76      0.79      0.78     15776\n",
            "           5       0.76      0.68      0.72      2561\n",
            "\n",
            "    accuracy                           0.78     76288\n",
            "   macro avg       0.72      0.66      0.69     76288\n",
            "weighted avg       0.78      0.78      0.78     76288\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38291\n",
            "           1       0.67      0.54      0.60      4031\n",
            "           2       0.69      0.67      0.68     13411\n",
            "           3       0.63      0.39      0.48      2239\n",
            "           4       0.76      0.79      0.78     15787\n",
            "           5       0.76      0.68      0.72      2561\n",
            "\n",
            "    accuracy                           0.78     76320\n",
            "   macro avg       0.72      0.66      0.69     76320\n",
            "weighted avg       0.78      0.78      0.78     76320\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38308\n",
            "           1       0.67      0.54      0.60      4033\n",
            "           2       0.69      0.67      0.68     13415\n",
            "           3       0.63      0.39      0.48      2239\n",
            "           4       0.76      0.79      0.78     15794\n",
            "           5       0.76      0.68      0.72      2563\n",
            "\n",
            "    accuracy                           0.78     76352\n",
            "   macro avg       0.72      0.66      0.69     76352\n",
            "weighted avg       0.78      0.78      0.78     76352\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38325\n",
            "           1       0.67      0.54      0.60      4034\n",
            "           2       0.69      0.67      0.68     13421\n",
            "           3       0.63      0.39      0.48      2241\n",
            "           4       0.76      0.79      0.78     15800\n",
            "           5       0.76      0.68      0.72      2563\n",
            "\n",
            "    accuracy                           0.78     76384\n",
            "   macro avg       0.72      0.66      0.69     76384\n",
            "weighted avg       0.78      0.78      0.78     76384\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38338\n",
            "           1       0.67      0.54      0.60      4037\n",
            "           2       0.69      0.67      0.68     13426\n",
            "           3       0.63      0.39      0.48      2241\n",
            "           4       0.76      0.79      0.78     15810\n",
            "           5       0.76      0.68      0.72      2564\n",
            "\n",
            "    accuracy                           0.78     76416\n",
            "   macro avg       0.72      0.66      0.69     76416\n",
            "weighted avg       0.78      0.78      0.78     76416\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38353\n",
            "           1       0.67      0.54      0.60      4037\n",
            "           2       0.69      0.67      0.68     13434\n",
            "           3       0.62      0.39      0.48      2241\n",
            "           4       0.76      0.79      0.78     15818\n",
            "           5       0.76      0.68      0.72      2565\n",
            "\n",
            "    accuracy                           0.79     76448\n",
            "   macro avg       0.72      0.66      0.69     76448\n",
            "weighted avg       0.78      0.79      0.78     76448\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38367\n",
            "           1       0.67      0.54      0.60      4038\n",
            "           2       0.69      0.67      0.68     13441\n",
            "           3       0.62      0.39      0.48      2242\n",
            "           4       0.76      0.79      0.78     15825\n",
            "           5       0.76      0.68      0.72      2567\n",
            "\n",
            "    accuracy                           0.79     76480\n",
            "   macro avg       0.72      0.66      0.69     76480\n",
            "weighted avg       0.78      0.79      0.78     76480\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38381\n",
            "           1       0.67      0.54      0.60      4040\n",
            "           2       0.69      0.67      0.68     13449\n",
            "           3       0.62      0.39      0.48      2244\n",
            "           4       0.76      0.79      0.78     15829\n",
            "           5       0.76      0.68      0.72      2569\n",
            "\n",
            "    accuracy                           0.79     76512\n",
            "   macro avg       0.72      0.66      0.69     76512\n",
            "weighted avg       0.78      0.79      0.78     76512\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38400\n",
            "           1       0.67      0.54      0.60      4043\n",
            "           2       0.69      0.67      0.68     13454\n",
            "           3       0.63      0.39      0.48      2245\n",
            "           4       0.76      0.79      0.78     15833\n",
            "           5       0.76      0.68      0.72      2569\n",
            "\n",
            "    accuracy                           0.79     76544\n",
            "   macro avg       0.72      0.66      0.69     76544\n",
            "weighted avg       0.78      0.79      0.78     76544\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38415\n",
            "           1       0.67      0.54      0.60      4044\n",
            "           2       0.69      0.67      0.68     13459\n",
            "           3       0.63      0.39      0.48      2245\n",
            "           4       0.76      0.79      0.78     15841\n",
            "           5       0.76      0.68      0.72      2572\n",
            "\n",
            "    accuracy                           0.79     76576\n",
            "   macro avg       0.72      0.66      0.69     76576\n",
            "weighted avg       0.78      0.79      0.78     76576\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38427\n",
            "           1       0.67      0.54      0.60      4046\n",
            "           2       0.69      0.67      0.68     13463\n",
            "           3       0.63      0.39      0.48      2246\n",
            "           4       0.76      0.79      0.78     15853\n",
            "           5       0.76      0.68      0.72      2573\n",
            "\n",
            "    accuracy                           0.79     76608\n",
            "   macro avg       0.72      0.66      0.69     76608\n",
            "weighted avg       0.78      0.79      0.78     76608\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38442\n",
            "           1       0.67      0.54      0.60      4047\n",
            "           2       0.69      0.67      0.68     13471\n",
            "           3       0.63      0.39      0.48      2246\n",
            "           4       0.76      0.79      0.78     15860\n",
            "           5       0.76      0.68      0.72      2574\n",
            "\n",
            "    accuracy                           0.79     76640\n",
            "   macro avg       0.72      0.66      0.69     76640\n",
            "weighted avg       0.78      0.79      0.78     76640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38463\n",
            "           1       0.67      0.54      0.60      4048\n",
            "           2       0.69      0.67      0.68     13474\n",
            "           3       0.62      0.39      0.48      2247\n",
            "           4       0.76      0.79      0.78     15865\n",
            "           5       0.76      0.68      0.72      2575\n",
            "\n",
            "    accuracy                           0.79     76672\n",
            "   macro avg       0.72      0.66      0.69     76672\n",
            "weighted avg       0.78      0.79      0.78     76672\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38480\n",
            "           1       0.67      0.54      0.60      4050\n",
            "           2       0.69      0.67      0.68     13478\n",
            "           3       0.62      0.39      0.48      2248\n",
            "           4       0.76      0.79      0.78     15872\n",
            "           5       0.76      0.68      0.72      2576\n",
            "\n",
            "    accuracy                           0.79     76704\n",
            "   macro avg       0.72      0.66      0.69     76704\n",
            "weighted avg       0.78      0.79      0.78     76704\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38495\n",
            "           1       0.67      0.54      0.60      4052\n",
            "           2       0.69      0.67      0.68     13483\n",
            "           3       0.62      0.39      0.48      2249\n",
            "           4       0.76      0.79      0.78     15881\n",
            "           5       0.76      0.68      0.72      2576\n",
            "\n",
            "    accuracy                           0.79     76736\n",
            "   macro avg       0.72      0.66      0.69     76736\n",
            "weighted avg       0.78      0.79      0.78     76736\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38511\n",
            "           1       0.67      0.54      0.60      4056\n",
            "           2       0.69      0.67      0.68     13487\n",
            "           3       0.62      0.39      0.48      2250\n",
            "           4       0.76      0.79      0.78     15887\n",
            "           5       0.76      0.68      0.72      2577\n",
            "\n",
            "    accuracy                           0.79     76768\n",
            "   macro avg       0.72      0.66      0.69     76768\n",
            "weighted avg       0.78      0.79      0.78     76768\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38530\n",
            "           1       0.67      0.54      0.60      4056\n",
            "           2       0.69      0.67      0.68     13495\n",
            "           3       0.62      0.39      0.48      2251\n",
            "           4       0.76      0.79      0.78     15890\n",
            "           5       0.76      0.68      0.72      2578\n",
            "\n",
            "    accuracy                           0.79     76800\n",
            "   macro avg       0.72      0.66      0.69     76800\n",
            "weighted avg       0.78      0.79      0.78     76800\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38548\n",
            "           1       0.67      0.54      0.60      4056\n",
            "           2       0.69      0.67      0.68     13500\n",
            "           3       0.62      0.39      0.48      2251\n",
            "           4       0.76      0.79      0.78     15897\n",
            "           5       0.76      0.68      0.72      2580\n",
            "\n",
            "    accuracy                           0.79     76832\n",
            "   macro avg       0.72      0.66      0.69     76832\n",
            "weighted avg       0.78      0.79      0.78     76832\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38566\n",
            "           1       0.67      0.54      0.60      4056\n",
            "           2       0.69      0.67      0.68     13505\n",
            "           3       0.62      0.39      0.48      2252\n",
            "           4       0.76      0.79      0.78     15904\n",
            "           5       0.76      0.68      0.72      2581\n",
            "\n",
            "    accuracy                           0.79     76864\n",
            "   macro avg       0.72      0.66      0.69     76864\n",
            "weighted avg       0.78      0.79      0.78     76864\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38583\n",
            "           1       0.67      0.54      0.60      4057\n",
            "           2       0.69      0.67      0.68     13512\n",
            "           3       0.62      0.39      0.48      2252\n",
            "           4       0.76      0.79      0.78     15911\n",
            "           5       0.76      0.68      0.72      2581\n",
            "\n",
            "    accuracy                           0.79     76896\n",
            "   macro avg       0.72      0.66      0.69     76896\n",
            "weighted avg       0.78      0.79      0.78     76896\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38596\n",
            "           1       0.67      0.54      0.60      4059\n",
            "           2       0.69      0.67      0.68     13518\n",
            "           3       0.62      0.39      0.48      2253\n",
            "           4       0.76      0.79      0.78     15921\n",
            "           5       0.76      0.68      0.72      2581\n",
            "\n",
            "    accuracy                           0.79     76928\n",
            "   macro avg       0.72      0.66      0.69     76928\n",
            "weighted avg       0.78      0.79      0.78     76928\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38613\n",
            "           1       0.67      0.54      0.60      4061\n",
            "           2       0.69      0.67      0.68     13524\n",
            "           3       0.62      0.39      0.48      2253\n",
            "           4       0.76      0.79      0.78     15927\n",
            "           5       0.76      0.68      0.72      2582\n",
            "\n",
            "    accuracy                           0.79     76960\n",
            "   macro avg       0.72      0.66      0.69     76960\n",
            "weighted avg       0.78      0.79      0.78     76960\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38634\n",
            "           1       0.67      0.54      0.60      4062\n",
            "           2       0.69      0.67      0.68     13530\n",
            "           3       0.62      0.39      0.48      2253\n",
            "           4       0.76      0.79      0.78     15931\n",
            "           5       0.76      0.68      0.72      2582\n",
            "\n",
            "    accuracy                           0.79     76992\n",
            "   macro avg       0.72      0.66      0.69     76992\n",
            "weighted avg       0.78      0.79      0.78     76992\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38654\n",
            "           1       0.67      0.54      0.60      4065\n",
            "           2       0.69      0.67      0.68     13537\n",
            "           3       0.62      0.39      0.48      2253\n",
            "           4       0.76      0.79      0.78     15933\n",
            "           5       0.76      0.68      0.72      2582\n",
            "\n",
            "    accuracy                           0.79     77024\n",
            "   macro avg       0.72      0.66      0.69     77024\n",
            "weighted avg       0.78      0.79      0.78     77024\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38666\n",
            "           1       0.67      0.54      0.60      4067\n",
            "           2       0.69      0.67      0.68     13542\n",
            "           3       0.62      0.39      0.48      2255\n",
            "           4       0.76      0.79      0.78     15944\n",
            "           5       0.76      0.68      0.72      2582\n",
            "\n",
            "    accuracy                           0.79     77056\n",
            "   macro avg       0.72      0.66      0.69     77056\n",
            "weighted avg       0.78      0.79      0.78     77056\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38684\n",
            "           1       0.67      0.54      0.60      4071\n",
            "           2       0.69      0.67      0.68     13545\n",
            "           3       0.62      0.39      0.48      2255\n",
            "           4       0.76      0.79      0.78     15951\n",
            "           5       0.76      0.68      0.72      2582\n",
            "\n",
            "    accuracy                           0.79     77088\n",
            "   macro avg       0.72      0.66      0.69     77088\n",
            "weighted avg       0.78      0.79      0.78     77088\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38702\n",
            "           1       0.67      0.54      0.60      4073\n",
            "           2       0.69      0.67      0.68     13548\n",
            "           3       0.62      0.39      0.48      2256\n",
            "           4       0.76      0.79      0.78     15958\n",
            "           5       0.76      0.68      0.72      2583\n",
            "\n",
            "    accuracy                           0.79     77120\n",
            "   macro avg       0.72      0.66      0.69     77120\n",
            "weighted avg       0.78      0.79      0.78     77120\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38715\n",
            "           1       0.67      0.54      0.60      4076\n",
            "           2       0.69      0.67      0.68     13554\n",
            "           3       0.62      0.39      0.48      2257\n",
            "           4       0.76      0.79      0.78     15966\n",
            "           5       0.76      0.68      0.72      2584\n",
            "\n",
            "    accuracy                           0.79     77152\n",
            "   macro avg       0.72      0.66      0.69     77152\n",
            "weighted avg       0.78      0.79      0.78     77152\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38732\n",
            "           1       0.67      0.54      0.60      4076\n",
            "           2       0.69      0.67      0.68     13558\n",
            "           3       0.62      0.39      0.48      2258\n",
            "           4       0.76      0.79      0.78     15974\n",
            "           5       0.76      0.68      0.72      2586\n",
            "\n",
            "    accuracy                           0.79     77184\n",
            "   macro avg       0.72      0.66      0.69     77184\n",
            "weighted avg       0.78      0.79      0.78     77184\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38747\n",
            "           1       0.67      0.54      0.60      4077\n",
            "           2       0.69      0.67      0.68     13566\n",
            "           3       0.62      0.39      0.48      2259\n",
            "           4       0.76      0.79      0.78     15980\n",
            "           5       0.76      0.68      0.72      2587\n",
            "\n",
            "    accuracy                           0.79     77216\n",
            "   macro avg       0.72      0.66      0.69     77216\n",
            "weighted avg       0.78      0.79      0.78     77216\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38760\n",
            "           1       0.67      0.54      0.60      4082\n",
            "           2       0.69      0.67      0.68     13574\n",
            "           3       0.62      0.39      0.48      2259\n",
            "           4       0.76      0.79      0.78     15986\n",
            "           5       0.76      0.68      0.72      2587\n",
            "\n",
            "    accuracy                           0.79     77248\n",
            "   macro avg       0.72      0.66      0.69     77248\n",
            "weighted avg       0.78      0.79      0.78     77248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38773\n",
            "           1       0.67      0.54      0.60      4083\n",
            "           2       0.69      0.67      0.68     13578\n",
            "           3       0.62      0.39      0.48      2260\n",
            "           4       0.76      0.79      0.78     15996\n",
            "           5       0.76      0.68      0.72      2590\n",
            "\n",
            "    accuracy                           0.79     77280\n",
            "   macro avg       0.72      0.66      0.69     77280\n",
            "weighted avg       0.78      0.79      0.78     77280\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38790\n",
            "           1       0.67      0.54      0.60      4085\n",
            "           2       0.69      0.67      0.68     13582\n",
            "           3       0.62      0.39      0.48      2261\n",
            "           4       0.76      0.79      0.78     16004\n",
            "           5       0.76      0.68      0.72      2590\n",
            "\n",
            "    accuracy                           0.79     77312\n",
            "   macro avg       0.72      0.66      0.69     77312\n",
            "weighted avg       0.78      0.79      0.78     77312\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38808\n",
            "           1       0.67      0.54      0.60      4088\n",
            "           2       0.69      0.67      0.68     13589\n",
            "           3       0.62      0.39      0.48      2263\n",
            "           4       0.76      0.79      0.78     16005\n",
            "           5       0.76      0.68      0.72      2591\n",
            "\n",
            "    accuracy                           0.79     77344\n",
            "   macro avg       0.72      0.66      0.69     77344\n",
            "weighted avg       0.78      0.79      0.78     77344\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38824\n",
            "           1       0.67      0.54      0.60      4090\n",
            "           2       0.69      0.67      0.68     13594\n",
            "           3       0.62      0.39      0.48      2264\n",
            "           4       0.76      0.79      0.78     16011\n",
            "           5       0.76      0.68      0.72      2593\n",
            "\n",
            "    accuracy                           0.79     77376\n",
            "   macro avg       0.72      0.66      0.69     77376\n",
            "weighted avg       0.78      0.79      0.78     77376\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38838\n",
            "           1       0.67      0.54      0.60      4091\n",
            "           2       0.69      0.67      0.68     13603\n",
            "           3       0.62      0.39      0.48      2264\n",
            "           4       0.76      0.79      0.78     16018\n",
            "           5       0.76      0.68      0.72      2594\n",
            "\n",
            "    accuracy                           0.79     77408\n",
            "   macro avg       0.72      0.66      0.69     77408\n",
            "weighted avg       0.78      0.79      0.78     77408\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38854\n",
            "           1       0.67      0.54      0.60      4094\n",
            "           2       0.69      0.67      0.68     13608\n",
            "           3       0.62      0.39      0.48      2267\n",
            "           4       0.76      0.79      0.78     16021\n",
            "           5       0.76      0.68      0.72      2596\n",
            "\n",
            "    accuracy                           0.79     77440\n",
            "   macro avg       0.72      0.66      0.69     77440\n",
            "weighted avg       0.78      0.79      0.78     77440\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38869\n",
            "           1       0.67      0.54      0.60      4096\n",
            "           2       0.69      0.67      0.68     13610\n",
            "           3       0.62      0.39      0.48      2268\n",
            "           4       0.76      0.79      0.78     16030\n",
            "           5       0.76      0.68      0.72      2599\n",
            "\n",
            "    accuracy                           0.79     77472\n",
            "   macro avg       0.72      0.66      0.69     77472\n",
            "weighted avg       0.78      0.79      0.78     77472\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38887\n",
            "           1       0.67      0.54      0.60      4097\n",
            "           2       0.69      0.67      0.68     13613\n",
            "           3       0.62      0.39      0.48      2268\n",
            "           4       0.76      0.79      0.78     16039\n",
            "           5       0.76      0.68      0.72      2600\n",
            "\n",
            "    accuracy                           0.79     77504\n",
            "   macro avg       0.72      0.66      0.69     77504\n",
            "weighted avg       0.78      0.79      0.78     77504\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38904\n",
            "           1       0.67      0.54      0.60      4099\n",
            "           2       0.69      0.67      0.68     13616\n",
            "           3       0.62      0.39      0.48      2268\n",
            "           4       0.76      0.79      0.78     16047\n",
            "           5       0.76      0.68      0.72      2602\n",
            "\n",
            "    accuracy                           0.79     77536\n",
            "   macro avg       0.72      0.66      0.69     77536\n",
            "weighted avg       0.78      0.79      0.78     77536\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38916\n",
            "           1       0.67      0.54      0.60      4100\n",
            "           2       0.69      0.67      0.68     13622\n",
            "           3       0.62      0.39      0.48      2270\n",
            "           4       0.76      0.79      0.78     16055\n",
            "           5       0.76      0.68      0.72      2605\n",
            "\n",
            "    accuracy                           0.79     77568\n",
            "   macro avg       0.72      0.66      0.69     77568\n",
            "weighted avg       0.78      0.79      0.78     77568\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38937\n",
            "           1       0.67      0.54      0.60      4100\n",
            "           2       0.69      0.67      0.68     13627\n",
            "           3       0.62      0.39      0.48      2270\n",
            "           4       0.76      0.79      0.78     16060\n",
            "           5       0.76      0.68      0.72      2606\n",
            "\n",
            "    accuracy                           0.79     77600\n",
            "   macro avg       0.72      0.66      0.69     77600\n",
            "weighted avg       0.78      0.79      0.78     77600\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38959\n",
            "           1       0.67      0.54      0.60      4102\n",
            "           2       0.69      0.67      0.68     13632\n",
            "           3       0.62      0.39      0.48      2270\n",
            "           4       0.76      0.79      0.78     16063\n",
            "           5       0.76      0.68      0.72      2606\n",
            "\n",
            "    accuracy                           0.79     77632\n",
            "   macro avg       0.72      0.66      0.69     77632\n",
            "weighted avg       0.78      0.79      0.78     77632\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38978\n",
            "           1       0.67      0.54      0.60      4103\n",
            "           2       0.69      0.67      0.68     13639\n",
            "           3       0.62      0.39      0.48      2270\n",
            "           4       0.76      0.79      0.78     16068\n",
            "           5       0.76      0.68      0.72      2606\n",
            "\n",
            "    accuracy                           0.79     77664\n",
            "   macro avg       0.72      0.66      0.69     77664\n",
            "weighted avg       0.78      0.79      0.78     77664\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     38998\n",
            "           1       0.67      0.54      0.60      4106\n",
            "           2       0.69      0.67      0.68     13641\n",
            "           3       0.62      0.39      0.48      2272\n",
            "           4       0.76      0.79      0.78     16072\n",
            "           5       0.76      0.68      0.72      2607\n",
            "\n",
            "    accuracy                           0.79     77696\n",
            "   macro avg       0.72      0.66      0.69     77696\n",
            "weighted avg       0.78      0.79      0.78     77696\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39013\n",
            "           1       0.67      0.54      0.60      4108\n",
            "           2       0.69      0.67      0.68     13645\n",
            "           3       0.62      0.39      0.48      2273\n",
            "           4       0.76      0.79      0.78     16079\n",
            "           5       0.76      0.68      0.72      2610\n",
            "\n",
            "    accuracy                           0.79     77728\n",
            "   macro avg       0.72      0.66      0.69     77728\n",
            "weighted avg       0.78      0.79      0.78     77728\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39033\n",
            "           1       0.67      0.54      0.60      4108\n",
            "           2       0.69      0.67      0.68     13650\n",
            "           3       0.62      0.39      0.48      2274\n",
            "           4       0.76      0.79      0.78     16084\n",
            "           5       0.76      0.68      0.72      2611\n",
            "\n",
            "    accuracy                           0.79     77760\n",
            "   macro avg       0.72      0.66      0.69     77760\n",
            "weighted avg       0.78      0.79      0.78     77760\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39051\n",
            "           1       0.67      0.54      0.60      4113\n",
            "           2       0.69      0.67      0.68     13653\n",
            "           3       0.62      0.39      0.48      2275\n",
            "           4       0.76      0.79      0.78     16088\n",
            "           5       0.76      0.68      0.72      2612\n",
            "\n",
            "    accuracy                           0.79     77792\n",
            "   macro avg       0.72      0.66      0.69     77792\n",
            "weighted avg       0.78      0.79      0.78     77792\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39071\n",
            "           1       0.67      0.54      0.60      4113\n",
            "           2       0.69      0.67      0.68     13656\n",
            "           3       0.62      0.39      0.48      2276\n",
            "           4       0.76      0.79      0.78     16094\n",
            "           5       0.76      0.68      0.72      2614\n",
            "\n",
            "    accuracy                           0.79     77824\n",
            "   macro avg       0.72      0.66      0.69     77824\n",
            "weighted avg       0.78      0.79      0.78     77824\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39086\n",
            "           1       0.67      0.54      0.60      4115\n",
            "           2       0.69      0.67      0.68     13659\n",
            "           3       0.62      0.39      0.48      2278\n",
            "           4       0.76      0.79      0.78     16102\n",
            "           5       0.76      0.68      0.72      2616\n",
            "\n",
            "    accuracy                           0.79     77856\n",
            "   macro avg       0.72      0.66      0.69     77856\n",
            "weighted avg       0.78      0.79      0.78     77856\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39099\n",
            "           1       0.67      0.54      0.60      4118\n",
            "           2       0.69      0.67      0.68     13663\n",
            "           3       0.62      0.39      0.48      2280\n",
            "           4       0.76      0.79      0.78     16112\n",
            "           5       0.76      0.68      0.72      2616\n",
            "\n",
            "    accuracy                           0.79     77888\n",
            "   macro avg       0.72      0.66      0.69     77888\n",
            "weighted avg       0.78      0.79      0.78     77888\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39113\n",
            "           1       0.67      0.54      0.60      4121\n",
            "           2       0.69      0.67      0.68     13667\n",
            "           3       0.63      0.39      0.48      2281\n",
            "           4       0.76      0.79      0.78     16122\n",
            "           5       0.76      0.68      0.72      2616\n",
            "\n",
            "    accuracy                           0.79     77920\n",
            "   macro avg       0.72      0.66      0.69     77920\n",
            "weighted avg       0.78      0.79      0.78     77920\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39131\n",
            "           1       0.67      0.54      0.60      4121\n",
            "           2       0.69      0.67      0.68     13673\n",
            "           3       0.63      0.39      0.48      2283\n",
            "           4       0.76      0.79      0.78     16126\n",
            "           5       0.76      0.68      0.72      2618\n",
            "\n",
            "    accuracy                           0.79     77952\n",
            "   macro avg       0.72      0.66      0.69     77952\n",
            "weighted avg       0.78      0.79      0.78     77952\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39146\n",
            "           1       0.67      0.54      0.60      4122\n",
            "           2       0.69      0.67      0.68     13679\n",
            "           3       0.63      0.39      0.48      2284\n",
            "           4       0.76      0.79      0.78     16134\n",
            "           5       0.76      0.68      0.72      2619\n",
            "\n",
            "    accuracy                           0.79     77984\n",
            "   macro avg       0.72      0.66      0.69     77984\n",
            "weighted avg       0.78      0.79      0.78     77984\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39164\n",
            "           1       0.67      0.54      0.60      4125\n",
            "           2       0.69      0.67      0.68     13683\n",
            "           3       0.63      0.39      0.48      2284\n",
            "           4       0.76      0.79      0.78     16141\n",
            "           5       0.76      0.68      0.72      2619\n",
            "\n",
            "    accuracy                           0.79     78016\n",
            "   macro avg       0.72      0.66      0.69     78016\n",
            "weighted avg       0.78      0.79      0.78     78016\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39185\n",
            "           1       0.67      0.54      0.60      4125\n",
            "           2       0.69      0.67      0.68     13688\n",
            "           3       0.63      0.39      0.48      2285\n",
            "           4       0.76      0.79      0.78     16145\n",
            "           5       0.76      0.68      0.72      2620\n",
            "\n",
            "    accuracy                           0.79     78048\n",
            "   macro avg       0.72      0.66      0.69     78048\n",
            "weighted avg       0.78      0.79      0.78     78048\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39200\n",
            "           1       0.67      0.54      0.60      4126\n",
            "           2       0.69      0.67      0.68     13694\n",
            "           3       0.63      0.39      0.48      2287\n",
            "           4       0.76      0.79      0.78     16151\n",
            "           5       0.76      0.68      0.72      2622\n",
            "\n",
            "    accuracy                           0.79     78080\n",
            "   macro avg       0.72      0.66      0.69     78080\n",
            "weighted avg       0.78      0.79      0.78     78080\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39220\n",
            "           1       0.67      0.54      0.60      4129\n",
            "           2       0.69      0.67      0.68     13696\n",
            "           3       0.63      0.39      0.48      2288\n",
            "           4       0.76      0.79      0.78     16155\n",
            "           5       0.76      0.68      0.72      2624\n",
            "\n",
            "    accuracy                           0.79     78112\n",
            "   macro avg       0.72      0.66      0.69     78112\n",
            "weighted avg       0.78      0.79      0.78     78112\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39233\n",
            "           1       0.67      0.54      0.60      4131\n",
            "           2       0.69      0.67      0.68     13705\n",
            "           3       0.63      0.39      0.48      2289\n",
            "           4       0.76      0.79      0.78     16162\n",
            "           5       0.76      0.68      0.72      2624\n",
            "\n",
            "    accuracy                           0.79     78144\n",
            "   macro avg       0.72      0.66      0.69     78144\n",
            "weighted avg       0.78      0.79      0.78     78144\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39251\n",
            "           1       0.67      0.54      0.60      4133\n",
            "           2       0.69      0.67      0.68     13713\n",
            "           3       0.63      0.39      0.48      2289\n",
            "           4       0.76      0.79      0.78     16166\n",
            "           5       0.76      0.68      0.72      2624\n",
            "\n",
            "    accuracy                           0.79     78176\n",
            "   macro avg       0.72      0.66      0.69     78176\n",
            "weighted avg       0.78      0.79      0.78     78176\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39265\n",
            "           1       0.67      0.54      0.60      4133\n",
            "           2       0.69      0.67      0.68     13721\n",
            "           3       0.63      0.39      0.48      2291\n",
            "           4       0.76      0.79      0.78     16173\n",
            "           5       0.76      0.68      0.72      2625\n",
            "\n",
            "    accuracy                           0.79     78208\n",
            "   macro avg       0.72      0.66      0.69     78208\n",
            "weighted avg       0.78      0.79      0.78     78208\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39284\n",
            "           1       0.67      0.54      0.60      4134\n",
            "           2       0.69      0.67      0.68     13725\n",
            "           3       0.63      0.39      0.48      2293\n",
            "           4       0.76      0.79      0.78     16179\n",
            "           5       0.76      0.68      0.72      2625\n",
            "\n",
            "    accuracy                           0.79     78240\n",
            "   macro avg       0.72      0.66      0.69     78240\n",
            "weighted avg       0.78      0.79      0.78     78240\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39300\n",
            "           1       0.67      0.54      0.60      4135\n",
            "           2       0.69      0.67      0.68     13729\n",
            "           3       0.63      0.39      0.48      2296\n",
            "           4       0.76      0.79      0.78     16183\n",
            "           5       0.76      0.68      0.72      2629\n",
            "\n",
            "    accuracy                           0.79     78272\n",
            "   macro avg       0.72      0.66      0.69     78272\n",
            "weighted avg       0.78      0.79      0.78     78272\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39319\n",
            "           1       0.67      0.54      0.60      4136\n",
            "           2       0.69      0.67      0.68     13736\n",
            "           3       0.63      0.39      0.48      2296\n",
            "           4       0.76      0.79      0.78     16186\n",
            "           5       0.76      0.68      0.72      2631\n",
            "\n",
            "    accuracy                           0.79     78304\n",
            "   macro avg       0.72      0.66      0.69     78304\n",
            "weighted avg       0.78      0.79      0.78     78304\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39339\n",
            "           1       0.67      0.54      0.60      4140\n",
            "           2       0.69      0.67      0.68     13740\n",
            "           3       0.63      0.39      0.48      2296\n",
            "           4       0.76      0.79      0.78     16190\n",
            "           5       0.76      0.68      0.72      2631\n",
            "\n",
            "    accuracy                           0.79     78336\n",
            "   macro avg       0.73      0.66      0.69     78336\n",
            "weighted avg       0.78      0.79      0.78     78336\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39356\n",
            "           1       0.67      0.54      0.60      4141\n",
            "           2       0.69      0.67      0.68     13742\n",
            "           3       0.63      0.39      0.48      2298\n",
            "           4       0.76      0.79      0.78     16199\n",
            "           5       0.76      0.68      0.72      2632\n",
            "\n",
            "    accuracy                           0.79     78368\n",
            "   macro avg       0.73      0.66      0.69     78368\n",
            "weighted avg       0.78      0.79      0.78     78368\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39369\n",
            "           1       0.67      0.54      0.60      4143\n",
            "           2       0.69      0.67      0.68     13749\n",
            "           3       0.63      0.39      0.48      2298\n",
            "           4       0.76      0.79      0.78     16208\n",
            "           5       0.76      0.68      0.72      2633\n",
            "\n",
            "    accuracy                           0.79     78400\n",
            "   macro avg       0.73      0.66      0.69     78400\n",
            "weighted avg       0.78      0.79      0.78     78400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39384\n",
            "           1       0.67      0.54      0.60      4143\n",
            "           2       0.69      0.67      0.68     13753\n",
            "           3       0.63      0.39      0.48      2299\n",
            "           4       0.76      0.79      0.78     16218\n",
            "           5       0.76      0.68      0.72      2635\n",
            "\n",
            "    accuracy                           0.79     78432\n",
            "   macro avg       0.72      0.66      0.69     78432\n",
            "weighted avg       0.78      0.79      0.78     78432\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39401\n",
            "           1       0.67      0.54      0.60      4145\n",
            "           2       0.69      0.67      0.68     13759\n",
            "           3       0.63      0.39      0.48      2300\n",
            "           4       0.76      0.79      0.78     16223\n",
            "           5       0.76      0.68      0.72      2636\n",
            "\n",
            "    accuracy                           0.79     78464\n",
            "   macro avg       0.73      0.66      0.69     78464\n",
            "weighted avg       0.78      0.79      0.78     78464\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39418\n",
            "           1       0.67      0.54      0.60      4149\n",
            "           2       0.69      0.67      0.68     13763\n",
            "           3       0.63      0.39      0.48      2300\n",
            "           4       0.76      0.79      0.78     16230\n",
            "           5       0.76      0.68      0.72      2636\n",
            "\n",
            "    accuracy                           0.79     78496\n",
            "   macro avg       0.73      0.66      0.69     78496\n",
            "weighted avg       0.78      0.79      0.78     78496\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39438\n",
            "           1       0.67      0.54      0.60      4149\n",
            "           2       0.69      0.67      0.68     13771\n",
            "           3       0.63      0.39      0.48      2301\n",
            "           4       0.76      0.79      0.78     16233\n",
            "           5       0.76      0.68      0.72      2636\n",
            "\n",
            "    accuracy                           0.79     78528\n",
            "   macro avg       0.72      0.66      0.69     78528\n",
            "weighted avg       0.78      0.79      0.78     78528\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39455\n",
            "           1       0.67      0.54      0.60      4153\n",
            "           2       0.69      0.67      0.68     13779\n",
            "           3       0.63      0.39      0.48      2301\n",
            "           4       0.76      0.79      0.78     16236\n",
            "           5       0.76      0.68      0.72      2636\n",
            "\n",
            "    accuracy                           0.79     78560\n",
            "   macro avg       0.72      0.66      0.69     78560\n",
            "weighted avg       0.78      0.79      0.78     78560\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39463\n",
            "           1       0.67      0.54      0.60      4159\n",
            "           2       0.69      0.67      0.68     13787\n",
            "           3       0.63      0.39      0.48      2303\n",
            "           4       0.76      0.79      0.78     16240\n",
            "           5       0.76      0.68      0.72      2640\n",
            "\n",
            "    accuracy                           0.79     78592\n",
            "   macro avg       0.73      0.66      0.69     78592\n",
            "weighted avg       0.78      0.79      0.78     78592\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39479\n",
            "           1       0.67      0.54      0.60      4162\n",
            "           2       0.69      0.67      0.68     13794\n",
            "           3       0.63      0.39      0.48      2303\n",
            "           4       0.76      0.79      0.78     16245\n",
            "           5       0.76      0.68      0.72      2641\n",
            "\n",
            "    accuracy                           0.79     78624\n",
            "   macro avg       0.73      0.66      0.69     78624\n",
            "weighted avg       0.78      0.79      0.78     78624\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39497\n",
            "           1       0.67      0.54      0.60      4164\n",
            "           2       0.69      0.67      0.68     13797\n",
            "           3       0.63      0.39      0.48      2303\n",
            "           4       0.76      0.79      0.78     16253\n",
            "           5       0.76      0.68      0.72      2642\n",
            "\n",
            "    accuracy                           0.79     78656\n",
            "   macro avg       0.73      0.66      0.69     78656\n",
            "weighted avg       0.78      0.79      0.78     78656\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39515\n",
            "           1       0.67      0.54      0.60      4164\n",
            "           2       0.69      0.67      0.68     13804\n",
            "           3       0.63      0.39      0.48      2303\n",
            "           4       0.76      0.79      0.78     16259\n",
            "           5       0.76      0.68      0.72      2643\n",
            "\n",
            "    accuracy                           0.79     78688\n",
            "   macro avg       0.73      0.66      0.69     78688\n",
            "weighted avg       0.78      0.79      0.78     78688\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39529\n",
            "           1       0.67      0.54      0.60      4164\n",
            "           2       0.69      0.67      0.68     13811\n",
            "           3       0.63      0.39      0.48      2303\n",
            "           4       0.76      0.79      0.78     16269\n",
            "           5       0.76      0.68      0.72      2644\n",
            "\n",
            "    accuracy                           0.79     78720\n",
            "   macro avg       0.73      0.66      0.69     78720\n",
            "weighted avg       0.78      0.79      0.78     78720\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39544\n",
            "           1       0.67      0.54      0.60      4167\n",
            "           2       0.69      0.67      0.68     13819\n",
            "           3       0.63      0.39      0.48      2303\n",
            "           4       0.76      0.79      0.78     16275\n",
            "           5       0.76      0.68      0.72      2644\n",
            "\n",
            "    accuracy                           0.79     78752\n",
            "   macro avg       0.73      0.66      0.69     78752\n",
            "weighted avg       0.78      0.79      0.78     78752\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39564\n",
            "           1       0.67      0.54      0.60      4169\n",
            "           2       0.69      0.67      0.68     13821\n",
            "           3       0.63      0.39      0.48      2304\n",
            "           4       0.76      0.79      0.78     16281\n",
            "           5       0.76      0.68      0.72      2645\n",
            "\n",
            "    accuracy                           0.79     78784\n",
            "   macro avg       0.73      0.66      0.69     78784\n",
            "weighted avg       0.78      0.79      0.78     78784\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39578\n",
            "           1       0.67      0.54      0.60      4169\n",
            "           2       0.69      0.67      0.68     13828\n",
            "           3       0.63      0.39      0.48      2306\n",
            "           4       0.76      0.79      0.78     16288\n",
            "           5       0.76      0.68      0.72      2647\n",
            "\n",
            "    accuracy                           0.79     78816\n",
            "   macro avg       0.73      0.66      0.69     78816\n",
            "weighted avg       0.78      0.79      0.78     78816\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39594\n",
            "           1       0.67      0.54      0.60      4171\n",
            "           2       0.69      0.67      0.68     13835\n",
            "           3       0.63      0.39      0.48      2306\n",
            "           4       0.76      0.79      0.78     16294\n",
            "           5       0.76      0.68      0.72      2648\n",
            "\n",
            "    accuracy                           0.79     78848\n",
            "   macro avg       0.73      0.66      0.69     78848\n",
            "weighted avg       0.78      0.79      0.78     78848\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39605\n",
            "           1       0.67      0.54      0.60      4173\n",
            "           2       0.69      0.67      0.68     13846\n",
            "           3       0.63      0.39      0.48      2307\n",
            "           4       0.76      0.79      0.78     16300\n",
            "           5       0.76      0.68      0.72      2649\n",
            "\n",
            "    accuracy                           0.79     78880\n",
            "   macro avg       0.73      0.66      0.69     78880\n",
            "weighted avg       0.78      0.79      0.78     78880\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39623\n",
            "           1       0.67      0.54      0.60      4175\n",
            "           2       0.69      0.67      0.68     13849\n",
            "           3       0.63      0.39      0.48      2307\n",
            "           4       0.76      0.79      0.78     16308\n",
            "           5       0.76      0.68      0.72      2650\n",
            "\n",
            "    accuracy                           0.79     78912\n",
            "   macro avg       0.73      0.66      0.69     78912\n",
            "weighted avg       0.78      0.79      0.78     78912\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39639\n",
            "           1       0.67      0.54      0.60      4177\n",
            "           2       0.69      0.67      0.68     13854\n",
            "           3       0.63      0.39      0.48      2309\n",
            "           4       0.76      0.79      0.78     16313\n",
            "           5       0.76      0.68      0.72      2652\n",
            "\n",
            "    accuracy                           0.79     78944\n",
            "   macro avg       0.73      0.66      0.69     78944\n",
            "weighted avg       0.78      0.79      0.78     78944\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39655\n",
            "           1       0.67      0.54      0.60      4178\n",
            "           2       0.69      0.67      0.68     13861\n",
            "           3       0.63      0.39      0.48      2310\n",
            "           4       0.76      0.79      0.78     16320\n",
            "           5       0.76      0.68      0.72      2652\n",
            "\n",
            "    accuracy                           0.79     78976\n",
            "   macro avg       0.73      0.66      0.69     78976\n",
            "weighted avg       0.78      0.79      0.78     78976\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39668\n",
            "           1       0.67      0.54      0.60      4180\n",
            "           2       0.69      0.67      0.68     13870\n",
            "           3       0.63      0.39      0.48      2311\n",
            "           4       0.76      0.79      0.78     16326\n",
            "           5       0.76      0.68      0.72      2653\n",
            "\n",
            "    accuracy                           0.79     79008\n",
            "   macro avg       0.73      0.66      0.69     79008\n",
            "weighted avg       0.78      0.79      0.78     79008\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39685\n",
            "           1       0.67      0.54      0.60      4183\n",
            "           2       0.69      0.67      0.68     13875\n",
            "           3       0.63      0.39      0.48      2311\n",
            "           4       0.76      0.79      0.78     16332\n",
            "           5       0.76      0.68      0.72      2654\n",
            "\n",
            "    accuracy                           0.79     79040\n",
            "   macro avg       0.73      0.66      0.69     79040\n",
            "weighted avg       0.78      0.79      0.78     79040\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39703\n",
            "           1       0.67      0.54      0.60      4185\n",
            "           2       0.69      0.67      0.68     13881\n",
            "           3       0.63      0.39      0.48      2312\n",
            "           4       0.76      0.79      0.78     16337\n",
            "           5       0.76      0.68      0.72      2654\n",
            "\n",
            "    accuracy                           0.79     79072\n",
            "   macro avg       0.73      0.66      0.69     79072\n",
            "weighted avg       0.78      0.79      0.78     79072\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39718\n",
            "           1       0.67      0.54      0.60      4190\n",
            "           2       0.69      0.67      0.68     13886\n",
            "           3       0.63      0.39      0.48      2313\n",
            "           4       0.76      0.79      0.78     16341\n",
            "           5       0.76      0.68      0.72      2656\n",
            "\n",
            "    accuracy                           0.79     79104\n",
            "   macro avg       0.73      0.66      0.69     79104\n",
            "weighted avg       0.78      0.79      0.78     79104\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39735\n",
            "           1       0.67      0.54      0.60      4191\n",
            "           2       0.69      0.67      0.68     13892\n",
            "           3       0.63      0.39      0.48      2314\n",
            "           4       0.76      0.79      0.78     16347\n",
            "           5       0.76      0.68      0.72      2657\n",
            "\n",
            "    accuracy                           0.79     79136\n",
            "   macro avg       0.73      0.66      0.69     79136\n",
            "weighted avg       0.78      0.79      0.78     79136\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39750\n",
            "           1       0.67      0.54      0.60      4193\n",
            "           2       0.69      0.67      0.68     13896\n",
            "           3       0.63      0.39      0.48      2314\n",
            "           4       0.76      0.79      0.78     16356\n",
            "           5       0.76      0.68      0.72      2659\n",
            "\n",
            "    accuracy                           0.79     79168\n",
            "   macro avg       0.73      0.66      0.69     79168\n",
            "weighted avg       0.78      0.79      0.78     79168\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39768\n",
            "           1       0.67      0.54      0.60      4193\n",
            "           2       0.69      0.67      0.68     13900\n",
            "           3       0.63      0.39      0.48      2315\n",
            "           4       0.76      0.79      0.78     16365\n",
            "           5       0.76      0.68      0.72      2659\n",
            "\n",
            "    accuracy                           0.79     79200\n",
            "   macro avg       0.73      0.66      0.69     79200\n",
            "weighted avg       0.78      0.79      0.78     79200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39785\n",
            "           1       0.67      0.54      0.60      4197\n",
            "           2       0.69      0.67      0.68     13906\n",
            "           3       0.63      0.39      0.48      2317\n",
            "           4       0.76      0.79      0.78     16367\n",
            "           5       0.76      0.68      0.72      2660\n",
            "\n",
            "    accuracy                           0.79     79232\n",
            "   macro avg       0.73      0.66      0.69     79232\n",
            "weighted avg       0.78      0.79      0.78     79232\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39800\n",
            "           1       0.67      0.54      0.60      4199\n",
            "           2       0.69      0.67      0.68     13912\n",
            "           3       0.63      0.39      0.48      2319\n",
            "           4       0.76      0.79      0.78     16374\n",
            "           5       0.76      0.68      0.72      2660\n",
            "\n",
            "    accuracy                           0.79     79264\n",
            "   macro avg       0.73      0.66      0.69     79264\n",
            "weighted avg       0.78      0.79      0.78     79264\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39815\n",
            "           1       0.67      0.54      0.60      4201\n",
            "           2       0.69      0.67      0.68     13920\n",
            "           3       0.63      0.39      0.48      2320\n",
            "           4       0.76      0.79      0.78     16378\n",
            "           5       0.76      0.68      0.72      2662\n",
            "\n",
            "    accuracy                           0.79     79296\n",
            "   macro avg       0.73      0.66      0.69     79296\n",
            "weighted avg       0.78      0.79      0.78     79296\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39828\n",
            "           1       0.67      0.54      0.60      4204\n",
            "           2       0.69      0.67      0.68     13926\n",
            "           3       0.63      0.39      0.48      2320\n",
            "           4       0.76      0.79      0.78     16387\n",
            "           5       0.76      0.68      0.72      2663\n",
            "\n",
            "    accuracy                           0.79     79328\n",
            "   macro avg       0.73      0.66      0.69     79328\n",
            "weighted avg       0.78      0.79      0.78     79328\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39841\n",
            "           1       0.67      0.54      0.60      4205\n",
            "           2       0.69      0.67      0.68     13936\n",
            "           3       0.63      0.39      0.48      2321\n",
            "           4       0.76      0.79      0.78     16393\n",
            "           5       0.76      0.68      0.72      2664\n",
            "\n",
            "    accuracy                           0.79     79360\n",
            "   macro avg       0.73      0.66      0.69     79360\n",
            "weighted avg       0.78      0.79      0.78     79360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39856\n",
            "           1       0.67      0.54      0.60      4206\n",
            "           2       0.69      0.67      0.68     13944\n",
            "           3       0.63      0.39      0.48      2322\n",
            "           4       0.76      0.79      0.78     16399\n",
            "           5       0.76      0.68      0.72      2665\n",
            "\n",
            "    accuracy                           0.79     79392\n",
            "   macro avg       0.73      0.66      0.69     79392\n",
            "weighted avg       0.78      0.79      0.78     79392\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39875\n",
            "           1       0.67      0.54      0.60      4210\n",
            "           2       0.69      0.67      0.68     13946\n",
            "           3       0.63      0.39      0.48      2323\n",
            "           4       0.76      0.79      0.78     16404\n",
            "           5       0.76      0.68      0.72      2666\n",
            "\n",
            "    accuracy                           0.79     79424\n",
            "   macro avg       0.73      0.66      0.69     79424\n",
            "weighted avg       0.78      0.79      0.78     79424\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39890\n",
            "           1       0.67      0.54      0.60      4212\n",
            "           2       0.69      0.67      0.68     13955\n",
            "           3       0.63      0.39      0.48      2323\n",
            "           4       0.76      0.79      0.78     16410\n",
            "           5       0.76      0.68      0.72      2666\n",
            "\n",
            "    accuracy                           0.79     79456\n",
            "   macro avg       0.73      0.66      0.69     79456\n",
            "weighted avg       0.78      0.79      0.78     79456\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39909\n",
            "           1       0.67      0.54      0.60      4212\n",
            "           2       0.69      0.67      0.68     13958\n",
            "           3       0.63      0.39      0.48      2325\n",
            "           4       0.76      0.79      0.78     16416\n",
            "           5       0.76      0.68      0.72      2668\n",
            "\n",
            "    accuracy                           0.79     79488\n",
            "   macro avg       0.73      0.66      0.69     79488\n",
            "weighted avg       0.78      0.79      0.78     79488\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39927\n",
            "           1       0.67      0.54      0.60      4212\n",
            "           2       0.69      0.67      0.68     13967\n",
            "           3       0.63      0.39      0.48      2325\n",
            "           4       0.76      0.79      0.78     16420\n",
            "           5       0.76      0.68      0.72      2669\n",
            "\n",
            "    accuracy                           0.79     79520\n",
            "   macro avg       0.73      0.66      0.69     79520\n",
            "weighted avg       0.78      0.79      0.78     79520\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39941\n",
            "           1       0.67      0.54      0.60      4213\n",
            "           2       0.69      0.67      0.68     13972\n",
            "           3       0.63      0.39      0.48      2326\n",
            "           4       0.76      0.79      0.78     16429\n",
            "           5       0.76      0.68      0.72      2671\n",
            "\n",
            "    accuracy                           0.79     79552\n",
            "   macro avg       0.73      0.66      0.69     79552\n",
            "weighted avg       0.78      0.79      0.78     79552\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39960\n",
            "           1       0.67      0.54      0.60      4213\n",
            "           2       0.69      0.67      0.68     13975\n",
            "           3       0.63      0.39      0.48      2327\n",
            "           4       0.76      0.79      0.78     16438\n",
            "           5       0.76      0.68      0.72      2671\n",
            "\n",
            "    accuracy                           0.79     79584\n",
            "   macro avg       0.73      0.66      0.69     79584\n",
            "weighted avg       0.78      0.79      0.78     79584\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39972\n",
            "           1       0.67      0.54      0.60      4215\n",
            "           2       0.69      0.67      0.68     13982\n",
            "           3       0.63      0.39      0.48      2328\n",
            "           4       0.76      0.79      0.78     16448\n",
            "           5       0.76      0.68      0.72      2671\n",
            "\n",
            "    accuracy                           0.79     79616\n",
            "   macro avg       0.73      0.66      0.69     79616\n",
            "weighted avg       0.78      0.79      0.78     79616\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     39989\n",
            "           1       0.67      0.54      0.60      4215\n",
            "           2       0.69      0.67      0.68     13987\n",
            "           3       0.63      0.39      0.48      2329\n",
            "           4       0.76      0.79      0.78     16457\n",
            "           5       0.76      0.68      0.72      2671\n",
            "\n",
            "    accuracy                           0.79     79648\n",
            "   macro avg       0.73      0.66      0.69     79648\n",
            "weighted avg       0.78      0.79      0.78     79648\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40009\n",
            "           1       0.67      0.54      0.60      4216\n",
            "           2       0.69      0.67      0.68     13994\n",
            "           3       0.63      0.39      0.48      2329\n",
            "           4       0.76      0.79      0.78     16461\n",
            "           5       0.76      0.68      0.72      2671\n",
            "\n",
            "    accuracy                           0.79     79680\n",
            "   macro avg       0.73      0.66      0.69     79680\n",
            "weighted avg       0.78      0.79      0.78     79680\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40026\n",
            "           1       0.67      0.54      0.60      4216\n",
            "           2       0.69      0.67      0.68     14000\n",
            "           3       0.63      0.39      0.48      2331\n",
            "           4       0.76      0.79      0.78     16466\n",
            "           5       0.76      0.68      0.72      2673\n",
            "\n",
            "    accuracy                           0.79     79712\n",
            "   macro avg       0.73      0.66      0.69     79712\n",
            "weighted avg       0.78      0.79      0.78     79712\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40042\n",
            "           1       0.67      0.54      0.60      4217\n",
            "           2       0.69      0.67      0.68     14004\n",
            "           3       0.63      0.39      0.48      2332\n",
            "           4       0.76      0.79      0.78     16475\n",
            "           5       0.76      0.68      0.72      2674\n",
            "\n",
            "    accuracy                           0.79     79744\n",
            "   macro avg       0.73      0.66      0.69     79744\n",
            "weighted avg       0.78      0.79      0.78     79744\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40058\n",
            "           1       0.67      0.54      0.60      4218\n",
            "           2       0.69      0.67      0.68     14011\n",
            "           3       0.63      0.39      0.48      2333\n",
            "           4       0.76      0.79      0.78     16481\n",
            "           5       0.76      0.68      0.72      2675\n",
            "\n",
            "    accuracy                           0.79     79776\n",
            "   macro avg       0.73      0.66      0.69     79776\n",
            "weighted avg       0.78      0.79      0.78     79776\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40075\n",
            "           1       0.67      0.54      0.60      4218\n",
            "           2       0.69      0.67      0.68     14017\n",
            "           3       0.63      0.39      0.48      2333\n",
            "           4       0.76      0.79      0.78     16488\n",
            "           5       0.76      0.68      0.72      2677\n",
            "\n",
            "    accuracy                           0.79     79808\n",
            "   macro avg       0.73      0.66      0.69     79808\n",
            "weighted avg       0.78      0.79      0.78     79808\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40089\n",
            "           1       0.67      0.54      0.60      4219\n",
            "           2       0.69      0.67      0.68     14025\n",
            "           3       0.63      0.39      0.48      2334\n",
            "           4       0.76      0.79      0.78     16494\n",
            "           5       0.76      0.68      0.72      2679\n",
            "\n",
            "    accuracy                           0.79     79840\n",
            "   macro avg       0.73      0.66      0.69     79840\n",
            "weighted avg       0.78      0.79      0.78     79840\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40104\n",
            "           1       0.67      0.54      0.60      4219\n",
            "           2       0.69      0.67      0.68     14031\n",
            "           3       0.63      0.39      0.48      2337\n",
            "           4       0.76      0.79      0.78     16501\n",
            "           5       0.76      0.68      0.72      2680\n",
            "\n",
            "    accuracy                           0.79     79872\n",
            "   macro avg       0.73      0.66      0.69     79872\n",
            "weighted avg       0.78      0.79      0.78     79872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40118\n",
            "           1       0.67      0.54      0.60      4220\n",
            "           2       0.69      0.67      0.68     14036\n",
            "           3       0.63      0.39      0.48      2338\n",
            "           4       0.76      0.79      0.78     16511\n",
            "           5       0.76      0.68      0.72      2681\n",
            "\n",
            "    accuracy                           0.79     79904\n",
            "   macro avg       0.73      0.66      0.69     79904\n",
            "weighted avg       0.78      0.79      0.78     79904\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40135\n",
            "           1       0.67      0.54      0.60      4222\n",
            "           2       0.69      0.67      0.68     14043\n",
            "           3       0.63      0.39      0.48      2339\n",
            "           4       0.76      0.79      0.78     16515\n",
            "           5       0.76      0.68      0.72      2682\n",
            "\n",
            "    accuracy                           0.79     79936\n",
            "   macro avg       0.73      0.66      0.69     79936\n",
            "weighted avg       0.78      0.79      0.78     79936\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40152\n",
            "           1       0.67      0.54      0.60      4223\n",
            "           2       0.69      0.67      0.68     14050\n",
            "           3       0.63      0.39      0.48      2340\n",
            "           4       0.76      0.79      0.78     16519\n",
            "           5       0.76      0.68      0.72      2684\n",
            "\n",
            "    accuracy                           0.79     79968\n",
            "   macro avg       0.73      0.66      0.69     79968\n",
            "weighted avg       0.78      0.79      0.78     79968\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40165\n",
            "           1       0.67      0.54      0.60      4228\n",
            "           2       0.69      0.67      0.68     14055\n",
            "           3       0.63      0.39      0.48      2341\n",
            "           4       0.76      0.79      0.78     16527\n",
            "           5       0.76      0.68      0.72      2684\n",
            "\n",
            "    accuracy                           0.79     80000\n",
            "   macro avg       0.73      0.66      0.69     80000\n",
            "weighted avg       0.78      0.79      0.78     80000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40177\n",
            "           1       0.67      0.54      0.60      4228\n",
            "           2       0.69      0.67      0.68     14063\n",
            "           3       0.63      0.39      0.48      2341\n",
            "           4       0.76      0.79      0.78     16537\n",
            "           5       0.76      0.68      0.72      2686\n",
            "\n",
            "    accuracy                           0.79     80032\n",
            "   macro avg       0.72      0.66      0.69     80032\n",
            "weighted avg       0.78      0.79      0.78     80032\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40193\n",
            "           1       0.67      0.54      0.60      4228\n",
            "           2       0.69      0.67      0.68     14068\n",
            "           3       0.63      0.39      0.48      2342\n",
            "           4       0.76      0.79      0.78     16547\n",
            "           5       0.76      0.68      0.72      2686\n",
            "\n",
            "    accuracy                           0.79     80064\n",
            "   macro avg       0.72      0.66      0.69     80064\n",
            "weighted avg       0.78      0.79      0.78     80064\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40204\n",
            "           1       0.67      0.54      0.60      4229\n",
            "           2       0.69      0.67      0.68     14074\n",
            "           3       0.63      0.39      0.48      2344\n",
            "           4       0.76      0.79      0.78     16558\n",
            "           5       0.76      0.68      0.72      2687\n",
            "\n",
            "    accuracy                           0.79     80096\n",
            "   macro avg       0.72      0.66      0.69     80096\n",
            "weighted avg       0.78      0.79      0.78     80096\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40217\n",
            "           1       0.67      0.54      0.60      4231\n",
            "           2       0.69      0.67      0.68     14081\n",
            "           3       0.63      0.39      0.48      2345\n",
            "           4       0.76      0.79      0.78     16565\n",
            "           5       0.76      0.68      0.72      2689\n",
            "\n",
            "    accuracy                           0.79     80128\n",
            "   macro avg       0.73      0.66      0.69     80128\n",
            "weighted avg       0.78      0.79      0.78     80128\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40232\n",
            "           1       0.67      0.54      0.60      4233\n",
            "           2       0.69      0.67      0.68     14088\n",
            "           3       0.63      0.39      0.48      2345\n",
            "           4       0.76      0.79      0.78     16571\n",
            "           5       0.76      0.68      0.72      2691\n",
            "\n",
            "    accuracy                           0.79     80160\n",
            "   macro avg       0.73      0.66      0.69     80160\n",
            "weighted avg       0.78      0.79      0.78     80160\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40247\n",
            "           1       0.67      0.54      0.60      4233\n",
            "           2       0.69      0.67      0.68     14094\n",
            "           3       0.63      0.39      0.48      2345\n",
            "           4       0.76      0.79      0.78     16580\n",
            "           5       0.76      0.68      0.72      2693\n",
            "\n",
            "    accuracy                           0.79     80192\n",
            "   macro avg       0.73      0.66      0.69     80192\n",
            "weighted avg       0.78      0.79      0.78     80192\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40267\n",
            "           1       0.67      0.54      0.60      4236\n",
            "           2       0.69      0.67      0.68     14096\n",
            "           3       0.63      0.39      0.48      2345\n",
            "           4       0.76      0.79      0.78     16587\n",
            "           5       0.76      0.68      0.72      2693\n",
            "\n",
            "    accuracy                           0.79     80224\n",
            "   macro avg       0.72      0.66      0.69     80224\n",
            "weighted avg       0.78      0.79      0.78     80224\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40282\n",
            "           1       0.67      0.54      0.60      4239\n",
            "           2       0.69      0.67      0.68     14101\n",
            "           3       0.63      0.39      0.48      2346\n",
            "           4       0.76      0.79      0.78     16595\n",
            "           5       0.76      0.68      0.72      2693\n",
            "\n",
            "    accuracy                           0.79     80256\n",
            "   macro avg       0.72      0.66      0.69     80256\n",
            "weighted avg       0.78      0.79      0.78     80256\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40294\n",
            "           1       0.67      0.54      0.60      4240\n",
            "           2       0.69      0.67      0.68     14109\n",
            "           3       0.63      0.39      0.48      2347\n",
            "           4       0.76      0.79      0.78     16603\n",
            "           5       0.76      0.68      0.72      2695\n",
            "\n",
            "    accuracy                           0.79     80288\n",
            "   macro avg       0.73      0.66      0.69     80288\n",
            "weighted avg       0.78      0.79      0.78     80288\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40308\n",
            "           1       0.67      0.54      0.60      4241\n",
            "           2       0.69      0.67      0.68     14114\n",
            "           3       0.63      0.39      0.48      2349\n",
            "           4       0.76      0.79      0.78     16611\n",
            "           5       0.76      0.68      0.72      2697\n",
            "\n",
            "    accuracy                           0.79     80320\n",
            "   macro avg       0.73      0.66      0.69     80320\n",
            "weighted avg       0.78      0.79      0.78     80320\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40324\n",
            "           1       0.67      0.54      0.60      4243\n",
            "           2       0.69      0.67      0.68     14120\n",
            "           3       0.63      0.39      0.48      2349\n",
            "           4       0.76      0.79      0.78     16617\n",
            "           5       0.76      0.68      0.72      2699\n",
            "\n",
            "    accuracy                           0.79     80352\n",
            "   macro avg       0.73      0.66      0.69     80352\n",
            "weighted avg       0.78      0.79      0.78     80352\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40343\n",
            "           1       0.67      0.54      0.60      4244\n",
            "           2       0.69      0.67      0.68     14127\n",
            "           3       0.63      0.39      0.48      2349\n",
            "           4       0.76      0.79      0.78     16620\n",
            "           5       0.76      0.68      0.72      2701\n",
            "\n",
            "    accuracy                           0.79     80384\n",
            "   macro avg       0.73      0.66      0.69     80384\n",
            "weighted avg       0.78      0.79      0.78     80384\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40360\n",
            "           1       0.67      0.54      0.60      4245\n",
            "           2       0.69      0.67      0.68     14130\n",
            "           3       0.63      0.39      0.48      2353\n",
            "           4       0.76      0.79      0.78     16627\n",
            "           5       0.76      0.68      0.72      2701\n",
            "\n",
            "    accuracy                           0.79     80416\n",
            "   macro avg       0.73      0.66      0.69     80416\n",
            "weighted avg       0.78      0.79      0.78     80416\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40378\n",
            "           1       0.67      0.54      0.60      4245\n",
            "           2       0.69      0.67      0.68     14137\n",
            "           3       0.63      0.39      0.48      2353\n",
            "           4       0.76      0.79      0.78     16634\n",
            "           5       0.76      0.68      0.72      2701\n",
            "\n",
            "    accuracy                           0.79     80448\n",
            "   macro avg       0.73      0.66      0.69     80448\n",
            "weighted avg       0.78      0.79      0.78     80448\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40393\n",
            "           1       0.67      0.54      0.60      4245\n",
            "           2       0.69      0.67      0.68     14143\n",
            "           3       0.63      0.39      0.48      2354\n",
            "           4       0.76      0.79      0.78     16644\n",
            "           5       0.76      0.68      0.72      2701\n",
            "\n",
            "    accuracy                           0.79     80480\n",
            "   macro avg       0.73      0.66      0.69     80480\n",
            "weighted avg       0.78      0.79      0.78     80480\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40403\n",
            "           1       0.67      0.54      0.60      4247\n",
            "           2       0.69      0.67      0.68     14152\n",
            "           3       0.63      0.39      0.48      2356\n",
            "           4       0.76      0.79      0.78     16652\n",
            "           5       0.76      0.68      0.72      2702\n",
            "\n",
            "    accuracy                           0.79     80512\n",
            "   macro avg       0.73      0.66      0.69     80512\n",
            "weighted avg       0.78      0.79      0.78     80512\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40415\n",
            "           1       0.67      0.54      0.60      4250\n",
            "           2       0.69      0.67      0.68     14157\n",
            "           3       0.63      0.39      0.48      2358\n",
            "           4       0.76      0.79      0.78     16660\n",
            "           5       0.76      0.68      0.72      2704\n",
            "\n",
            "    accuracy                           0.79     80544\n",
            "   macro avg       0.72      0.66      0.69     80544\n",
            "weighted avg       0.78      0.79      0.78     80544\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40431\n",
            "           1       0.67      0.54      0.60      4252\n",
            "           2       0.69      0.67      0.68     14163\n",
            "           3       0.63      0.39      0.48      2359\n",
            "           4       0.76      0.79      0.78     16665\n",
            "           5       0.76      0.68      0.72      2706\n",
            "\n",
            "    accuracy                           0.79     80576\n",
            "   macro avg       0.73      0.66      0.69     80576\n",
            "weighted avg       0.78      0.79      0.78     80576\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40448\n",
            "           1       0.67      0.54      0.60      4255\n",
            "           2       0.69      0.67      0.68     14167\n",
            "           3       0.63      0.39      0.48      2359\n",
            "           4       0.76      0.79      0.78     16673\n",
            "           5       0.76      0.68      0.72      2706\n",
            "\n",
            "    accuracy                           0.79     80608\n",
            "   macro avg       0.73      0.66      0.69     80608\n",
            "weighted avg       0.78      0.79      0.78     80608\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40460\n",
            "           1       0.67      0.54      0.60      4259\n",
            "           2       0.69      0.67      0.68     14175\n",
            "           3       0.63      0.39      0.48      2361\n",
            "           4       0.76      0.79      0.78     16679\n",
            "           5       0.76      0.68      0.72      2706\n",
            "\n",
            "    accuracy                           0.79     80640\n",
            "   macro avg       0.73      0.66      0.69     80640\n",
            "weighted avg       0.78      0.79      0.78     80640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40479\n",
            "           1       0.67      0.54      0.60      4259\n",
            "           2       0.69      0.67      0.68     14182\n",
            "           3       0.63      0.39      0.48      2363\n",
            "           4       0.76      0.79      0.78     16682\n",
            "           5       0.76      0.68      0.72      2707\n",
            "\n",
            "    accuracy                           0.79     80672\n",
            "   macro avg       0.73      0.66      0.69     80672\n",
            "weighted avg       0.78      0.79      0.78     80672\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40495\n",
            "           1       0.67      0.54      0.60      4261\n",
            "           2       0.69      0.67      0.68     14188\n",
            "           3       0.63      0.39      0.48      2367\n",
            "           4       0.76      0.79      0.78     16686\n",
            "           5       0.76      0.68      0.72      2707\n",
            "\n",
            "    accuracy                           0.79     80704\n",
            "   macro avg       0.73      0.66      0.69     80704\n",
            "weighted avg       0.78      0.79      0.78     80704\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40510\n",
            "           1       0.67      0.54      0.60      4262\n",
            "           2       0.69      0.67      0.68     14197\n",
            "           3       0.63      0.39      0.48      2368\n",
            "           4       0.76      0.79      0.78     16692\n",
            "           5       0.76      0.68      0.72      2707\n",
            "\n",
            "    accuracy                           0.79     80736\n",
            "   macro avg       0.73      0.66      0.69     80736\n",
            "weighted avg       0.78      0.79      0.78     80736\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40524\n",
            "           1       0.67      0.54      0.60      4264\n",
            "           2       0.69      0.67      0.68     14204\n",
            "           3       0.63      0.39      0.48      2368\n",
            "           4       0.76      0.79      0.78     16700\n",
            "           5       0.76      0.68      0.72      2708\n",
            "\n",
            "    accuracy                           0.79     80768\n",
            "   macro avg       0.73      0.66      0.69     80768\n",
            "weighted avg       0.78      0.79      0.78     80768\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40541\n",
            "           1       0.67      0.54      0.60      4264\n",
            "           2       0.69      0.67      0.68     14213\n",
            "           3       0.63      0.39      0.48      2370\n",
            "           4       0.76      0.79      0.78     16704\n",
            "           5       0.76      0.68      0.72      2708\n",
            "\n",
            "    accuracy                           0.79     80800\n",
            "   macro avg       0.72      0.66      0.69     80800\n",
            "weighted avg       0.78      0.79      0.78     80800\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40557\n",
            "           1       0.67      0.54      0.60      4266\n",
            "           2       0.69      0.67      0.68     14219\n",
            "           3       0.63      0.39      0.48      2371\n",
            "           4       0.76      0.79      0.78     16709\n",
            "           5       0.76      0.68      0.72      2710\n",
            "\n",
            "    accuracy                           0.79     80832\n",
            "   macro avg       0.73      0.66      0.69     80832\n",
            "weighted avg       0.78      0.79      0.78     80832\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40576\n",
            "           1       0.67      0.54      0.60      4268\n",
            "           2       0.69      0.67      0.68     14223\n",
            "           3       0.63      0.39      0.48      2371\n",
            "           4       0.76      0.79      0.78     16715\n",
            "           5       0.76      0.68      0.72      2711\n",
            "\n",
            "    accuracy                           0.79     80864\n",
            "   macro avg       0.73      0.66      0.69     80864\n",
            "weighted avg       0.78      0.79      0.78     80864\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40593\n",
            "           1       0.67      0.54      0.60      4269\n",
            "           2       0.69      0.67      0.68     14229\n",
            "           3       0.63      0.39      0.48      2371\n",
            "           4       0.76      0.79      0.78     16721\n",
            "           5       0.76      0.68      0.72      2713\n",
            "\n",
            "    accuracy                           0.79     80896\n",
            "   macro avg       0.73      0.66      0.69     80896\n",
            "weighted avg       0.78      0.79      0.78     80896\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40611\n",
            "           1       0.67      0.54      0.60      4270\n",
            "           2       0.69      0.67      0.68     14239\n",
            "           3       0.63      0.39      0.48      2372\n",
            "           4       0.76      0.79      0.78     16723\n",
            "           5       0.76      0.68      0.72      2713\n",
            "\n",
            "    accuracy                           0.79     80928\n",
            "   macro avg       0.73      0.66      0.69     80928\n",
            "weighted avg       0.78      0.79      0.78     80928\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40631\n",
            "           1       0.67      0.54      0.60      4271\n",
            "           2       0.69      0.67      0.68     14241\n",
            "           3       0.63      0.39      0.48      2372\n",
            "           4       0.76      0.79      0.78     16729\n",
            "           5       0.76      0.68      0.72      2716\n",
            "\n",
            "    accuracy                           0.79     80960\n",
            "   macro avg       0.73      0.66      0.69     80960\n",
            "weighted avg       0.78      0.79      0.78     80960\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40648\n",
            "           1       0.67      0.54      0.60      4272\n",
            "           2       0.69      0.67      0.68     14247\n",
            "           3       0.63      0.39      0.48      2372\n",
            "           4       0.76      0.79      0.78     16735\n",
            "           5       0.76      0.68      0.72      2718\n",
            "\n",
            "    accuracy                           0.79     80992\n",
            "   macro avg       0.73      0.66      0.69     80992\n",
            "weighted avg       0.78      0.79      0.78     80992\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40658\n",
            "           1       0.67      0.54      0.60      4274\n",
            "           2       0.69      0.67      0.68     14254\n",
            "           3       0.63      0.39      0.48      2373\n",
            "           4       0.76      0.79      0.78     16745\n",
            "           5       0.76      0.68      0.72      2720\n",
            "\n",
            "    accuracy                           0.79     81024\n",
            "   macro avg       0.73      0.66      0.69     81024\n",
            "weighted avg       0.78      0.79      0.78     81024\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40674\n",
            "           1       0.67      0.54      0.60      4276\n",
            "           2       0.69      0.67      0.68     14261\n",
            "           3       0.63      0.39      0.48      2375\n",
            "           4       0.76      0.79      0.78     16749\n",
            "           5       0.76      0.68      0.72      2721\n",
            "\n",
            "    accuracy                           0.79     81056\n",
            "   macro avg       0.73      0.66      0.69     81056\n",
            "weighted avg       0.78      0.79      0.78     81056\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40691\n",
            "           1       0.67      0.54      0.60      4277\n",
            "           2       0.69      0.67      0.68     14265\n",
            "           3       0.63      0.39      0.48      2375\n",
            "           4       0.76      0.79      0.78     16758\n",
            "           5       0.76      0.68      0.72      2722\n",
            "\n",
            "    accuracy                           0.79     81088\n",
            "   macro avg       0.73      0.66      0.69     81088\n",
            "weighted avg       0.78      0.79      0.78     81088\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40706\n",
            "           1       0.67      0.54      0.60      4278\n",
            "           2       0.69      0.67      0.68     14269\n",
            "           3       0.63      0.39      0.48      2375\n",
            "           4       0.76      0.79      0.78     16769\n",
            "           5       0.76      0.68      0.72      2723\n",
            "\n",
            "    accuracy                           0.79     81120\n",
            "   macro avg       0.73      0.66      0.69     81120\n",
            "weighted avg       0.78      0.79      0.78     81120\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40721\n",
            "           1       0.67      0.54      0.60      4282\n",
            "           2       0.69      0.67      0.68     14273\n",
            "           3       0.63      0.39      0.48      2376\n",
            "           4       0.76      0.79      0.78     16777\n",
            "           5       0.76      0.68      0.72      2723\n",
            "\n",
            "    accuracy                           0.79     81152\n",
            "   macro avg       0.73      0.66      0.69     81152\n",
            "weighted avg       0.78      0.79      0.78     81152\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40744\n",
            "           1       0.67      0.54      0.60      4283\n",
            "           2       0.69      0.67      0.68     14277\n",
            "           3       0.63      0.39      0.48      2377\n",
            "           4       0.76      0.79      0.78     16780\n",
            "           5       0.76      0.68      0.72      2723\n",
            "\n",
            "    accuracy                           0.79     81184\n",
            "   macro avg       0.73      0.66      0.69     81184\n",
            "weighted avg       0.78      0.79      0.78     81184\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40760\n",
            "           1       0.67      0.54      0.60      4283\n",
            "           2       0.69      0.67      0.68     14288\n",
            "           3       0.63      0.39      0.48      2377\n",
            "           4       0.76      0.79      0.78     16785\n",
            "           5       0.76      0.68      0.72      2723\n",
            "\n",
            "    accuracy                           0.79     81216\n",
            "   macro avg       0.73      0.66      0.69     81216\n",
            "weighted avg       0.78      0.79      0.78     81216\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40776\n",
            "           1       0.67      0.54      0.60      4286\n",
            "           2       0.69      0.67      0.68     14294\n",
            "           3       0.63      0.39      0.48      2378\n",
            "           4       0.76      0.79      0.78     16790\n",
            "           5       0.76      0.68      0.72      2724\n",
            "\n",
            "    accuracy                           0.79     81248\n",
            "   macro avg       0.73      0.66      0.69     81248\n",
            "weighted avg       0.78      0.79      0.78     81248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40792\n",
            "           1       0.67      0.54      0.60      4286\n",
            "           2       0.69      0.67      0.68     14300\n",
            "           3       0.63      0.39      0.48      2380\n",
            "           4       0.76      0.79      0.78     16797\n",
            "           5       0.76      0.68      0.72      2725\n",
            "\n",
            "    accuracy                           0.79     81280\n",
            "   macro avg       0.73      0.66      0.69     81280\n",
            "weighted avg       0.78      0.79      0.78     81280\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40809\n",
            "           1       0.67      0.54      0.60      4287\n",
            "           2       0.69      0.67      0.68     14308\n",
            "           3       0.63      0.39      0.48      2380\n",
            "           4       0.76      0.79      0.78     16802\n",
            "           5       0.76      0.68      0.72      2726\n",
            "\n",
            "    accuracy                           0.79     81312\n",
            "   macro avg       0.73      0.66      0.69     81312\n",
            "weighted avg       0.78      0.79      0.78     81312\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40826\n",
            "           1       0.67      0.54      0.60      4290\n",
            "           2       0.69      0.67      0.68     14316\n",
            "           3       0.63      0.39      0.48      2380\n",
            "           4       0.76      0.79      0.78     16806\n",
            "           5       0.76      0.68      0.72      2726\n",
            "\n",
            "    accuracy                           0.79     81344\n",
            "   macro avg       0.73      0.66      0.69     81344\n",
            "weighted avg       0.78      0.79      0.78     81344\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40844\n",
            "           1       0.67      0.54      0.60      4290\n",
            "           2       0.69      0.67      0.68     14323\n",
            "           3       0.63      0.39      0.48      2382\n",
            "           4       0.76      0.79      0.78     16811\n",
            "           5       0.76      0.68      0.72      2726\n",
            "\n",
            "    accuracy                           0.79     81376\n",
            "   macro avg       0.73      0.66      0.69     81376\n",
            "weighted avg       0.78      0.79      0.78     81376\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40860\n",
            "           1       0.67      0.54      0.60      4295\n",
            "           2       0.69      0.67      0.68     14329\n",
            "           3       0.63      0.39      0.48      2383\n",
            "           4       0.76      0.79      0.78     16814\n",
            "           5       0.76      0.68      0.72      2727\n",
            "\n",
            "    accuracy                           0.79     81408\n",
            "   macro avg       0.73      0.66      0.69     81408\n",
            "weighted avg       0.78      0.79      0.78     81408\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40875\n",
            "           1       0.67      0.54      0.60      4295\n",
            "           2       0.69      0.67      0.68     14337\n",
            "           3       0.63      0.39      0.48      2383\n",
            "           4       0.76      0.79      0.78     16821\n",
            "           5       0.76      0.68      0.72      2729\n",
            "\n",
            "    accuracy                           0.79     81440\n",
            "   macro avg       0.73      0.66      0.69     81440\n",
            "weighted avg       0.78      0.79      0.78     81440\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40889\n",
            "           1       0.67      0.54      0.60      4298\n",
            "           2       0.69      0.67      0.68     14345\n",
            "           3       0.63      0.39      0.48      2384\n",
            "           4       0.76      0.79      0.78     16827\n",
            "           5       0.76      0.68      0.72      2729\n",
            "\n",
            "    accuracy                           0.79     81472\n",
            "   macro avg       0.73      0.66      0.69     81472\n",
            "weighted avg       0.78      0.79      0.78     81472\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40903\n",
            "           1       0.67      0.54      0.60      4299\n",
            "           2       0.69      0.67      0.68     14355\n",
            "           3       0.63      0.39      0.48      2386\n",
            "           4       0.76      0.79      0.78     16832\n",
            "           5       0.76      0.68      0.72      2729\n",
            "\n",
            "    accuracy                           0.79     81504\n",
            "   macro avg       0.72      0.66      0.69     81504\n",
            "weighted avg       0.78      0.79      0.78     81504\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40915\n",
            "           1       0.67      0.54      0.60      4299\n",
            "           2       0.69      0.67      0.68     14366\n",
            "           3       0.63      0.39      0.48      2386\n",
            "           4       0.76      0.79      0.78     16840\n",
            "           5       0.76      0.68      0.72      2730\n",
            "\n",
            "    accuracy                           0.79     81536\n",
            "   macro avg       0.72      0.66      0.69     81536\n",
            "weighted avg       0.78      0.79      0.78     81536\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40934\n",
            "           1       0.67      0.55      0.60      4302\n",
            "           2       0.69      0.67      0.68     14369\n",
            "           3       0.63      0.39      0.48      2387\n",
            "           4       0.76      0.79      0.78     16845\n",
            "           5       0.76      0.68      0.72      2731\n",
            "\n",
            "    accuracy                           0.79     81568\n",
            "   macro avg       0.73      0.66      0.69     81568\n",
            "weighted avg       0.78      0.79      0.78     81568\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40947\n",
            "           1       0.67      0.55      0.60      4305\n",
            "           2       0.69      0.67      0.68     14376\n",
            "           3       0.63      0.39      0.48      2388\n",
            "           4       0.76      0.79      0.78     16853\n",
            "           5       0.76      0.68      0.72      2731\n",
            "\n",
            "    accuracy                           0.79     81600\n",
            "   macro avg       0.73      0.66      0.69     81600\n",
            "weighted avg       0.78      0.79      0.78     81600\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40965\n",
            "           1       0.67      0.55      0.60      4305\n",
            "           2       0.69      0.67      0.68     14380\n",
            "           3       0.63      0.39      0.48      2388\n",
            "           4       0.76      0.79      0.78     16861\n",
            "           5       0.76      0.68      0.72      2733\n",
            "\n",
            "    accuracy                           0.79     81632\n",
            "   macro avg       0.73      0.66      0.69     81632\n",
            "weighted avg       0.78      0.79      0.78     81632\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40983\n",
            "           1       0.67      0.55      0.60      4308\n",
            "           2       0.69      0.67      0.68     14386\n",
            "           3       0.63      0.39      0.48      2388\n",
            "           4       0.76      0.79      0.78     16865\n",
            "           5       0.76      0.68      0.72      2734\n",
            "\n",
            "    accuracy                           0.79     81664\n",
            "   macro avg       0.73      0.66      0.69     81664\n",
            "weighted avg       0.78      0.79      0.78     81664\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     40998\n",
            "           1       0.67      0.54      0.60      4309\n",
            "           2       0.69      0.67      0.68     14390\n",
            "           3       0.63      0.39      0.48      2389\n",
            "           4       0.76      0.79      0.78     16874\n",
            "           5       0.76      0.68      0.72      2736\n",
            "\n",
            "    accuracy                           0.79     81696\n",
            "   macro avg       0.73      0.66      0.69     81696\n",
            "weighted avg       0.78      0.79      0.78     81696\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41011\n",
            "           1       0.67      0.54      0.60      4312\n",
            "           2       0.69      0.67      0.68     14397\n",
            "           3       0.63      0.39      0.48      2389\n",
            "           4       0.76      0.79      0.78     16882\n",
            "           5       0.76      0.68      0.72      2737\n",
            "\n",
            "    accuracy                           0.79     81728\n",
            "   macro avg       0.73      0.66      0.69     81728\n",
            "weighted avg       0.78      0.79      0.78     81728\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41026\n",
            "           1       0.67      0.54      0.60      4314\n",
            "           2       0.69      0.67      0.68     14402\n",
            "           3       0.63      0.39      0.48      2390\n",
            "           4       0.76      0.79      0.78     16888\n",
            "           5       0.76      0.68      0.72      2740\n",
            "\n",
            "    accuracy                           0.79     81760\n",
            "   macro avg       0.73      0.66      0.69     81760\n",
            "weighted avg       0.78      0.79      0.78     81760\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41041\n",
            "           1       0.67      0.54      0.60      4315\n",
            "           2       0.69      0.67      0.68     14409\n",
            "           3       0.63      0.39      0.48      2390\n",
            "           4       0.76      0.79      0.78     16897\n",
            "           5       0.76      0.68      0.72      2740\n",
            "\n",
            "    accuracy                           0.79     81792\n",
            "   macro avg       0.73      0.66      0.69     81792\n",
            "weighted avg       0.78      0.79      0.78     81792\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41055\n",
            "           1       0.67      0.54      0.60      4317\n",
            "           2       0.69      0.67      0.68     14416\n",
            "           3       0.63      0.39      0.48      2391\n",
            "           4       0.76      0.79      0.78     16903\n",
            "           5       0.76      0.68      0.72      2742\n",
            "\n",
            "    accuracy                           0.79     81824\n",
            "   macro avg       0.73      0.66      0.69     81824\n",
            "weighted avg       0.78      0.79      0.78     81824\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41073\n",
            "           1       0.67      0.54      0.60      4317\n",
            "           2       0.69      0.67      0.68     14421\n",
            "           3       0.63      0.39      0.48      2392\n",
            "           4       0.76      0.79      0.78     16909\n",
            "           5       0.76      0.68      0.72      2744\n",
            "\n",
            "    accuracy                           0.79     81856\n",
            "   macro avg       0.73      0.66      0.69     81856\n",
            "weighted avg       0.78      0.79      0.78     81856\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41089\n",
            "           1       0.67      0.54      0.60      4317\n",
            "           2       0.69      0.67      0.68     14425\n",
            "           3       0.62      0.39      0.48      2393\n",
            "           4       0.76      0.79      0.78     16919\n",
            "           5       0.76      0.68      0.72      2745\n",
            "\n",
            "    accuracy                           0.79     81888\n",
            "   macro avg       0.72      0.66      0.69     81888\n",
            "weighted avg       0.78      0.79      0.78     81888\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41098\n",
            "           1       0.67      0.54      0.60      4318\n",
            "           2       0.69      0.67      0.68     14432\n",
            "           3       0.62      0.39      0.48      2394\n",
            "           4       0.76      0.79      0.78     16931\n",
            "           5       0.76      0.68      0.72      2747\n",
            "\n",
            "    accuracy                           0.79     81920\n",
            "   macro avg       0.73      0.66      0.69     81920\n",
            "weighted avg       0.78      0.79      0.78     81920\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41115\n",
            "           1       0.67      0.54      0.60      4320\n",
            "           2       0.69      0.67      0.68     14436\n",
            "           3       0.62      0.39      0.48      2396\n",
            "           4       0.76      0.79      0.78     16937\n",
            "           5       0.76      0.68      0.72      2748\n",
            "\n",
            "    accuracy                           0.79     81952\n",
            "   macro avg       0.73      0.66      0.69     81952\n",
            "weighted avg       0.78      0.79      0.78     81952\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41135\n",
            "           1       0.67      0.54      0.60      4322\n",
            "           2       0.69      0.67      0.68     14442\n",
            "           3       0.62      0.39      0.48      2396\n",
            "           4       0.76      0.79      0.78     16940\n",
            "           5       0.76      0.68      0.72      2749\n",
            "\n",
            "    accuracy                           0.79     81984\n",
            "   macro avg       0.73      0.66      0.69     81984\n",
            "weighted avg       0.78      0.79      0.78     81984\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41148\n",
            "           1       0.67      0.54      0.60      4323\n",
            "           2       0.69      0.67      0.68     14449\n",
            "           3       0.63      0.39      0.48      2399\n",
            "           4       0.76      0.79      0.78     16948\n",
            "           5       0.76      0.68      0.72      2749\n",
            "\n",
            "    accuracy                           0.79     82016\n",
            "   macro avg       0.73      0.66      0.69     82016\n",
            "weighted avg       0.78      0.79      0.78     82016\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41163\n",
            "           1       0.67      0.54      0.60      4323\n",
            "           2       0.69      0.67      0.68     14457\n",
            "           3       0.62      0.39      0.48      2400\n",
            "           4       0.76      0.79      0.78     16956\n",
            "           5       0.76      0.68      0.72      2749\n",
            "\n",
            "    accuracy                           0.79     82048\n",
            "   macro avg       0.72      0.66      0.69     82048\n",
            "weighted avg       0.78      0.79      0.78     82048\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41176\n",
            "           1       0.67      0.54      0.60      4324\n",
            "           2       0.69      0.67      0.68     14466\n",
            "           3       0.62      0.39      0.48      2401\n",
            "           4       0.76      0.79      0.78     16964\n",
            "           5       0.76      0.68      0.72      2749\n",
            "\n",
            "    accuracy                           0.79     82080\n",
            "   macro avg       0.73      0.66      0.69     82080\n",
            "weighted avg       0.78      0.79      0.78     82080\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41190\n",
            "           1       0.67      0.54      0.60      4325\n",
            "           2       0.69      0.67      0.68     14473\n",
            "           3       0.62      0.39      0.48      2402\n",
            "           4       0.76      0.79      0.78     16971\n",
            "           5       0.76      0.68      0.72      2751\n",
            "\n",
            "    accuracy                           0.79     82112\n",
            "   macro avg       0.73      0.66      0.69     82112\n",
            "weighted avg       0.78      0.79      0.78     82112\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41205\n",
            "           1       0.67      0.54      0.60      4326\n",
            "           2       0.69      0.67      0.68     14481\n",
            "           3       0.62      0.39      0.48      2403\n",
            "           4       0.76      0.79      0.78     16977\n",
            "           5       0.76      0.68      0.72      2752\n",
            "\n",
            "    accuracy                           0.79     82144\n",
            "   macro avg       0.72      0.66      0.69     82144\n",
            "weighted avg       0.78      0.79      0.78     82144\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41218\n",
            "           1       0.67      0.54      0.60      4329\n",
            "           2       0.69      0.67      0.68     14490\n",
            "           3       0.63      0.39      0.48      2404\n",
            "           4       0.76      0.79      0.78     16983\n",
            "           5       0.76      0.68      0.72      2752\n",
            "\n",
            "    accuracy                           0.79     82176\n",
            "   macro avg       0.73      0.66      0.69     82176\n",
            "weighted avg       0.78      0.79      0.78     82176\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41229\n",
            "           1       0.67      0.54      0.60      4329\n",
            "           2       0.69      0.67      0.68     14499\n",
            "           3       0.63      0.39      0.48      2405\n",
            "           4       0.76      0.79      0.78     16992\n",
            "           5       0.76      0.68      0.72      2754\n",
            "\n",
            "    accuracy                           0.79     82208\n",
            "   macro avg       0.73      0.66      0.69     82208\n",
            "weighted avg       0.78      0.79      0.78     82208\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41245\n",
            "           1       0.67      0.55      0.60      4332\n",
            "           2       0.69      0.67      0.68     14505\n",
            "           3       0.63      0.39      0.48      2405\n",
            "           4       0.76      0.79      0.78     16998\n",
            "           5       0.75      0.68      0.72      2755\n",
            "\n",
            "    accuracy                           0.79     82240\n",
            "   macro avg       0.73      0.66      0.69     82240\n",
            "weighted avg       0.78      0.79      0.78     82240\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41259\n",
            "           1       0.67      0.55      0.60      4336\n",
            "           2       0.69      0.67      0.68     14514\n",
            "           3       0.63      0.39      0.48      2405\n",
            "           4       0.76      0.79      0.78     17002\n",
            "           5       0.76      0.68      0.72      2756\n",
            "\n",
            "    accuracy                           0.79     82272\n",
            "   macro avg       0.73      0.66      0.69     82272\n",
            "weighted avg       0.78      0.79      0.78     82272\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41272\n",
            "           1       0.67      0.55      0.60      4338\n",
            "           2       0.69      0.67      0.68     14523\n",
            "           3       0.63      0.39      0.48      2405\n",
            "           4       0.76      0.79      0.78     17008\n",
            "           5       0.76      0.68      0.72      2758\n",
            "\n",
            "    accuracy                           0.79     82304\n",
            "   macro avg       0.73      0.66      0.69     82304\n",
            "weighted avg       0.78      0.79      0.78     82304\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41286\n",
            "           1       0.67      0.55      0.60      4342\n",
            "           2       0.69      0.67      0.68     14530\n",
            "           3       0.63      0.39      0.48      2405\n",
            "           4       0.76      0.79      0.78     17015\n",
            "           5       0.76      0.68      0.72      2758\n",
            "\n",
            "    accuracy                           0.79     82336\n",
            "   macro avg       0.73      0.66      0.69     82336\n",
            "weighted avg       0.78      0.79      0.78     82336\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41308\n",
            "           1       0.67      0.55      0.60      4342\n",
            "           2       0.69      0.67      0.68     14536\n",
            "           3       0.62      0.39      0.48      2405\n",
            "           4       0.76      0.79      0.78     17018\n",
            "           5       0.76      0.68      0.72      2759\n",
            "\n",
            "    accuracy                           0.79     82368\n",
            "   macro avg       0.73      0.66      0.69     82368\n",
            "weighted avg       0.78      0.79      0.78     82368\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41326\n",
            "           1       0.67      0.55      0.60      4342\n",
            "           2       0.69      0.67      0.68     14543\n",
            "           3       0.62      0.39      0.48      2406\n",
            "           4       0.76      0.79      0.78     17024\n",
            "           5       0.76      0.68      0.72      2759\n",
            "\n",
            "    accuracy                           0.79     82400\n",
            "   macro avg       0.73      0.66      0.69     82400\n",
            "weighted avg       0.78      0.79      0.78     82400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41342\n",
            "           1       0.67      0.54      0.60      4345\n",
            "           2       0.69      0.67      0.68     14548\n",
            "           3       0.62      0.39      0.48      2408\n",
            "           4       0.76      0.79      0.78     17028\n",
            "           5       0.76      0.68      0.72      2761\n",
            "\n",
            "    accuracy                           0.79     82432\n",
            "   macro avg       0.73      0.66      0.69     82432\n",
            "weighted avg       0.78      0.79      0.78     82432\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41361\n",
            "           1       0.67      0.55      0.60      4347\n",
            "           2       0.69      0.67      0.68     14552\n",
            "           3       0.62      0.39      0.48      2409\n",
            "           4       0.76      0.79      0.78     17033\n",
            "           5       0.76      0.68      0.72      2762\n",
            "\n",
            "    accuracy                           0.79     82464\n",
            "   macro avg       0.73      0.66      0.69     82464\n",
            "weighted avg       0.78      0.79      0.78     82464\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41378\n",
            "           1       0.67      0.55      0.60      4348\n",
            "           2       0.69      0.67      0.68     14554\n",
            "           3       0.62      0.39      0.48      2410\n",
            "           4       0.76      0.79      0.78     17044\n",
            "           5       0.76      0.68      0.72      2762\n",
            "\n",
            "    accuracy                           0.79     82496\n",
            "   macro avg       0.73      0.66      0.69     82496\n",
            "weighted avg       0.78      0.79      0.78     82496\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41393\n",
            "           1       0.67      0.55      0.60      4349\n",
            "           2       0.69      0.67      0.68     14563\n",
            "           3       0.62      0.39      0.48      2410\n",
            "           4       0.76      0.79      0.78     17051\n",
            "           5       0.76      0.68      0.72      2762\n",
            "\n",
            "    accuracy                           0.79     82528\n",
            "   macro avg       0.73      0.66      0.69     82528\n",
            "weighted avg       0.78      0.79      0.78     82528\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41407\n",
            "           1       0.67      0.55      0.60      4352\n",
            "           2       0.69      0.67      0.68     14573\n",
            "           3       0.63      0.39      0.48      2411\n",
            "           4       0.76      0.79      0.78     17054\n",
            "           5       0.76      0.68      0.72      2763\n",
            "\n",
            "    accuracy                           0.79     82560\n",
            "   macro avg       0.73      0.66      0.69     82560\n",
            "weighted avg       0.78      0.79      0.78     82560\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41424\n",
            "           1       0.67      0.55      0.60      4354\n",
            "           2       0.69      0.67      0.68     14578\n",
            "           3       0.62      0.39      0.48      2411\n",
            "           4       0.76      0.79      0.78     17059\n",
            "           5       0.76      0.68      0.72      2766\n",
            "\n",
            "    accuracy                           0.79     82592\n",
            "   macro avg       0.73      0.66      0.69     82592\n",
            "weighted avg       0.78      0.79      0.78     82592\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41445\n",
            "           1       0.67      0.55      0.60      4354\n",
            "           2       0.69      0.67      0.68     14580\n",
            "           3       0.63      0.39      0.48      2412\n",
            "           4       0.76      0.79      0.78     17065\n",
            "           5       0.76      0.68      0.72      2768\n",
            "\n",
            "    accuracy                           0.79     82624\n",
            "   macro avg       0.73      0.66      0.69     82624\n",
            "weighted avg       0.78      0.79      0.78     82624\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41454\n",
            "           1       0.67      0.55      0.60      4356\n",
            "           2       0.69      0.67      0.68     14589\n",
            "           3       0.62      0.39      0.48      2412\n",
            "           4       0.76      0.79      0.78     17076\n",
            "           5       0.76      0.68      0.72      2769\n",
            "\n",
            "    accuracy                           0.79     82656\n",
            "   macro avg       0.73      0.66      0.69     82656\n",
            "weighted avg       0.78      0.79      0.78     82656\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41472\n",
            "           1       0.67      0.55      0.60      4358\n",
            "           2       0.69      0.67      0.68     14593\n",
            "           3       0.62      0.39      0.48      2412\n",
            "           4       0.76      0.79      0.78     17084\n",
            "           5       0.76      0.68      0.72      2769\n",
            "\n",
            "    accuracy                           0.79     82688\n",
            "   macro avg       0.73      0.66      0.69     82688\n",
            "weighted avg       0.78      0.79      0.78     82688\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41485\n",
            "           1       0.67      0.55      0.60      4359\n",
            "           2       0.69      0.67      0.68     14601\n",
            "           3       0.62      0.39      0.48      2413\n",
            "           4       0.76      0.79      0.78     17091\n",
            "           5       0.75      0.68      0.72      2771\n",
            "\n",
            "    accuracy                           0.79     82720\n",
            "   macro avg       0.73      0.66      0.69     82720\n",
            "weighted avg       0.78      0.79      0.78     82720\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41503\n",
            "           1       0.67      0.55      0.60      4359\n",
            "           2       0.69      0.67      0.68     14605\n",
            "           3       0.62      0.39      0.48      2415\n",
            "           4       0.76      0.79      0.78     17098\n",
            "           5       0.76      0.68      0.72      2772\n",
            "\n",
            "    accuracy                           0.79     82752\n",
            "   macro avg       0.73      0.66      0.69     82752\n",
            "weighted avg       0.78      0.79      0.78     82752\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41518\n",
            "           1       0.67      0.55      0.60      4359\n",
            "           2       0.69      0.67      0.68     14610\n",
            "           3       0.63      0.39      0.48      2417\n",
            "           4       0.76      0.79      0.78     17106\n",
            "           5       0.76      0.68      0.72      2774\n",
            "\n",
            "    accuracy                           0.79     82784\n",
            "   macro avg       0.73      0.66      0.69     82784\n",
            "weighted avg       0.78      0.79      0.78     82784\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41529\n",
            "           1       0.67      0.55      0.60      4359\n",
            "           2       0.69      0.67      0.68     14616\n",
            "           3       0.63      0.39      0.48      2417\n",
            "           4       0.76      0.79      0.78     17119\n",
            "           5       0.76      0.68      0.72      2776\n",
            "\n",
            "    accuracy                           0.79     82816\n",
            "   macro avg       0.73      0.66      0.69     82816\n",
            "weighted avg       0.78      0.79      0.78     82816\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41546\n",
            "           1       0.67      0.55      0.60      4359\n",
            "           2       0.69      0.67      0.68     14624\n",
            "           3       0.62      0.39      0.48      2417\n",
            "           4       0.76      0.79      0.78     17126\n",
            "           5       0.75      0.68      0.72      2776\n",
            "\n",
            "    accuracy                           0.79     82848\n",
            "   macro avg       0.73      0.66      0.69     82848\n",
            "weighted avg       0.78      0.79      0.78     82848\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41559\n",
            "           1       0.67      0.55      0.60      4364\n",
            "           2       0.69      0.67      0.68     14629\n",
            "           3       0.62      0.39      0.48      2417\n",
            "           4       0.76      0.79      0.78     17134\n",
            "           5       0.75      0.68      0.72      2777\n",
            "\n",
            "    accuracy                           0.79     82880\n",
            "   macro avg       0.72      0.66      0.69     82880\n",
            "weighted avg       0.78      0.79      0.78     82880\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41568\n",
            "           1       0.67      0.55      0.60      4367\n",
            "           2       0.69      0.67      0.68     14639\n",
            "           3       0.62      0.39      0.48      2419\n",
            "           4       0.76      0.79      0.78     17140\n",
            "           5       0.75      0.68      0.72      2779\n",
            "\n",
            "    accuracy                           0.79     82912\n",
            "   macro avg       0.73      0.66      0.69     82912\n",
            "weighted avg       0.78      0.79      0.78     82912\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41587\n",
            "           1       0.67      0.55      0.60      4367\n",
            "           2       0.69      0.67      0.68     14644\n",
            "           3       0.62      0.39      0.48      2420\n",
            "           4       0.76      0.79      0.78     17146\n",
            "           5       0.75      0.68      0.72      2780\n",
            "\n",
            "    accuracy                           0.79     82944\n",
            "   macro avg       0.72      0.66      0.69     82944\n",
            "weighted avg       0.78      0.79      0.78     82944\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41603\n",
            "           1       0.67      0.55      0.60      4368\n",
            "           2       0.69      0.67      0.68     14651\n",
            "           3       0.62      0.39      0.48      2421\n",
            "           4       0.76      0.79      0.78     17151\n",
            "           5       0.75      0.68      0.72      2782\n",
            "\n",
            "    accuracy                           0.79     82976\n",
            "   macro avg       0.72      0.66      0.69     82976\n",
            "weighted avg       0.78      0.79      0.78     82976\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41619\n",
            "           1       0.67      0.54      0.60      4369\n",
            "           2       0.69      0.67      0.68     14655\n",
            "           3       0.62      0.39      0.48      2422\n",
            "           4       0.76      0.79      0.78     17161\n",
            "           5       0.75      0.68      0.71      2782\n",
            "\n",
            "    accuracy                           0.79     83008\n",
            "   macro avg       0.72      0.66      0.69     83008\n",
            "weighted avg       0.78      0.79      0.78     83008\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41633\n",
            "           1       0.67      0.55      0.60      4370\n",
            "           2       0.69      0.67      0.68     14658\n",
            "           3       0.62      0.39      0.48      2423\n",
            "           4       0.76      0.79      0.78     17172\n",
            "           5       0.75      0.68      0.71      2784\n",
            "\n",
            "    accuracy                           0.79     83040\n",
            "   macro avg       0.72      0.66      0.69     83040\n",
            "weighted avg       0.78      0.79      0.78     83040\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41650\n",
            "           1       0.67      0.54      0.60      4373\n",
            "           2       0.69      0.67      0.68     14659\n",
            "           3       0.62      0.39      0.48      2424\n",
            "           4       0.76      0.79      0.78     17180\n",
            "           5       0.75      0.68      0.71      2786\n",
            "\n",
            "    accuracy                           0.79     83072\n",
            "   macro avg       0.72      0.66      0.69     83072\n",
            "weighted avg       0.78      0.79      0.78     83072\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41666\n",
            "           1       0.67      0.55      0.60      4374\n",
            "           2       0.69      0.67      0.68     14666\n",
            "           3       0.62      0.39      0.48      2425\n",
            "           4       0.76      0.79      0.78     17185\n",
            "           5       0.75      0.68      0.71      2788\n",
            "\n",
            "    accuracy                           0.79     83104\n",
            "   macro avg       0.72      0.66      0.69     83104\n",
            "weighted avg       0.78      0.79      0.78     83104\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41682\n",
            "           1       0.67      0.55      0.60      4374\n",
            "           2       0.69      0.67      0.68     14672\n",
            "           3       0.62      0.39      0.48      2425\n",
            "           4       0.76      0.79      0.78     17194\n",
            "           5       0.75      0.68      0.71      2789\n",
            "\n",
            "    accuracy                           0.79     83136\n",
            "   macro avg       0.72      0.66      0.69     83136\n",
            "weighted avg       0.78      0.79      0.78     83136\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41695\n",
            "           1       0.67      0.55      0.60      4375\n",
            "           2       0.69      0.67      0.68     14679\n",
            "           3       0.62      0.39      0.48      2426\n",
            "           4       0.76      0.79      0.78     17202\n",
            "           5       0.75      0.68      0.71      2791\n",
            "\n",
            "    accuracy                           0.79     83168\n",
            "   macro avg       0.72      0.66      0.69     83168\n",
            "weighted avg       0.78      0.79      0.78     83168\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41709\n",
            "           1       0.67      0.55      0.60      4378\n",
            "           2       0.69      0.67      0.68     14688\n",
            "           3       0.62      0.39      0.48      2427\n",
            "           4       0.76      0.79      0.78     17206\n",
            "           5       0.75      0.68      0.71      2792\n",
            "\n",
            "    accuracy                           0.79     83200\n",
            "   macro avg       0.72      0.66      0.69     83200\n",
            "weighted avg       0.78      0.79      0.78     83200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41726\n",
            "           1       0.67      0.55      0.60      4379\n",
            "           2       0.69      0.67      0.68     14692\n",
            "           3       0.62      0.39      0.48      2430\n",
            "           4       0.76      0.79      0.78     17212\n",
            "           5       0.75      0.68      0.71      2793\n",
            "\n",
            "    accuracy                           0.79     83232\n",
            "   macro avg       0.72      0.66      0.69     83232\n",
            "weighted avg       0.78      0.79      0.78     83232\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41739\n",
            "           1       0.67      0.55      0.60      4382\n",
            "           2       0.69      0.67      0.68     14697\n",
            "           3       0.62      0.39      0.48      2430\n",
            "           4       0.76      0.79      0.78     17221\n",
            "           5       0.75      0.68      0.72      2795\n",
            "\n",
            "    accuracy                           0.79     83264\n",
            "   macro avg       0.72      0.66      0.69     83264\n",
            "weighted avg       0.78      0.79      0.78     83264\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41756\n",
            "           1       0.67      0.55      0.60      4383\n",
            "           2       0.69      0.67      0.68     14702\n",
            "           3       0.62      0.39      0.48      2431\n",
            "           4       0.76      0.79      0.78     17228\n",
            "           5       0.75      0.68      0.72      2796\n",
            "\n",
            "    accuracy                           0.79     83296\n",
            "   macro avg       0.72      0.66      0.69     83296\n",
            "weighted avg       0.78      0.79      0.78     83296\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41768\n",
            "           1       0.67      0.55      0.60      4384\n",
            "           2       0.69      0.67      0.68     14708\n",
            "           3       0.62      0.39      0.48      2434\n",
            "           4       0.76      0.79      0.78     17237\n",
            "           5       0.75      0.68      0.72      2797\n",
            "\n",
            "    accuracy                           0.79     83328\n",
            "   macro avg       0.73      0.66      0.69     83328\n",
            "weighted avg       0.78      0.79      0.78     83328\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41780\n",
            "           1       0.67      0.55      0.60      4388\n",
            "           2       0.69      0.67      0.68     14717\n",
            "           3       0.62      0.39      0.48      2434\n",
            "           4       0.76      0.79      0.78     17243\n",
            "           5       0.75      0.68      0.72      2798\n",
            "\n",
            "    accuracy                           0.79     83360\n",
            "   macro avg       0.72      0.66      0.69     83360\n",
            "weighted avg       0.78      0.79      0.78     83360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41793\n",
            "           1       0.67      0.55      0.60      4391\n",
            "           2       0.69      0.67      0.68     14723\n",
            "           3       0.62      0.39      0.48      2435\n",
            "           4       0.76      0.79      0.78     17252\n",
            "           5       0.75      0.68      0.72      2798\n",
            "\n",
            "    accuracy                           0.79     83392\n",
            "   macro avg       0.72      0.66      0.69     83392\n",
            "weighted avg       0.78      0.79      0.78     83392\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41808\n",
            "           1       0.67      0.55      0.60      4391\n",
            "           2       0.69      0.67      0.68     14729\n",
            "           3       0.62      0.39      0.48      2438\n",
            "           4       0.76      0.79      0.78     17257\n",
            "           5       0.75      0.68      0.72      2801\n",
            "\n",
            "    accuracy                           0.79     83424\n",
            "   macro avg       0.73      0.66      0.69     83424\n",
            "weighted avg       0.78      0.79      0.78     83424\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41824\n",
            "           1       0.67      0.55      0.60      4392\n",
            "           2       0.69      0.67      0.68     14735\n",
            "           3       0.62      0.39      0.48      2439\n",
            "           4       0.76      0.79      0.78     17264\n",
            "           5       0.75      0.68      0.72      2802\n",
            "\n",
            "    accuracy                           0.79     83456\n",
            "   macro avg       0.73      0.66      0.69     83456\n",
            "weighted avg       0.78      0.79      0.78     83456\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41839\n",
            "           1       0.67      0.55      0.60      4394\n",
            "           2       0.69      0.67      0.68     14741\n",
            "           3       0.62      0.39      0.48      2440\n",
            "           4       0.76      0.79      0.78     17271\n",
            "           5       0.76      0.68      0.72      2803\n",
            "\n",
            "    accuracy                           0.79     83488\n",
            "   macro avg       0.72      0.66      0.69     83488\n",
            "weighted avg       0.78      0.79      0.78     83488\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41855\n",
            "           1       0.67      0.55      0.60      4394\n",
            "           2       0.69      0.67      0.68     14749\n",
            "           3       0.62      0.39      0.48      2440\n",
            "           4       0.76      0.79      0.78     17278\n",
            "           5       0.76      0.68      0.72      2804\n",
            "\n",
            "    accuracy                           0.79     83520\n",
            "   macro avg       0.72      0.66      0.69     83520\n",
            "weighted avg       0.78      0.79      0.78     83520\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41870\n",
            "           1       0.67      0.55      0.60      4395\n",
            "           2       0.69      0.67      0.68     14757\n",
            "           3       0.62      0.39      0.48      2440\n",
            "           4       0.76      0.79      0.78     17285\n",
            "           5       0.76      0.68      0.72      2805\n",
            "\n",
            "    accuracy                           0.79     83552\n",
            "   macro avg       0.73      0.66      0.69     83552\n",
            "weighted avg       0.78      0.79      0.78     83552\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41882\n",
            "           1       0.67      0.55      0.60      4398\n",
            "           2       0.69      0.67      0.68     14764\n",
            "           3       0.62      0.39      0.48      2443\n",
            "           4       0.76      0.79      0.78     17289\n",
            "           5       0.76      0.68      0.72      2808\n",
            "\n",
            "    accuracy                           0.79     83584\n",
            "   macro avg       0.73      0.66      0.69     83584\n",
            "weighted avg       0.78      0.79      0.78     83584\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41895\n",
            "           1       0.67      0.55      0.60      4399\n",
            "           2       0.69      0.67      0.68     14771\n",
            "           3       0.62      0.39      0.48      2443\n",
            "           4       0.76      0.79      0.78     17299\n",
            "           5       0.76      0.68      0.72      2809\n",
            "\n",
            "    accuracy                           0.79     83616\n",
            "   macro avg       0.73      0.66      0.69     83616\n",
            "weighted avg       0.78      0.79      0.78     83616\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41911\n",
            "           1       0.67      0.55      0.60      4404\n",
            "           2       0.69      0.67      0.68     14773\n",
            "           3       0.62      0.39      0.48      2445\n",
            "           4       0.76      0.79      0.78     17305\n",
            "           5       0.76      0.68      0.72      2810\n",
            "\n",
            "    accuracy                           0.79     83648\n",
            "   macro avg       0.73      0.66      0.69     83648\n",
            "weighted avg       0.78      0.79      0.78     83648\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41923\n",
            "           1       0.67      0.55      0.60      4405\n",
            "           2       0.69      0.67      0.68     14785\n",
            "           3       0.62      0.39      0.48      2445\n",
            "           4       0.76      0.79      0.78     17309\n",
            "           5       0.76      0.68      0.72      2813\n",
            "\n",
            "    accuracy                           0.79     83680\n",
            "   macro avg       0.73      0.66      0.69     83680\n",
            "weighted avg       0.78      0.79      0.78     83680\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41937\n",
            "           1       0.67      0.55      0.60      4408\n",
            "           2       0.69      0.67      0.68     14792\n",
            "           3       0.62      0.39      0.48      2446\n",
            "           4       0.76      0.79      0.78     17315\n",
            "           5       0.76      0.68      0.72      2814\n",
            "\n",
            "    accuracy                           0.79     83712\n",
            "   macro avg       0.73      0.66      0.69     83712\n",
            "weighted avg       0.78      0.79      0.78     83712\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41950\n",
            "           1       0.67      0.55      0.60      4409\n",
            "           2       0.69      0.67      0.68     14800\n",
            "           3       0.62      0.39      0.48      2446\n",
            "           4       0.76      0.79      0.78     17325\n",
            "           5       0.76      0.68      0.72      2814\n",
            "\n",
            "    accuracy                           0.79     83744\n",
            "   macro avg       0.73      0.66      0.69     83744\n",
            "weighted avg       0.78      0.79      0.78     83744\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41968\n",
            "           1       0.67      0.55      0.60      4409\n",
            "           2       0.69      0.67      0.68     14805\n",
            "           3       0.62      0.39      0.48      2448\n",
            "           4       0.76      0.79      0.78     17330\n",
            "           5       0.76      0.68      0.72      2816\n",
            "\n",
            "    accuracy                           0.79     83776\n",
            "   macro avg       0.73      0.66      0.69     83776\n",
            "weighted avg       0.78      0.79      0.78     83776\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41979\n",
            "           1       0.67      0.55      0.60      4411\n",
            "           2       0.69      0.67      0.68     14816\n",
            "           3       0.62      0.39      0.48      2449\n",
            "           4       0.76      0.79      0.78     17337\n",
            "           5       0.76      0.68      0.72      2816\n",
            "\n",
            "    accuracy                           0.79     83808\n",
            "   macro avg       0.73      0.66      0.69     83808\n",
            "weighted avg       0.78      0.79      0.78     83808\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     41995\n",
            "           1       0.67      0.55      0.60      4414\n",
            "           2       0.69      0.67      0.68     14822\n",
            "           3       0.62      0.39      0.48      2449\n",
            "           4       0.76      0.79      0.78     17343\n",
            "           5       0.76      0.68      0.72      2817\n",
            "\n",
            "    accuracy                           0.79     83840\n",
            "   macro avg       0.73      0.66      0.69     83840\n",
            "weighted avg       0.78      0.79      0.78     83840\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42015\n",
            "           1       0.67      0.55      0.60      4417\n",
            "           2       0.69      0.67      0.68     14825\n",
            "           3       0.62      0.39      0.48      2449\n",
            "           4       0.76      0.79      0.78     17347\n",
            "           5       0.76      0.68      0.72      2819\n",
            "\n",
            "    accuracy                           0.79     83872\n",
            "   macro avg       0.73      0.66      0.69     83872\n",
            "weighted avg       0.78      0.79      0.78     83872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42029\n",
            "           1       0.67      0.55      0.60      4418\n",
            "           2       0.69      0.67      0.68     14831\n",
            "           3       0.62      0.39      0.48      2449\n",
            "           4       0.76      0.79      0.78     17358\n",
            "           5       0.76      0.68      0.72      2819\n",
            "\n",
            "    accuracy                           0.79     83904\n",
            "   macro avg       0.72      0.66      0.69     83904\n",
            "weighted avg       0.78      0.79      0.78     83904\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42048\n",
            "           1       0.67      0.55      0.60      4421\n",
            "           2       0.69      0.67      0.68     14835\n",
            "           3       0.62      0.39      0.48      2449\n",
            "           4       0.76      0.79      0.78     17364\n",
            "           5       0.76      0.68      0.72      2819\n",
            "\n",
            "    accuracy                           0.79     83936\n",
            "   macro avg       0.72      0.66      0.69     83936\n",
            "weighted avg       0.78      0.79      0.78     83936\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42064\n",
            "           1       0.67      0.55      0.60      4421\n",
            "           2       0.69      0.67      0.68     14843\n",
            "           3       0.62      0.39      0.48      2449\n",
            "           4       0.76      0.79      0.78     17372\n",
            "           5       0.76      0.68      0.72      2819\n",
            "\n",
            "    accuracy                           0.79     83968\n",
            "   macro avg       0.72      0.66      0.69     83968\n",
            "weighted avg       0.78      0.79      0.78     83968\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42078\n",
            "           1       0.67      0.55      0.60      4423\n",
            "           2       0.69      0.67      0.68     14850\n",
            "           3       0.62      0.39      0.48      2452\n",
            "           4       0.76      0.79      0.78     17378\n",
            "           5       0.76      0.68      0.72      2819\n",
            "\n",
            "    accuracy                           0.79     84000\n",
            "   macro avg       0.72      0.66      0.69     84000\n",
            "weighted avg       0.78      0.79      0.78     84000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42092\n",
            "           1       0.67      0.55      0.60      4424\n",
            "           2       0.69      0.67      0.68     14857\n",
            "           3       0.62      0.39      0.48      2453\n",
            "           4       0.76      0.79      0.78     17386\n",
            "           5       0.76      0.68      0.72      2820\n",
            "\n",
            "    accuracy                           0.79     84032\n",
            "   macro avg       0.72      0.66      0.69     84032\n",
            "weighted avg       0.78      0.79      0.78     84032\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42112\n",
            "           1       0.67      0.55      0.60      4425\n",
            "           2       0.69      0.67      0.68     14861\n",
            "           3       0.62      0.39      0.48      2455\n",
            "           4       0.76      0.79      0.78     17391\n",
            "           5       0.76      0.68      0.72      2820\n",
            "\n",
            "    accuracy                           0.79     84064\n",
            "   macro avg       0.72      0.66      0.69     84064\n",
            "weighted avg       0.78      0.79      0.78     84064\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42132\n",
            "           1       0.67      0.55      0.60      4425\n",
            "           2       0.69      0.67      0.68     14863\n",
            "           3       0.62      0.39      0.48      2458\n",
            "           4       0.76      0.79      0.78     17398\n",
            "           5       0.76      0.68      0.72      2820\n",
            "\n",
            "    accuracy                           0.79     84096\n",
            "   macro avg       0.72      0.66      0.69     84096\n",
            "weighted avg       0.78      0.79      0.78     84096\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42150\n",
            "           1       0.67      0.55      0.60      4426\n",
            "           2       0.69      0.67      0.68     14870\n",
            "           3       0.62      0.39      0.48      2459\n",
            "           4       0.76      0.79      0.78     17402\n",
            "           5       0.76      0.68      0.72      2821\n",
            "\n",
            "    accuracy                           0.79     84128\n",
            "   macro avg       0.72      0.66      0.69     84128\n",
            "weighted avg       0.78      0.79      0.78     84128\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42170\n",
            "           1       0.67      0.55      0.60      4427\n",
            "           2       0.69      0.67      0.68     14873\n",
            "           3       0.62      0.39      0.48      2460\n",
            "           4       0.76      0.79      0.78     17409\n",
            "           5       0.76      0.68      0.72      2821\n",
            "\n",
            "    accuracy                           0.79     84160\n",
            "   macro avg       0.72      0.66      0.69     84160\n",
            "weighted avg       0.78      0.79      0.78     84160\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42187\n",
            "           1       0.67      0.55      0.60      4429\n",
            "           2       0.69      0.67      0.68     14877\n",
            "           3       0.62      0.39      0.48      2460\n",
            "           4       0.76      0.79      0.78     17417\n",
            "           5       0.76      0.68      0.72      2822\n",
            "\n",
            "    accuracy                           0.79     84192\n",
            "   macro avg       0.72      0.66      0.69     84192\n",
            "weighted avg       0.78      0.79      0.78     84192\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42203\n",
            "           1       0.67      0.55      0.60      4433\n",
            "           2       0.69      0.67      0.68     14882\n",
            "           3       0.62      0.39      0.48      2463\n",
            "           4       0.76      0.79      0.78     17420\n",
            "           5       0.76      0.68      0.72      2823\n",
            "\n",
            "    accuracy                           0.79     84224\n",
            "   macro avg       0.72      0.66      0.69     84224\n",
            "weighted avg       0.78      0.79      0.78     84224\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42218\n",
            "           1       0.67      0.55      0.60      4437\n",
            "           2       0.69      0.67      0.68     14887\n",
            "           3       0.62      0.39      0.48      2464\n",
            "           4       0.76      0.79      0.78     17425\n",
            "           5       0.76      0.68      0.72      2825\n",
            "\n",
            "    accuracy                           0.79     84256\n",
            "   macro avg       0.72      0.66      0.69     84256\n",
            "weighted avg       0.78      0.79      0.78     84256\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42234\n",
            "           1       0.67      0.55      0.60      4437\n",
            "           2       0.69      0.67      0.68     14892\n",
            "           3       0.62      0.39      0.48      2465\n",
            "           4       0.76      0.79      0.78     17433\n",
            "           5       0.76      0.68      0.72      2827\n",
            "\n",
            "    accuracy                           0.79     84288\n",
            "   macro avg       0.72      0.66      0.69     84288\n",
            "weighted avg       0.78      0.79      0.78     84288\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42246\n",
            "           1       0.67      0.55      0.60      4440\n",
            "           2       0.69      0.67      0.68     14900\n",
            "           3       0.62      0.39      0.48      2465\n",
            "           4       0.76      0.79      0.78     17439\n",
            "           5       0.76      0.68      0.72      2830\n",
            "\n",
            "    accuracy                           0.79     84320\n",
            "   macro avg       0.72      0.66      0.69     84320\n",
            "weighted avg       0.78      0.79      0.78     84320\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42261\n",
            "           1       0.67      0.55      0.60      4441\n",
            "           2       0.69      0.67      0.68     14905\n",
            "           3       0.62      0.39      0.48      2465\n",
            "           4       0.76      0.79      0.78     17448\n",
            "           5       0.76      0.68      0.72      2832\n",
            "\n",
            "    accuracy                           0.79     84352\n",
            "   macro avg       0.72      0.66      0.69     84352\n",
            "weighted avg       0.78      0.79      0.78     84352\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42274\n",
            "           1       0.67      0.55      0.60      4444\n",
            "           2       0.69      0.67      0.68     14912\n",
            "           3       0.62      0.39      0.48      2467\n",
            "           4       0.76      0.79      0.78     17453\n",
            "           5       0.76      0.68      0.72      2834\n",
            "\n",
            "    accuracy                           0.79     84384\n",
            "   macro avg       0.72      0.66      0.69     84384\n",
            "weighted avg       0.78      0.79      0.78     84384\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42291\n",
            "           1       0.67      0.55      0.60      4444\n",
            "           2       0.69      0.67      0.68     14919\n",
            "           3       0.62      0.39      0.48      2469\n",
            "           4       0.76      0.79      0.78     17458\n",
            "           5       0.76      0.68      0.72      2835\n",
            "\n",
            "    accuracy                           0.79     84416\n",
            "   macro avg       0.72      0.66      0.69     84416\n",
            "weighted avg       0.78      0.79      0.78     84416\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42307\n",
            "           1       0.67      0.55      0.60      4445\n",
            "           2       0.69      0.67      0.68     14924\n",
            "           3       0.62      0.39      0.48      2471\n",
            "           4       0.76      0.79      0.78     17466\n",
            "           5       0.76      0.68      0.72      2835\n",
            "\n",
            "    accuracy                           0.79     84448\n",
            "   macro avg       0.72      0.66      0.69     84448\n",
            "weighted avg       0.78      0.79      0.78     84448\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42325\n",
            "           1       0.67      0.55      0.60      4446\n",
            "           2       0.69      0.67      0.68     14928\n",
            "           3       0.62      0.39      0.48      2471\n",
            "           4       0.76      0.79      0.78     17472\n",
            "           5       0.76      0.68      0.72      2838\n",
            "\n",
            "    accuracy                           0.79     84480\n",
            "   macro avg       0.72      0.66      0.69     84480\n",
            "weighted avg       0.78      0.79      0.78     84480\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86     42326\n",
            "           1       0.67      0.55      0.60      4446\n",
            "           2       0.69      0.67      0.68     14928\n",
            "           3       0.62      0.39      0.48      2471\n",
            "           4       0.76      0.79      0.78     17472\n",
            "           5       0.76      0.68      0.72      2838\n",
            "\n",
            "    accuracy                           0.79     84481\n",
            "   macro avg       0.72      0.66      0.69     84481\n",
            "weighted avg       0.78      0.79      0.78     84481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "############ Validation #############\n",
        "\n",
        "# Obtain performance over the validation set\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/SaveModels/BERT_model.pt'))\n",
        "\n",
        "# Initialize lists to store predictions and labels\n",
        "predictions = []\n",
        "labels_test = []\n",
        "\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "# Evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Don't compute and store gradients\n",
        "    with torch.no_grad():        \n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        # Get the \"logits\"\n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Obtain predictions\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        # Append predictions and labels to the lists\n",
        "        predictions.extend(pred_flat.tolist())\n",
        "        labels_test.extend(label_ids.tolist())\n",
        "\n",
        "    \n",
        "    # Print classification report\n",
        "    print(classification_report(np.array(labels_test).reshape(len(labels_test),1), predictions))\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DG_PnqHzGuwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a46521-cf99-4abe-d9e9-fa22f70a5406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.57%\n"
          ]
        }
      ],
      "source": [
        "# Calculate validation accuracy\n",
        "accuracy = accuracy_score(labels_test, predictions)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dgqJAG71AmLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe14137-10db-493b-b567-f4fc7932da41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.55      0.60      4446\n",
            "           2       0.69      0.67      0.68     14928\n",
            "           3       0.62      0.39      0.48      2471\n",
            "           4       0.76      0.79      0.78     17472\n",
            "           5       0.76      0.68      0.72      2838\n",
            "\n",
            "   micro avg       0.72      0.69      0.71     42155\n",
            "   macro avg       0.70      0.62      0.65     42155\n",
            "weighted avg       0.72      0.69      0.70     42155\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 'true' label\n",
        "print(classification_report(np.array(labels_test).reshape(len(labels_test), 1), predictions, labels = [0,1,2,3,4,5], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "b78o8-LJ_f37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875d2c78-9a44-4bd4-a6ab-536639e6ef60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[37171   530  2449   261  1583   332]\n",
            " [ 1048  2428   298    66   542    64]\n",
            " [ 2766   183 10053    80  1762    84]\n",
            " [  870   105   186   960   284    66]\n",
            " [ 1767   304  1366   126 13832    77]\n",
            " [  526    54   163    50   115  1930]]\n"
          ]
        }
      ],
      "source": [
        "# Plot confusion matrix\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(np.array(labels_test), predictions)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will show a heatmap of the confusion matrix, where the x-axis represents the predicted labels and the y-axis represents the true labels. The cells in the heatmap will be colored based on the number of instances in that cell, with darker colors representing higher numbers. The values in each cell will also be displayed.\n",
        "\n",
        "It will be showing you how many instances of each true label were predicted as each other label. This way I can see if the model struggles with certain types of samples and focus on improving those."
      ],
      "metadata": {
        "id": "CVNHPfFef5Mh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "WG2oIHTEBKxb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d6f6b8dd-f609-4279-ae89-875e6b3da6c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualize confusion matrix\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "JdMhUpCS_1gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec96195-2c2d-4747-953f-672b6c71c9e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation completed\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/SaveModels/BERT_model.pt')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Evaluation completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etvAoWRb_f7P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ae68284a5ee410e99f178a40052a120": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130362262372456aafb417e85bb893f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fcb0d5ccf14045b3838d30de7fe018": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39aef75933cf487891e7b01dc4576689",
            "placeholder": "​",
            "style": "IPY_MODEL_9a677501dcdd4c9f96a35b49128bcea8",
            "value": " 570/570 [00:00&lt;00:00, 37.5kB/s]"
          }
        },
        "1bb675d05a514fa2b279583716428edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798a4c09282e4c4f8f2e2e2fda54cb1b",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6a7e95024b4de58256be670e05c697",
            "value": "Downloading: 100%"
          }
        },
        "240698cf4bd4430eb0fe4f2ab51d7ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e0a77f17404b84b1c10f39fef3432d",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d67a29c7f60541f89936a05a7b75c68a",
            "value": 28
          }
        },
        "25093ecd994941bf96f98ef1c5a086a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb0da4497734b89a8c56010ae698115",
            "placeholder": "​",
            "style": "IPY_MODEL_f616500124c143d8b3f0adef653af0fd",
            "value": "Downloading: 100%"
          }
        },
        "26336371aea04664ab6949f4c77661ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cd889ffdb974d97836c27d1c55e7e90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d830e27ffe49178fba4b05700ba3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39aef75933cf487891e7b01dc4576689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb0da4497734b89a8c56010ae698115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6a7e95024b4de58256be670e05c697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f8dd4b4c75346688c2f6eb61116f243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bb675d05a514fa2b279583716428edd",
              "IPY_MODEL_ba761e8fec9449248471ea5f58ba1a73",
              "IPY_MODEL_18fcb0d5ccf14045b3838d30de7fe018"
            ],
            "layout": "IPY_MODEL_2cd889ffdb974d97836c27d1c55e7e90"
          }
        },
        "43da489abec64024a6a584b32882ea38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be4db30a0e564ca183eb555a42054e1c",
              "IPY_MODEL_f24d7b29804443fbac587959db40f2e9",
              "IPY_MODEL_bd7a9f3b943e41238e0de3f013d710ff"
            ],
            "layout": "IPY_MODEL_130362262372456aafb417e85bb893f8"
          }
        },
        "477519260af94392ad4271df88ce3278": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "526ddd4299a347958ee758d0ce8db3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665ae6e9a85a4fd4bf3be137681a84dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7681b3beaad049f0828cc88f2c4268f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798a4c09282e4c4f8f2e2e2fda54cb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd72db9caba40f39fa67e404f4b8a09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a677501dcdd4c9f96a35b49128bcea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3081fb1362441d594f7cd79270aa2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25093ecd994941bf96f98ef1c5a086a1",
              "IPY_MODEL_240698cf4bd4430eb0fe4f2ab51d7ca5",
              "IPY_MODEL_c9bea0b6cdfc42008d16c169c6572843"
            ],
            "layout": "IPY_MODEL_8dd72db9caba40f39fa67e404f4b8a09"
          }
        },
        "ba761e8fec9449248471ea5f58ba1a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526ddd4299a347958ee758d0ce8db3d2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cabf7b04eba844a6b7c971e798218580",
            "value": 570
          }
        },
        "bd7a9f3b943e41238e0de3f013d710ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3474f8b6c3e4dc1bf3cde9b3614a551",
            "placeholder": "​",
            "style": "IPY_MODEL_26336371aea04664ab6949f4c77661ba",
            "value": " 232k/232k [00:00&lt;00:00, 904kB/s]"
          }
        },
        "be4db30a0e564ca183eb555a42054e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_665ae6e9a85a4fd4bf3be137681a84dc",
            "placeholder": "​",
            "style": "IPY_MODEL_f5fa7ece707541bf92e1bf8a954d082c",
            "value": "Downloading: 100%"
          }
        },
        "c9bea0b6cdfc42008d16c169c6572843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d830e27ffe49178fba4b05700ba3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_477519260af94392ad4271df88ce3278",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.92kB/s]"
          }
        },
        "cabf7b04eba844a6b7c971e798218580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d67a29c7f60541f89936a05a7b75c68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7e0a77f17404b84b1c10f39fef3432d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24d7b29804443fbac587959db40f2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae68284a5ee410e99f178a40052a120",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7681b3beaad049f0828cc88f2c4268f1",
            "value": 231508
          }
        },
        "f3474f8b6c3e4dc1bf3cde9b3614a551": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5fa7ece707541bf92e1bf8a954d082c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f616500124c143d8b3f0adef653af0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}